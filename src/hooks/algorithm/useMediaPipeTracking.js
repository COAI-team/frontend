import { useState, useEffect, useCallback, useRef } from 'react';
import {
    startMonitoringSession,
    sendMonitoringViolation,
    endMonitoringSession,
    recordMonitoringWarning
} from '../../service/algorithm/algorithmApi';

/**
 * MediaPipe ê¸°ë°˜ ì‹œì„ /ì–¼êµ´ ì¶”ì  ì»¤ìŠ¤í…€ í›…
 *
 * WebGazer ëŒ€ì•ˆìœ¼ë¡œ MediaPipe Face Landmarker ì‚¬ìš©
 * ì¶”ê°€ ê¸°ëŠ¥: ì¡¸ìŒ ê°ì§€, ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€, 3D ì–¼êµ´ ë°©í–¥, í™ì±„ ì¶”ì 
 *
 * @param {number} problemId - í˜„ì¬ ë¬¸ì œ ID
 * @param {boolean} isActive - ì¶”ì  í™œì„±í™” ì—¬ë¶€
 * @param {number} timeLimitMinutes - ì œí•œ ì‹œê°„ (ë¶„, ê¸°ë³¸ 30ë¶„)
 * @returns {object} - ì¶”ì  ìƒíƒœ ë° ì œì–´ í•¨ìˆ˜
 */

// ìƒìˆ˜ ì •ì˜
const NO_FACE_THRESHOLD_MS = 15000; // 15ì´ˆ ì´ìƒ NO_FACE ì‹œ ì‹¬ê°í•œ ìœ„ë°˜
const NO_FACE_WARNING_THRESHOLD_MS = 5000; // 5ì´ˆ ì´ìƒ ì‹œ ê²½ê³  í‘œì‹œ ì‹œì‘

// ì¡¸ìŒ ê°ì§€ ìƒìˆ˜
const EAR_THRESHOLD = 0.20; // Eye Aspect Ratio ì„ê³„ê°’ (ëˆˆ ê°ê¹€ íŒë‹¨) - 0.25ì—ì„œ í•˜í–¥ (ë” í™•ì‹¤í•œ ëˆˆ ê°ê¹€ë§Œ ê°ì§€)
const DROWSY_FRAME_THRESHOLD = 90; // ì—°ì† í”„ë ˆì„ ìˆ˜ (90í”„ë ˆì„ â‰ˆ 3ì´ˆ) - 30ì—ì„œ ìƒí–¥ (ì˜¤íƒ ê°ì†Œ)
const PERCLOS_THRESHOLD = 0.8; // PERCLOS ì„ê³„ê°’ (80% ì´ìƒ ì‹œ ì¡¸ìŒ)
const PERCLOS_WINDOW_SECONDS = 60; // PERCLOS ê³„ì‚° ìœˆë„ìš° (60ì´ˆ)

// MediaPipe ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (478ê°œ ì¤‘ ì£¼ìš” í¬ì¸íŠ¸)
const LANDMARK_INDICES = {
    // ëˆˆ (Eye Aspect Ratio ê³„ì‚°ìš©)
    LEFT_EYE: {
        P1: 33,   // ì™¼ìª½ ë
        P2: 160,  // ìƒë‹¨ 1
        P3: 158,  // ìƒë‹¨ 2
        P4: 133,  // ì˜¤ë¥¸ìª½ ë
        P5: 153,  // í•˜ë‹¨ 1
        P6: 144   // í•˜ë‹¨ 2
    },
    RIGHT_EYE: {
        P1: 362,  // ì™¼ìª½ ë
        P2: 385,  // ìƒë‹¨ 1
        P3: 387,  // ìƒë‹¨ 2
        P4: 263,  // ì˜¤ë¥¸ìª½ ë
        P5: 373,  // í•˜ë‹¨ 1
        P6: 380   // í•˜ë‹¨ 2
    },
    // í™ì±„ (Iris)
    LEFT_IRIS: [468, 469, 470, 471, 472],  // ì™¼ìª½ í™ì±„ ì¤‘ì‹¬ ë° ì£¼ë³€
    RIGHT_IRIS: [473, 474, 475, 476, 477], // ì˜¤ë¥¸ìª½ í™ì±„ ì¤‘ì‹¬ ë° ì£¼ë³€
    // ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš©
    NOSE_TIP: 1,
    CHIN: 152,
    LEFT_EYE_OUTER: 33,
    RIGHT_EYE_OUTER: 263,
    LEFT_MOUTH_CORNER: 61,
    RIGHT_MOUTH_CORNER: 291
};

// ìœ í‹¸ë¦¬í‹°: ë‘ ì  ì‚¬ì´ ê±°ë¦¬ ê³„ì‚°
const distance = (p1, p2) => {
    return Math.sqrt(
        Math.pow(p2.x - p1.x, 2) +
        Math.pow(p2.y - p1.y, 2) +
        Math.pow((p2.z || 0) - (p1.z || 0), 2)
    );
};

// Eye Aspect Ratio (EAR) ê³„ì‚°
const calculateEAR = (eyeLandmarks) => {
    const { P1, P2, P3, P4, P5, P6 } = eyeLandmarks;
    const vertical1 = distance(P2, P6);
    const vertical2 = distance(P3, P5);
    const horizontal = distance(P1, P4);
    return (vertical1 + vertical2) / (2.0 * horizontal);
};

// ========== Kalman Filter for 2D Gaze Tracking ==========
// State: [x, y, vx, vy] (position + velocity)
// Measurement: [x, y] (position only)
class KalmanFilter2D {
    constructor() {
        // ìƒíƒœ ë²¡í„°: [x, y, vx, vy]
        this.state = {
            x: window.innerWidth / 2,
            y: window.innerHeight / 2,
            vx: 0,
            vy: 0
        };

        // ì˜¤ì°¨ ê³µë¶„ì‚° í–‰ë ¬ P (4x4, ëŒ€ê°ì„ ë§Œ ì‚¬ìš© - ë‹¨ìˆœí™”)
        this.P = {
            x: 1000,   // ì´ˆê¸° ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„± (í° ê°’)
            y: 1000,
            vx: 1000,  // ì´ˆê¸° ì†ë„ ë¶ˆí™•ì‹¤ì„±
            vy: 1000
        };

        // í”„ë¡œì„¸ìŠ¤ ë…¸ì´ì¦ˆ Q (ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±)
        // ê°’ì´ í´ìˆ˜ë¡ ì¸¡ì •ê°’ì„ ë” ì‹ ë¢°
        this.Q = {
            x: 0.1,    // ìœ„ì¹˜ ë…¸ì´ì¦ˆ
            y: 0.1,
            vx: 1.0,   // ì†ë„ ë…¸ì´ì¦ˆ (ê°€ì† í—ˆìš©)
            vy: 1.0
        };

        // ì¸¡ì • ë…¸ì´ì¦ˆ R (ì¸¡ì •ê°’ ë¶ˆí™•ì‹¤ì„±)
        // ê°’ì´ í´ìˆ˜ë¡ ì˜ˆì¸¡ê°’ì„ ë” ì‹ ë¢° (ìŠ¤ë¬´ë”© íš¨ê³¼ ì¦ê°€)
        // ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¸¡ì •ê°’ì„ ë” ì‹ ë¢° (ë°˜ì‘ ì†ë„ ì¦ê°€)
        this.R = {
            x: 20,     // ì‹œì„  ì¸¡ì • ë…¸ì´ì¦ˆ (í”½ì…€ ë‹¨ìœ„) - 50ì—ì„œ 20ìœ¼ë¡œ ê°ì†Œ (ë°˜ì‘ì„± í–¥ìƒ)
            y: 20
        };

        this.lastTime = performance.now();
        this.initialized = false;
    }

    // ì˜ˆì¸¡ ë‹¨ê³„ (Predict)
    predict(dt = null) {
        const now = performance.now();
        if (dt === null) {
            dt = (now - this.lastTime) / 1000; // ì´ˆ ë‹¨ìœ„
        }
        this.lastTime = now;

        // dtê°€ ë„ˆë¬´ í¬ë©´ (0.5ì´ˆ ì´ìƒ) ë¦¬ì…‹
        if (dt > 0.5) {
            dt = 0.033; // 30fps ê¸°ì¤€
        }

        // ìƒíƒœ ì „ì´: x' = x + vx * dt
        this.state.x += this.state.vx * dt;
        this.state.y += this.state.vy * dt;

        // ìœ„ì¹˜ ê²½ê³„ í´ë¨í•‘ (í™”ë©´ ë°–ìœ¼ë¡œ ë„ˆë¬´ ë©€ë¦¬ ë‚˜ê°€ì§€ ì•Šë„ë¡)
        const MARGIN = 200;
        this.state.x = Math.max(-MARGIN, Math.min(this.state.x, window.innerWidth + MARGIN));
        this.state.y = Math.max(-MARGIN, Math.min(this.state.y, window.innerHeight + MARGIN));

        // ì˜¤ì°¨ ê³µë¶„ì‚° ì—…ë°ì´íŠ¸: P' = F * P * F^T + Q
        // ë‹¨ìˆœí™”ëœ ë²„ì „ (ëŒ€ê° í–‰ë ¬ ê°€ì •)
        this.P.x += this.P.vx * dt * dt + this.Q.x;
        this.P.y += this.P.vy * dt * dt + this.Q.y;
        this.P.vx += this.Q.vx;
        this.P.vy += this.Q.vy;

        return { x: this.state.x, y: this.state.y };
    }

    // ì—…ë°ì´íŠ¸ ë‹¨ê³„ (Update/Correct)
    update(measurementX, measurementY) {
        if (!this.initialized) {
            // ì²« ì¸¡ì •ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            this.state.x = measurementX;
            this.state.y = measurementY;
            this.state.vx = 0;
            this.state.vy = 0;
            this.initialized = true;
            return { x: measurementX, y: measurementY };
        }

        // ì¹¼ë§Œ ì´ë“ ê³„ì‚°: K = P * H^T * (H * P * H^T + R)^-1
        // H = [[1, 0, 0, 0], [0, 1, 0, 0]] (ìœ„ì¹˜ë§Œ ì¸¡ì •)
        const Kx = this.P.x / (this.P.x + this.R.x);
        const Ky = this.P.y / (this.P.y + this.R.y);

        // ì†ë„ì— ëŒ€í•œ ì¹¼ë§Œ ì´ë“ (ìœ„ì¹˜ ì”ì°¨ì—ì„œ ì†ë„ ì¶”ì •)
        const Kvx = this.P.vx / (this.P.x + this.R.x) * 0.5;
        const Kvy = this.P.vy / (this.P.y + this.R.y) * 0.5;

        // ì”ì°¨ (Innovation): y = z - H * x
        let residualX = measurementX - this.state.x;
        let residualY = measurementY - this.state.y;

        // ì”ì°¨ í´ë¨í•‘ (ë„ˆë¬´ í° ì í”„ ë°©ì§€ - í™”ë©´ 1/2 ì´ìƒ ì í”„ ì œí•œ)
        // 1/3 â†’ 1/2ë¡œ ë³€ê²½: ë¹ ë¥¸ ì‹œì„  ì´ë™ í—ˆìš© ë²”ìœ„ í™•ëŒ€
        const MAX_RESIDUAL = Math.max(window.innerWidth, window.innerHeight) / 2;
        residualX = Math.max(-MAX_RESIDUAL, Math.min(MAX_RESIDUAL, residualX));
        residualY = Math.max(-MAX_RESIDUAL, Math.min(MAX_RESIDUAL, residualY));

        // ìƒíƒœ ì—…ë°ì´íŠ¸: x = x + K * y
        this.state.x += Kx * residualX;
        this.state.y += Ky * residualY;

        // ì†ë„ ì—…ë°ì´íŠ¸ (ì”ì°¨ ê¸°ë°˜)
        this.state.vx += Kvx * residualX;
        this.state.vy += Kvy * residualY;

        // ì†ë„ í´ë¨í•‘ (í­ì£¼ ë°©ì§€ - 1ì´ˆì— í™”ë©´ 1ë°° ì´ìƒ ì´ë™ ë¶ˆê°€)
        const MAX_VELOCITY = window.innerWidth;
        this.state.vx = Math.max(-MAX_VELOCITY, Math.min(MAX_VELOCITY, this.state.vx));
        this.state.vy = Math.max(-MAX_VELOCITY, Math.min(MAX_VELOCITY, this.state.vy));

        // ì†ë„ ê°ì‡  (ì„œì„œíˆ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ë„ë¡ - ì•ˆì •ì„±)
        // 0.95 â†’ 0.98ë¡œ ë³€ê²½: ê°ì‡ ë¥¼ ì¤„ì—¬ ë¹ ë¥¸ ì›€ì§ì„ ì¶”ì  ê°œì„ 
        this.state.vx *= 0.98;
        this.state.vy *= 0.98;

        // ì˜¤ì°¨ ê³µë¶„ì‚° ì—…ë°ì´íŠ¸: P = (I - K * H) * P
        this.P.x *= (1 - Kx);
        this.P.y *= (1 - Ky);
        this.P.vx *= (1 - Kvx * 0.3);
        this.P.vy *= (1 - Kvy * 0.3);

        // ê³µë¶„ì‚° í´ë¨í•‘ (ìˆ˜ì¹˜ ì•ˆì •ì„±)
        const MIN_P = 0.01;
        const MAX_P = 10000;
        this.P.x = Math.max(MIN_P, Math.min(MAX_P, this.P.x));
        this.P.y = Math.max(MIN_P, Math.min(MAX_P, this.P.y));
        this.P.vx = Math.max(MIN_P, Math.min(MAX_P, this.P.vx));
        this.P.vy = Math.max(MIN_P, Math.min(MAX_P, this.P.vy));

        // ìµœì¢… NaN ì²´í¬ (ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°)
        if (!Number.isFinite(this.state.x) || !Number.isFinite(this.state.y) ||
            !Number.isFinite(this.state.vx) || !Number.isFinite(this.state.vy) ||
            !Number.isFinite(this.P.x) || !Number.isFinite(this.P.y)) {
            console.error('ğŸš¨ Kalman state became NaN/Infinity, resetting...');
            this.reset();
            return { x: window.innerWidth / 2, y: window.innerHeight / 2 };
        }

        return { x: this.state.x, y: this.state.y };
    }

    // ì˜ˆì¸¡ + ì—…ë°ì´íŠ¸ í•œë²ˆì— (ì¼ë°˜ì ì¸ ì‚¬ìš©)
    filter(measurementX, measurementY) {
        // NaN/Infinity ê²€ì¦ - ì˜ëª»ëœ ì…ë ¥ ë°©ì§€
        if (!Number.isFinite(measurementX) || !Number.isFinite(measurementY)) {
            console.warn('âš ï¸ Kalman filter received invalid input:', { measurementX, measurementY });
            // í˜„ì¬ ìƒíƒœ ë°˜í™˜ (ì˜ˆì¸¡ë§Œ ìˆ˜í–‰)
            this.predict();
            return { x: this.state.x, y: this.state.y };
        }

        this.predict();
        const result = this.update(measurementX, measurementY);

        // ê²°ê³¼ NaN ê²€ì¦
        if (!Number.isFinite(result.x) || !Number.isFinite(result.y)) {
            console.error('ğŸš¨ Kalman filter produced NaN, resetting...');
            this.reset();
            return { x: window.innerWidth / 2, y: window.innerHeight / 2 };
        }

        return result;
    }

    // í˜„ì¬ ìƒíƒœ ë°˜í™˜
    getState() {
        return { ...this.state };
    }

    // í•„í„° ë¦¬ì…‹
    reset() {
        this.state = {
            x: window.innerWidth / 2,
            y: window.innerHeight / 2,
            vx: 0,
            vy: 0
        };
        this.P = { x: 1000, y: 1000, vx: 1000, vy: 1000 };
        this.initialized = false;
        this.lastTime = performance.now();
    }

    // ì¸¡ì • ë…¸ì´ì¦ˆ ì¡°ì • (ë™ì  ì¡°ì •ìš©)
    setMeasurementNoise(rx, ry) {
        this.R.x = rx;
        this.R.y = ry;
    }
}

// ========== One Euro Filter for 2D Gaze Tracking ==========
// ì ì‘í˜• ì €ì—­ í†µê³¼ í•„í„°: ëŠë¦° ì›€ì§ì„ì€ ê°•í•˜ê²Œ ìŠ¤ë¬´ë”©, ë¹ ë¥¸ ì›€ì§ì„ì€ ë¹ ë¥´ê²Œ ë°˜ì‘
// ì°¸ê³ : https://gery.casiez.net/1euro/

/**
 * 1D One Euro Filter
 * @param {number} minCutoff - ìµœì†Œ ì°¨ë‹¨ ì£¼íŒŒìˆ˜ (Hz). ë‚®ì„ìˆ˜ë¡ ë” ë¶€ë“œëŸ¬ì›€ (ê¸°ë³¸: 1.0)
 * @param {number} beta - ì†ë„ ê°€ì¤‘ì¹˜. ë†’ì„ìˆ˜ë¡ ë¹ ë¥¸ ì›€ì§ì„ì— ë¯¼ê° (ê¸°ë³¸: 0.0005)
 * @param {number} dCutoff - ë¯¸ë¶„ ì‹ í˜¸(ì†ë„) ì°¨ë‹¨ ì£¼íŒŒìˆ˜ (ê¸°ë³¸: 1.0)
 */
class OneEuroFilter {
    constructor(minCutoff = 1.0, beta = 0.0005, dCutoff = 1.0) {
        this.minCutoff = minCutoff;
        this.beta = beta;
        this.dCutoff = dCutoff;

        // ì´ì „ ìƒíƒœ
        this.xPrev = null;      // ì´ì „ í•„í„°ë§ëœ ê°’
        this.dxPrev = 0;        // ì´ì „ ë¯¸ë¶„ê°’ (ì†ë„)
        this.tPrev = null;      // ì´ì „ íƒ€ì„ìŠ¤íƒ¬í”„
    }

    // ì•ŒíŒŒ ê³„ì‚° (ì°¨ë‹¨ ì£¼íŒŒìˆ˜ì—ì„œ ìŠ¤ë¬´ë”© íŒ©í„°)
    _alpha(cutoff, dt) {
        const tau = 1.0 / (2 * Math.PI * cutoff);
        return 1.0 / (1.0 + tau / dt);
    }

    // Exponential smoothing (ì§€ìˆ˜ í‰í™œ)
    _exponentialSmoothing(alpha, x, xPrev) {
        return alpha * x + (1 - alpha) * xPrev;
    }

    /**
     * ê°’ í•„í„°ë§
     * @param {number} x - ì…ë ¥ê°’
     * @param {number} timestamp - íƒ€ì„ìŠ¤íƒ¬í”„ (ms). nullì´ë©´ performance.now() ì‚¬ìš©
     * @returns {number} í•„í„°ë§ëœ ê°’
     */
    filter(x, timestamp = null) {
        // NaN/Infinity ê²€ì¦
        if (!Number.isFinite(x)) {
            console.warn('âš ï¸ OneEuroFilter received invalid input:', x);
            return this.xPrev !== null ? this.xPrev : x;
        }

        const now = timestamp !== null ? timestamp : performance.now();

        // ì²« ë²ˆì§¸ ê°’
        if (this.xPrev === null) {
            this.xPrev = x;
            this.dxPrev = 0;
            this.tPrev = now;
            return x;
        }

        // dt ê³„ì‚° (ì´ˆ ë‹¨ìœ„)
        let dt = (now - this.tPrev) / 1000;

        // dtê°€ 0ì´ê±°ë‚˜ ë„ˆë¬´ ì‘ìœ¼ë©´ ìµœì†Œê°’ ì‚¬ìš©
        if (dt <= 0) dt = 0.001;
        // dtê°€ ë„ˆë¬´ í¬ë©´ (0.5ì´ˆ ì´ìƒ) ë¦¬ì…‹
        if (dt > 0.5) {
            this.xPrev = x;
            this.dxPrev = 0;
            this.tPrev = now;
            return x;
        }

        this.tPrev = now;

        // 1ë‹¨ê³„: ë¯¸ë¶„ê°’(ì†ë„) ì¶”ì • ë° í•„í„°ë§
        const dx = (x - this.xPrev) / dt;
        const alphaDx = this._alpha(this.dCutoff, dt);
        const dxFiltered = this._exponentialSmoothing(alphaDx, dx, this.dxPrev);
        this.dxPrev = dxFiltered;

        // 2ë‹¨ê³„: ì ì‘í˜• ì°¨ë‹¨ ì£¼íŒŒìˆ˜ ê³„ì‚°
        // ì†ë„ê°€ ë¹ ë¥´ë©´ cutoffê°€ ë†’ì•„ì ¸ì„œ ë¹ ë¥´ê²Œ ë°˜ì‘
        const cutoff = this.minCutoff + this.beta * Math.abs(dxFiltered);

        // 3ë‹¨ê³„: ì‹ í˜¸ í•„í„°ë§
        const alphaX = this._alpha(cutoff, dt);
        const xFiltered = this._exponentialSmoothing(alphaX, x, this.xPrev);
        this.xPrev = xFiltered;

        return xFiltered;
    }

    // í•„í„° ë¦¬ì…‹
    reset() {
        this.xPrev = null;
        this.dxPrev = 0;
        this.tPrev = null;
    }

    // í˜„ì¬ ìƒíƒœ ë°˜í™˜ (ë””ë²„ê·¸ìš©)
    getState() {
        return {
            xPrev: this.xPrev,
            dxPrev: this.dxPrev,
            tPrev: this.tPrev
        };
    }

    // íŒŒë¼ë¯¸í„° ë™ì  ì¡°ì •
    setParameters(minCutoff = null, beta = null, dCutoff = null) {
        if (minCutoff !== null) this.minCutoff = minCutoff;
        if (beta !== null) this.beta = beta;
        if (dCutoff !== null) this.dCutoff = dCutoff;
    }
}

/**
 * 2D One Euro Filter (X, Y ë…ë¦½ í•„í„°ë§)
 * ì‹œì„  ì¶”ì ì— ìµœì í™”ëœ ê¸°ë³¸ê°’ ì‚¬ìš©
 */
class OneEuroFilter2D {
    /**
     * @param {number} minCutoff - ìµœì†Œ ì°¨ë‹¨ ì£¼íŒŒìˆ˜ (ê¸°ë³¸: 1.0 - ì•ˆì •ì  ìŠ¤ë¬´ë”©)
     * @param {number} beta - ì†ë„ ê°€ì¤‘ì¹˜ (ê¸°ë³¸: 0.0005 - ì‹œì„  ì¶”ì ì— ìµœì í™”)
     */
    constructor(minCutoff = 1.0, beta = 0.0005) {
        this.xFilter = new OneEuroFilter(minCutoff, beta);
        this.yFilter = new OneEuroFilter(minCutoff, beta);
    }

    /**
     * 2D ì¢Œí‘œ í•„í„°ë§
     * @param {number} x - X ì¢Œí‘œ
     * @param {number} y - Y ì¢Œí‘œ
     * @param {number} timestamp - íƒ€ì„ìŠ¤íƒ¬í”„ (ms)
     * @returns {{x: number, y: number}} í•„í„°ë§ëœ ì¢Œí‘œ
     */
    filter(x, y, timestamp = null) {
        const now = timestamp !== null ? timestamp : performance.now();
        return {
            x: this.xFilter.filter(x, now),
            y: this.yFilter.filter(y, now)
        };
    }

    // í•„í„° ë¦¬ì…‹
    reset() {
        this.xFilter.reset();
        this.yFilter.reset();
    }

    // í˜„ì¬ ìƒíƒœ ë°˜í™˜ (ë””ë²„ê·¸ìš©)
    getState() {
        return {
            x: this.xFilter.getState(),
            y: this.yFilter.getState()
        };
    }

    // íŒŒë¼ë¯¸í„° ë™ì  ì¡°ì •
    setParameters(minCutoff = null, beta = null) {
        this.xFilter.setParameters(minCutoff, beta);
        this.yFilter.setParameters(minCutoff, beta);
    }
}

// ========== ìŠ¤ë¬´ë”© í•„í„° íƒ€ì… ì„¤ì • ==========
// 'KALMAN': Kalman Filter (ìœ„ì¹˜+ì†ë„ ê¸°ë°˜ ì˜ˆì¸¡, ì•ˆì •ì ì´ì§€ë§Œ ì§€ì—° ìˆìŒ)
// 'ONE_EURO': One Euro Filter (ì ì‘í˜• ì €ì—­ í†µê³¼, ë¹ ë¥¸ ë°˜ì‘ + ìŠ¤ë¬´ë”©)
const SMOOTHING_FILTER_TYPE = 'ONE_EURO'; // 'KALMAN' ë˜ëŠ” 'ONE_EURO'

export const useMediaPipeTracking = (problemId, isActive = false, timeLimitMinutes = 30) => {
    // ê¸°ë³¸ ìƒíƒœ
    const [isCalibrated, setIsCalibrated] = useState(false);
    const [isTracking, setIsTracking] = useState(false);
    const [sessionId, setSessionId] = useState(null);
    const sessionIdRef = useRef(null); // Ref for synchronous access in trackingLoop

    // NO_FACE ìƒíƒœ
    const noFaceStartTimeRef = useRef(null);
    const [noFaceDuration, setNoFaceDuration] = useState(0);
    const [showNoFaceWarning, setShowNoFaceWarning] = useState(false);
    const warningShownRef = useRef(false);
    const sustainedViolationSentRef = useRef(false);

    // ë””ë²„ê·¸ ëª¨ë“œ
    const [debugMode, setDebugMode] = useState(false);
    const debugModeRef = useRef(false); // tracking loopì—ì„œ ì‚¬ìš©í•  ref
    const [isFaceDetected, setIsFaceDetected] = useState(true);

    // MediaPipe ê´€ë ¨ ìƒíƒœ
    const faceLandmarkerRef = useRef(null);
    const videoRef = useRef(null);
    const streamRef = useRef(null); // MediaStream ì§ì ‘ ì°¸ì¡° (cleanupìš©)
    const canvasRef = useRef(null);
    const animationFrameRef = useRef(null);
    const isCleaningUpRef = useRef(false);

    // ì¶”ê°€ ê¸°ëŠ¥ ìƒíƒœ - UI í‘œì‹œìš© (throttled update)
    const [detectedFaces, setDetectedFaces] = useState([]); // ë‹¤ì¤‘ ì¸ë¬¼
    const [faceCount, setFaceCount] = useState(0);
    const [headPose, setHeadPose] = useState({ pitch: 0, yaw: 0, roll: 0 }); // 3D ì–¼êµ´ ë°©í–¥
    const [gazePosition, setGazePosition] = useState({ x: window.innerWidth / 2, y: window.innerHeight / 2 }); // ì‹œì„  ìœ„ì¹˜ (í´ë¨í•‘ë¨)
    const [rawGazePosition, setRawGazePosition] = useState({ x: window.innerWidth / 2, y: window.innerHeight / 2 }); // ì‹œì„  ìœ„ì¹˜ (í´ë¨í•‘ ì „, ì§‘ì¤‘ë„ íŒë‹¨ìš©)
    const [eyeState, setEyeState] = useState({ leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false });
    const [irisPosition, setIrisPosition] = useState({ left: null, right: null });

    // ì¡¸ìŒ ê°ì§€ ìƒíƒœ
    const [drowsinessState, setDrowsinessState] = useState({
        isDrowsy: false,
        perclos: 0,
        consecutiveClosedFrames: 0
    });
    const closedFrameCountRef = useRef(0);
    const earHistoryRef = useRef([]); // PERCLOS ê³„ì‚°ìš©
    const drowsyViolationSentRef = useRef(false);

    // ========== Gaze Away (ì‹œì„  ì´íƒˆ) ìœ„ë°˜ ì¶”ì  ==========
    const lastGazeAwayViolationTimeRef = useRef(0); // ë§ˆì§€ë§‰ GAZE_AWAY ì „ì†¡ ì‹œê°„
    const GAZE_AWAY_THROTTLE_MS = 5000; // 5ì´ˆë§ˆë‹¤ ìµœëŒ€ 1íšŒ ì „ì†¡

    // ========== Liveness Detection (ì‚¬ì§„/ì˜ìƒ ê°ì§€) ==========
    // ëˆˆ ê¹œë¹¡ì„ì´ ì¼ì • ì‹œê°„ ë™ì•ˆ ì—†ìœ¼ë©´ ì‚¬ì§„/ì˜ìƒìœ¼ë¡œ íŒì •
    const LIVENESS_BLINK_TIMEOUT_MS = 30000; // 30ì´ˆ ë™ì•ˆ ëˆˆ ê¹œë¹¡ì„ ì—†ìœ¼ë©´ ê²½ê³ 
    const lastBlinkTimeRef = useRef(Date.now()); // ë§ˆì§€ë§‰ ëˆˆ ê¹œë¹¡ì„ ì‹œê°„
    const wasBlinkingRef = useRef(false); // ì´ì „ í”„ë ˆì„ ëˆˆ ê°ê¹€ ìƒíƒœ
    const [livenessWarning, setLivenessWarning] = useState(false); // ì‚¬ì§„ ê°ì§€ ê²½ê³ 
    const livenessWarningRef = useRef(false); // trackingLoopì—ì„œ ì‚¬ìš© (ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
    const livenessViolationSentRef = useRef(false); // Liveness ìœ„ë°˜ ì „ì†¡ ì—¬ë¶€ (1íšŒë§Œ)
    const multipleFacesViolationSentRef = useRef(false); // ë‹¤ì¤‘ì¸ë¬¼ ìœ„ë°˜ ì „ì†¡ ì—¬ë¶€ (1íšŒë§Œ)

    // ê³ ë¹ˆë„ ë°ì´í„°ë¥¼ ìœ„í•œ refs (setState í˜¸ì¶œ ìµœì†Œí™” - Maximum update depth ë°©ì§€)
    const latestDataRef = useRef({
        isFaceDetected: false,
        faceCount: 0,
        detectedFaces: [],
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        gazePosition: { x: window.innerWidth / 2, y: window.innerHeight / 2 },
        rawGazePosition: { x: window.innerWidth / 2, y: window.innerHeight / 2 },
        eyeState: { leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false },
        irisPosition: { left: null, right: null },
        drowsinessState: { isDrowsy: false, perclos: 0, consecutiveClosedFrames: 0 },
        noFaceDuration: 0,
        showNoFaceWarning: false
    });
    const lastStateUpdateRef = useRef(0);
    const STATE_UPDATE_INTERVAL_MS = 100; // 100msë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (10fps - UIì— ì¶©ë¶„)

    // ========== 3-Point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ==========
    // MediaPipeCalibrationScreenì—ì„œ ì „ë‹¬ë°›ì€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°
    const calibrationDataRef = useRef(null);
    const hasManualCalibrationRef = useRef(false); // ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì—¬ë¶€

    // ========== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (Baseline) - ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ì„ ë•Œ í´ë°± ==========
    // ì‹œì‘ í›„ ì²˜ìŒ ëª‡ í”„ë ˆì„ì˜ í‰ê· ê°’ì„ ê¸°ì¤€ì ìœ¼ë¡œ ì €ì¥
    const CALIBRATION_FRAMES = 30; // 30í”„ë ˆì„ (~1ì´ˆ) ë™ì•ˆ í‰ê·  ê³„ì‚°
    const isBaselineCalibratedRef = useRef(false);
    const baselineRef = useRef({
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        irisOffset: { x: 0, y: 0 } // ì •ë©´ ë³¼ ë•Œ í™ì±„ ì˜¤í”„ì…‹
    });
    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ ëˆ„ì ê°’
    const calibrationAccumulatorRef = useRef({
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        irisOffset: { x: 0, y: 0 },
        count: 0
    });

    // ========== ê¹œë¹¡ì„ ì‹œ gaze ë™ê²°ì„ ìœ„í•œ ë§ˆì§€ë§‰ ìœ íš¨ ìœ„ì¹˜ ==========
    const lastValidGazeRef = useRef({ x: window.innerWidth / 2, y: window.innerHeight / 2 });

    // ========== ìŠ¤ë¬´ë”© í•„í„° (Kalman / One Euro ì„ íƒ ê°€ëŠ¥) ==========
    // SMOOTHING_FILTER_TYPE ìƒìˆ˜ì— ë”°ë¼ í•„í„° íƒ€ì… ê²°ì •
    const smoothingFilterRef = useRef(null);
    const filterTypeRef = useRef(SMOOTHING_FILTER_TYPE); // í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í•„í„° íƒ€ì…

    // ìŠ¤ë¬´ë”© í•„í„° ì´ˆê¸°í™” (lazy initialization)
    const getSmoothingFilter = useCallback(() => {
        if (!smoothingFilterRef.current) {
            if (SMOOTHING_FILTER_TYPE === 'KALMAN') {
                smoothingFilterRef.current = new KalmanFilter2D();
                console.log('âœ… Kalman Filter initialized');
            } else {
                // ê¸°ë³¸: One Euro Filter (ì‹œì„  ì¶”ì ì— ìµœì í™”ëœ íŒŒë¼ë¯¸í„°)
                // minCutoff: 4.0 (ë†’ì„ìˆ˜ë¡ ë¹ ë¥¸ ë°˜ì‘) - ì‹¤ì‹œê°„ ë°˜ì‘ì„ ìœ„í•´ ëŒ€í­ ì¦ê°€
                // beta: 1.2 (ì†ë„ ì ì‘ - ë¹ ë¥¸ ì›€ì§ì„ì— ì¦‰ì‹œ ë°˜ì‘)
                smoothingFilterRef.current = new OneEuroFilter2D(4.0, 1.2);
                console.log('âœ… One Euro Filter initialized (minCutoff=4.0, beta=1.2)');
            }
            filterTypeRef.current = SMOOTHING_FILTER_TYPE;
        }
        return smoothingFilterRef.current;
    }, []);

    // ========== ì–¼êµ´ ê°ì§€ ì•ˆì •í™” (ë””ë°”ìš´ì‹±) ==========
    // ì—°ì† Ní”„ë ˆì„ ë™ì•ˆ ê°™ì€ ìƒíƒœì—¬ì•¼ ë³€ê²½
    const FACE_DETECTION_DEBOUNCE_FRAMES = 3; // 3í”„ë ˆì„ ì—°ì† í•„ìš”
    const faceDetectionCounterRef = useRef({ detected: 0, notDetected: 0 });
    const stableFaceDetectedRef = useRef(false);

    // drawDebugOverlayë¥¼ refë¡œ ê´€ë¦¬ (ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
    const drawDebugOverlayRef = useRef(null);

    // MediaPipe FaceLandmarker ì´ˆê¸°í™”
    useEffect(() => {
        if (!isActive) return;

        const initMediaPipe = async () => {
            try {
                // MediaPipe Vision ë™ì  ë¡œë“œ
                const vision = await import('@mediapipe/tasks-vision');
                const { FaceLandmarker, FilesetResolver } = vision;

                // WASM íŒŒì¼ ë¡œë“œ
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
                );

                // FaceLandmarker ìƒì„±
                const faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                        delegate: 'GPU' // GPU ê°€ì† ì‚¬ìš©
                    },
                    outputFaceBlendshapes: true, // í‘œì • ë¶„ì„
                    outputFacialTransformationMatrixes: true, // 3D ë³€í™˜ í–‰ë ¬
                    runningMode: 'VIDEO',
                    numFaces: 5, // ìµœëŒ€ 5ëª… ê°ì§€
                    refineLandmarks: true // 468ê°œ ê¸°ë³¸ ëœë“œë§ˆí¬ + í™ì±„(Iris) ëœë“œë§ˆí¬(468-477) í™œì„±í™”
                });

                faceLandmarkerRef.current = faceLandmarker;
                console.log('âœ… MediaPipe FaceLandmarker initialized');
            } catch (error) {
                console.error('âŒ MediaPipe initialization failed:', error);
            }
        };

        initMediaPipe();

        return () => {
            if (faceLandmarkerRef.current) {
                faceLandmarkerRef.current.close();
                faceLandmarkerRef.current = null;
            }
        };
    }, [isActive]);

    // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì„¤ì •
    const setupWebcam = useCallback(async () => {
        try {
            // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ ë¨¼ì € ì •ë¦¬ (ì¤‘ë³µ ìŠ¤íŠ¸ë¦¼ ë°©ì§€)
            if (streamRef.current) {
                console.log('âš ï¸ Cleaning up existing stream before creating new one');
                const oldTracks = streamRef.current.getTracks();
                oldTracks.forEach(track => track.stop());
                streamRef.current = null;
            }
            if (videoRef.current) {
                videoRef.current.pause();
                if (videoRef.current.srcObject) {
                    videoRef.current.srcObject = null;
                }
                videoRef.current = null;
            }

            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                }
            });

            // ìŠ¤íŠ¸ë¦¼ ì§ì ‘ ì°¸ì¡° ì €ì¥ (cleanupìš©)
            streamRef.current = stream;

            // ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
            const video = document.createElement('video');
            video.id = 'mediapipeVideoFeed';
            video.srcObject = stream;
            video.autoplay = true;
            video.playsInline = true;
            video.muted = true;

            await new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    video.play();
                    resolve();
                };
            });

            videoRef.current = video;

            // ìº”ë²„ìŠ¤ ìƒì„± (ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ìš©)
            const canvas = document.createElement('canvas');
            canvas.id = 'mediapipeOverlay';
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvasRef.current = canvas;

            console.log('âœ… Webcam stream ready:', video.videoWidth, 'x', video.videoHeight);
            return true;
        } catch (error) {
            console.error('âŒ Webcam setup failed:', error);
            return false;
        }
    }, []);

    // 3D ì–¼êµ´ ë°©í–¥ ê³„ì‚° (Pitch, Yaw, Roll)
    const calculateHeadPose = useCallback((landmarks) => {
        if (!landmarks || landmarks.length === 0) return { pitch: 0, yaw: 0, roll: 0 };

        const noseTip = landmarks[LANDMARK_INDICES.NOSE_TIP];
        const chin = landmarks[LANDMARK_INDICES.CHIN];
        const leftEye = landmarks[LANDMARK_INDICES.LEFT_EYE_OUTER];
        const rightEye = landmarks[LANDMARK_INDICES.RIGHT_EYE_OUTER];

        // ëœë“œë§ˆí¬ ìœ íš¨ì„± ê²€ì¦
        if (!noseTip || !chin || !leftEye || !rightEye) {
            return { pitch: 0, yaw: 0, roll: 0 };
        }

        // Yaw (ì¢Œìš° íšŒì „) - ì½”ì™€ ì–‘ ëˆˆ ì¤‘ì‹¬ ë¹„êµ
        const eyeCenter = {
            x: (leftEye.x + rightEye.x) / 2,
            y: (leftEye.y + rightEye.y) / 2,
            z: ((leftEye.z || 0) + (rightEye.z || 0)) / 2
        };

        // ========== ë‹¨ìˆœ ëœë“œë§ˆí¬ ê¸°ë°˜ Head Pose ê³„ì‚° ==========
        // z ì¢Œí‘œê°€ ë¶ˆì•ˆì •í•˜ë¯€ë¡œ (ìŒìˆ˜ ê°’, ë¶€í˜¸ ë¬¸ì œ) x, y ì¢Œí‘œë§Œ ì‚¬ìš©

        let yaw = 0, pitch = 0, roll = 0;

        // Yaw (ì¢Œìš° íšŒì „): ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€
        // ì›¹ìº ì€ ë¯¸ëŸ¬ë§ë˜ë¯€ë¡œ ë°©í–¥ ë°˜ì „ í•„ìš”
        // ì™¼ìª½ íšŒì „: ì´ë¯¸ì§€ì—ì„œ ì½”ê°€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ â†’ xOffset > 0 â†’ yawëŠ” ìŒìˆ˜ì—¬ì•¼ í•¨
        // ì˜¤ë¥¸ìª½ íšŒì „: ì´ë¯¸ì§€ì—ì„œ ì½”ê°€ ì™¼ìª½ìœ¼ë¡œ â†’ xOffset < 0 â†’ yawëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•¨
        const xOffset = noseTip.x - eyeCenter.x;
        // ì •ê·œí™”ëœ ì¢Œí‘œì—ì„œ ì•½ 0.05 ì°¨ì´ = ì•½ 30ë„ íšŒì „ìœ¼ë¡œ ì¶”ì •
        yaw = -xOffset * 600; // ì›¹ìº  ë¯¸ëŸ¬ë§ ë³´ì • (ë¶€í˜¸ ë°˜ì „)

        // Pitch (ìƒí•˜ ê¸°ìš¸ê¸°): ì½”-í„± ê±°ë¦¬ ëŒ€ë¹„ ì½”ì˜ ìƒëŒ€ ìœ„ì¹˜
        // ì–¼êµ´ ë†’ì´ ì¶”ì • (ëˆˆ ì¤‘ì‹¬ ~ í„±)
        const faceHeight = chin.y - eyeCenter.y;
        // ì½”ê°€ ì–¼êµ´ ì¤‘ì•™ì—ì„œ ì–¼ë§ˆë‚˜ ìœ„/ì•„ë˜ì— ìˆëŠ”ì§€
        const noseRelativeY = (noseTip.y - eyeCenter.y) / (faceHeight || 0.001);
        // ì •ë©´ì¼ ë•Œ noseRelativeY â‰ˆ 0.35 (ì½”ëŠ” ëˆˆê³¼ í„± ì‚¬ì´ ì•½ 35% ìœ„ì¹˜)
        // ìœ„ë¡œ ê¸°ìš¸ì„: noseRelativeY < 0.35 â†’ pitch < 0
        // ì•„ë˜ë¡œ ê¸°ìš¸ì„: noseRelativeY > 0.35 â†’ pitch > 0
        const pitchOffset = noseRelativeY - 0.35;
        pitch = pitchOffset * 150; // ìŠ¤ì¼€ì¼ ì¡°ì •

        // Roll (ê¸°ìš¸ê¸°) - ì–‘ ëˆˆì˜ ë†’ì´ ì°¨ì´
        roll = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x) * (180 / Math.PI);

        // ë””ë²„ê·¸: ì›ì‹œ head pose ê°’ í™•ì¸ (í•œ ë²ˆë§Œ, ì„¸ì…˜ë§ˆë‹¤ ë¦¬ì…‹)
        if (!window._headPoseDebugLoggedV2) {
            console.log('ğŸ” Head Pose (Landmark-based):', {
                pitch: pitch.toFixed(1) + 'Â°',
                yaw: yaw.toFixed(1) + 'Â°',
                roll: roll.toFixed(1) + 'Â°',
                xOffset: xOffset.toFixed(4),
                noseRelativeY: noseRelativeY.toFixed(3),
                faceHeight: faceHeight.toFixed(3)
            });
            window._headPoseDebugLoggedV2 = true;
        }

        // NaN ê²€ì¦ ë° ë²”ìœ„ í´ë¨í•‘ (ì‹¤ì œ ë¨¸ë¦¬ íšŒì „ ë²”ìœ„: ì•½ Â±60ë„)
        const MAX_ANGLE = 60;
        if (!Number.isFinite(pitch)) pitch = 0;
        if (!Number.isFinite(yaw)) yaw = 0;
        if (!Number.isFinite(roll)) roll = 0;

        pitch = Math.max(-MAX_ANGLE, Math.min(MAX_ANGLE, pitch));
        yaw = Math.max(-MAX_ANGLE, Math.min(MAX_ANGLE, yaw));
        roll = Math.max(-MAX_ANGLE, Math.min(MAX_ANGLE, roll));

        return { pitch, yaw, roll };
    }, []);

    // ========== 3D ë²¡í„° ê¸°ë°˜ ì‹œì„  ì¶”ì • ==========
    // MediaPipeì˜ 3D ì¢Œí‘œ(x, y, z)ë¥¼ í™œìš©í•˜ì—¬ ì‹œì„  ë²¡í„°ë¥¼ ê³„ì‚°í•˜ê³  í™”ë©´ì— íˆ¬ì˜
    const estimateGazeFromIris = useCallback((landmarks, videoWidth, videoHeight, headPose = null) => {
        if (!landmarks || landmarks.length < 478) return { x: window.innerWidth / 2, y: window.innerHeight / 2 };

        // ========== 3D ì¢Œí‘œ ì¶”ì¶œ ==========
        // ì™¼ìª½ í™ì±„ ì¤‘ì‹¬ (3D)
        const leftIris3D = landmarks[LANDMARK_INDICES.LEFT_IRIS[0]];
        // ì˜¤ë¥¸ìª½ í™ì±„ ì¤‘ì‹¬ (3D)
        const rightIris3D = landmarks[LANDMARK_INDICES.RIGHT_IRIS[0]];

        // ì™¼ìª½/ì˜¤ë¥¸ìª½ ëˆˆì˜ ê²½ê³„ (3D)
        const leftEyeLeft3D = landmarks[LANDMARK_INDICES.LEFT_EYE.P1];
        const leftEyeRight3D = landmarks[LANDMARK_INDICES.LEFT_EYE.P4];
        const rightEyeLeft3D = landmarks[LANDMARK_INDICES.RIGHT_EYE.P1];
        const rightEyeRight3D = landmarks[LANDMARK_INDICES.RIGHT_EYE.P4];

        // ========== í™ì±„ ìƒëŒ€ ìœ„ì¹˜ ê³„ì‚° (ëˆˆ ê²½ê³„ ê¸°ì¤€) ==========
        // ì •ê·œí™” ëŒ€ì‹  ëˆˆ í­/ë†’ì´ ëŒ€ë¹„ í™ì±„ ìœ„ì¹˜ ë¹„ìœ¨ ì‚¬ìš© (ë” ì •í™•í•œ ì‹œì„  ì¶”ì •)

        // ì™¼ìª½ ëˆˆ: í™ì±„ê°€ ëˆˆ ì¢Œìš° ëì  ì‚¬ì´ì—ì„œ ì–´ë””ì— ìˆëŠ”ì§€ (0=ì™¼ìª½ ë, 1=ì˜¤ë¥¸ìª½ ë)
        const leftEyeWidth = Math.abs(leftEyeRight3D.x - leftEyeLeft3D.x) || 0.001;
        const leftIrisRatioX = (leftIris3D.x - leftEyeLeft3D.x) / leftEyeWidth;

        // ì˜¤ë¥¸ìª½ ëˆˆ: ë™ì¼í•˜ê²Œ ê³„ì‚°
        const rightEyeWidth = Math.abs(rightEyeRight3D.x - rightEyeLeft3D.x) || 0.001;
        const rightIrisRatioX = (rightIris3D.x - rightEyeLeft3D.x) / rightEyeWidth;

        // ì–‘ìª½ ëˆˆ í‰ê·  (0.5ê°€ ì •ë©´, <0.5 ì™¼ìª½ ì‘ì‹œ, >0.5 ì˜¤ë¥¸ìª½ ì‘ì‹œ)
        const irisRatioX = (leftIrisRatioX + rightIrisRatioX) / 2;

        // Yì¶•: ëˆˆ ìƒí•˜ ë†’ì´ ëŒ€ë¹„ í™ì±„ ìœ„ì¹˜ (ìƒë‹¨/í•˜ë‹¨ ëœë“œë§ˆí¬ ì‚¬ìš©)
        const leftEyeTop3D = landmarks[LANDMARK_INDICES.LEFT_EYE.P2];
        const leftEyeBottom3D = landmarks[LANDMARK_INDICES.LEFT_EYE.P5];
        const rightEyeTop3D = landmarks[LANDMARK_INDICES.RIGHT_EYE.P2];
        const rightEyeBottom3D = landmarks[LANDMARK_INDICES.RIGHT_EYE.P5];

        const leftEyeHeight = Math.abs(leftEyeBottom3D.y - leftEyeTop3D.y) || 0.001;
        const leftIrisRatioY = (leftIris3D.y - leftEyeTop3D.y) / leftEyeHeight;

        const rightEyeHeight = Math.abs(rightEyeBottom3D.y - rightEyeTop3D.y) || 0.001;
        const rightIrisRatioY = (rightIris3D.y - rightEyeTop3D.y) / rightEyeHeight;

        const irisRatioY = (leftIrisRatioY + rightIrisRatioY) / 2;

        // ========== ê¹œë¹¡ì„ ê°ì§€ - gaze ë™ê²° ==========
        // ëˆˆ ë†’ì´ê°€ ì‘ìœ¼ë©´ (ëˆˆ ê°ìŒ) ë§ˆì§€ë§‰ ìœ íš¨ gaze ë°˜í™˜
        const BLINK_HEIGHT_THRESHOLD = 0.015; // ëˆˆ ë†’ì´ê°€ ì´ ê°’ ì´í•˜ë©´ ê¹œë¹¡ì„ìœ¼ë¡œ íŒë‹¨
        const avgEyeHeight = (leftEyeHeight + rightEyeHeight) / 2;

        if (avgEyeHeight < BLINK_HEIGHT_THRESHOLD) {
            // ê¹œë¹¡ì„ ì¤‘ - ë§ˆì§€ë§‰ ìœ íš¨ ìœ„ì¹˜ ë°˜í™˜ (ì í”„ ë°©ì§€)
            return lastValidGazeRef.current;
        }

        // ì •ê·œí™”ëœ ì‹œì„  ë²¡í„° (0.5 ì¤‘ì‹¬, ë²”ìœ„ ì•½ 0.3~0.7)
        // X: 0.5ë³´ë‹¤ ì‘ìœ¼ë©´ ì™¼ìª½, í¬ë©´ ì˜¤ë¥¸ìª½ (ì›¹ìº  ë¯¸ëŸ¬ë§ ê³ ë ¤)
        // Y: 0.5ë³´ë‹¤ ì‘ìœ¼ë©´ ìœ„ìª½, í¬ë©´ ì•„ë˜ìª½
        const normalizedGaze = {
            x: irisRatioX - 0.5,  // -0.2 ~ +0.2 ë²”ìœ„ë¡œ ë³€í™˜ (ì¤‘ì‹¬=0)
            y: irisRatioY - 0.5,
            z: 0  // 2D ë¹„ìœ¨ ê¸°ë°˜ì´ë¯€ë¡œ zëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        };

        // ========== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (baseline ì €ì¥) ==========
        // ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ìˆìœ¼ë©´ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê±´ë„ˆë›°ê¸°
        if (!isBaselineCalibratedRef.current && !hasManualCalibrationRef.current && headPose) {
            const acc = calibrationAccumulatorRef.current;
            acc.headPose.pitch += headPose.pitch;
            acc.headPose.yaw += headPose.yaw;
            acc.headPose.roll += headPose.roll;
            // 3D ë²¡í„° ëˆ„ì 
            acc.irisOffset.x += normalizedGaze.x;
            acc.irisOffset.y += normalizedGaze.y;
            acc.count++;

            if (acc.count >= CALIBRATION_FRAMES) {
                baselineRef.current = {
                    headPose: {
                        pitch: acc.headPose.pitch / acc.count,
                        yaw: acc.headPose.yaw / acc.count,
                        roll: acc.headPose.roll / acc.count
                    },
                    irisOffset: {
                        x: acc.irisOffset.x / acc.count,
                        y: acc.irisOffset.y / acc.count
                    }
                };
                isBaselineCalibratedRef.current = true;
                console.log('âœ… 3D Gaze baseline calibration complete:', baselineRef.current);
            }

            return { x: window.innerWidth / 2, y: window.innerHeight / 2 };
        }

        // ========== 3-Point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‚¬ìš© (ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì‹œ) ==========
        if (hasManualCalibrationRef.current && calibrationDataRef.current) {
            const calibData = calibrationDataRef.current;
            const baseline = calibData.baseline;

            // 3D ë²¡í„° ê¸°ë°˜ ìƒëŒ€ê°’ (ë² ì´ìŠ¤ë¼ì¸ì€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ ê°€ì ¸ì˜´)
            const deltaGazeX = normalizedGaze.x - baseline.irisOffset.x;
            const deltaGazeY = normalizedGaze.y - baseline.irisOffset.y;

            // ========== ê³ ì • ë¯¼ê°ë„ ì‚¬ìš© (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë¯¼ê°ë„ ëŒ€ì‹ ) ==========
            // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ ê³„ì‚°ëœ ë¯¼ê°ë„ëŠ” X/Y ë¶ˆê· í˜•ì´ ì‹¬í•´ì„œ ê³ ì •ê°’ ì‚¬ìš©
            // í™ì±„ ë¹„ìœ¨ ë²”ìœ„: ì•½ -0.05 ~ +0.05 (ì¤‘ì‹¬=0)
            // ê°ë„ 6.0 = í™ì±„ê°€ 0.05 ì´ë™ ì‹œ í™”ë©´ 30% ì´ë™ (0.05 * 6.0 = 0.3)
            const FIXED_GAZE_SENSITIVITY_X = 6.0; // Xì¶• (ì¢Œìš°) - 3.5â†’6.0 ì¦ê°€
            const FIXED_GAZE_SENSITIVITY_Y = 10.0; // Yì¶• (ìƒí•˜) - Y ê°ì§€ê°€ ì•½í•´ì„œ ë” ë†’ê²Œ (3.5â†’10.0)

            // í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜ (ê³ ì • ë¯¼ê°ë„ ì‚¬ìš©)
            // Xì¶•: ì›¹ìº  ë¯¸ëŸ¬ë§ìœ¼ë¡œ ì¸í•´ ë°˜ì „ í•„ìš” (í™ì±„ê°€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê°€ë©´ ì‹œì„ ì€ ì™¼ìª½)
            let rawGazeX = baseline.screenX - deltaGazeX * window.innerWidth * FIXED_GAZE_SENSITIVITY_X;
            let rawGazeY = baseline.screenY + deltaGazeY * window.innerHeight * FIXED_GAZE_SENSITIVITY_Y;
            
            // Raw gaze í´ë¨í•‘ (í™”ë©´ ë°–ìœ¼ë¡œ ë„ˆë¬´ ë©€ë¦¬ ë‚˜ê°€ì§€ ì•Šë„ë¡ - í•„í„° ì•ˆì •ì„±)
            const SCREEN_MARGIN = 100; // í™”ë©´ ë°– 100pxê¹Œì§€ë§Œ í—ˆìš© (500â†’100 ì¶•ì†Œ)
            rawGazeX = Math.max(-SCREEN_MARGIN, Math.min(rawGazeX, window.innerWidth + SCREEN_MARGIN));
            rawGazeY = Math.max(-SCREEN_MARGIN, Math.min(rawGazeY, window.innerHeight + SCREEN_MARGIN));

            // ìŠ¤ë¬´ë”© í•„í„° ì ìš© (Kalman / One Euro)
            const smoother = getSmoothingFilter();
            const filtered = smoother.filter(rawGazeX, rawGazeY);

            // ë””ë²„ê·¸: ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²½ë¡œ ê°’ í™•ì¸ (10% í™•ë¥ ë¡œ ì¶œë ¥)
            if (Math.random() < 0.10) {
                // í™ì±„ ê¸°ì—¬ë„ ê³„ì‚° (ê³ ì • ë¯¼ê°ë„ ì‚¬ìš©)
                const irisContribX = deltaGazeX * window.innerWidth * FIXED_GAZE_SENSITIVITY_X;
                const irisContribY = deltaGazeY * window.innerHeight * FIXED_GAZE_SENSITIVITY_Y;

                console.log('ğŸ” [Manual Calib] Gaze Debug:', {
                    irisRatio: { x: irisRatioX.toFixed(3), y: irisRatioY.toFixed(3) },
                    deltaIris: { x: deltaGazeX.toFixed(4), y: deltaGazeY.toFixed(4) },
                    sensitivity: { sX: FIXED_GAZE_SENSITIVITY_X, sY: FIXED_GAZE_SENSITIVITY_Y },
                    contrib: { irisX: Math.round(irisContribX), irisY: Math.round(irisContribY) },
                    raw: { x: Math.round(rawGazeX), y: Math.round(rawGazeY) },
                    filtered: { x: Math.round(filtered.x), y: Math.round(filtered.y) }
                });
            }

            // í´ë¨í•‘ ì „ ì›ì‹œ ì¢Œí‘œ (ì§‘ì¤‘ë„ íŒë‹¨ìš©)
            const rawGazeResult = { x: filtered.x, y: filtered.y };

            // í´ë¨í•‘ëœ ì¢Œí‘œ (ì‹œì„ ì  í‘œì‹œìš©)
            const gazeResult = {
                x: Math.max(0, Math.min(filtered.x, window.innerWidth)),
                y: Math.max(0, Math.min(filtered.y, window.innerHeight))
            };
            // ë§ˆì§€ë§‰ ìœ íš¨ gaze ì €ì¥ (ê¹œë¹¡ì„ ì‹œ ì‚¬ìš©)
            lastValidGazeRef.current = gazeResult;
            return { clamped: gazeResult, raw: rawGazeResult };
        }

        // ========== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ: baseline ê¸°ì¤€ ìƒëŒ€ê°’ ==========
        const baseline = baselineRef.current;

        // 3D ì‹œì„  ë²¡í„°ì˜ ìƒëŒ€ì  ë³€í™”
        const relativeGazeX = normalizedGaze.x - baseline.irisOffset.x;
        const relativeGazeY = normalizedGaze.y - baseline.irisOffset.y;

        // ë¨¸ë¦¬ íšŒì „ ë³´ì • (ëœë“œë§ˆí¬ ê¸°ë°˜ head pose ì‚¬ìš©)
        // ë¨¸ë¦¬ê°€ íšŒì „í•˜ë©´ í™ì±„ê°€ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ëŠ” ê²ƒì„ ìƒì‡„
        let headCompensationX = 0;
        let headCompensationY = 0;

        if (headPose && baseline.headPose) {
            const relativeYaw = headPose.yaw - baseline.headPose.yaw;
            const relativePitch = headPose.pitch - baseline.headPose.pitch;

            // ë¨¸ë¦¬ íšŒì „ì„ ìƒì‡„ (ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ë³´ì •)
            // ë¨¸ë¦¬ê°€ ì˜¤ë¥¸ìª½(+yaw)ìœ¼ë¡œ ëŒë©´ â†’ í™ì±„ê°€ ì™¼ìª½ìœ¼ë¡œ ë³´ì„ â†’ ì‹œì„ ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë³´ì •
            const HEAD_WEIGHT_X = 0.015; // ë¨¸ë¦¬ íšŒì „ 1ë„ë‹¹ í™”ë©´ 1.5% ì´ë™
            const HEAD_WEIGHT_Y = 0.010; // pitch ë³´ì • (Yì¶•)
            headCompensationX = relativeYaw * HEAD_WEIGHT_X;  // ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë³´ì • (ë°˜ì „ ì—†ìŒ)
            headCompensationY = relativePitch * HEAD_WEIGHT_Y;
        }

        // ========== 3D ë²¡í„°ë¥¼ í™”ë©´ ì¢Œí‘œë¡œ íˆ¬ì˜ ==========
        // ì‹œì„  ë²¡í„°ë¥¼ í™”ë©´ì— íˆ¬ì˜ (ê³ ì • ê°ë„ ë°©ì‹)

        // ì‹œì„  ê°ë„ (í™ì±„ ë¹„ìœ¨ â†’ í™”ë©´ í”½ì…€)
        // X/Y ë™ì¼í•œ ë¯¼ê°ë„ë¡œ ê· í˜• ë§ì¶¤, ì•„ë˜ ì‘ì‹œëŠ” head pitchë¡œ ë³´ì™„
        const GAZE_SENSITIVITY_X = 6.0;  // Xì¶• (ì¢Œìš°)
        const GAZE_SENSITIVITY_Y = 6.0;  // Yì¶• (ìƒí•˜) - 10.0â†’6.0 ê°ì†Œ (Y íŠ ê°ì†Œ)

        // Yì¶• ë°ë“œì¡´: ì‘ì€ Y ë³€í™”ëŠ” ë¬´ì‹œí•˜ì—¬ íŠ ê°ì†Œ
        // relativeYê°€ Â±0.01 ì´ë‚´ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬ (ì¤‘ì•™ ì‘ì‹œ ì‹œ íŠ ë°©ì§€)
        const Y_DEADZONE = 0.01;
        let stabilizedRelativeY = relativeGazeY;
        if (Math.abs(relativeGazeY) < Y_DEADZONE) {
            stabilizedRelativeY = 0;
        } else {
            // ë°ë“œì¡´ ë²”ìœ„ë§Œí¼ ê°’ì„ ì¤„ì—¬ì„œ ë¶€ë“œëŸ¬ìš´ ì „í™˜
            stabilizedRelativeY = relativeGazeY > 0
                ? relativeGazeY - Y_DEADZONE
                : relativeGazeY + Y_DEADZONE;
        }

        // Yì¶•: í™ì±„ ì¶”ì  + head pitch ê²°í•©
        // ì•„ë˜ë¥¼ ë³¼ ë•Œ í™ì±„ ì¶”ì ì´ ì˜ ì•ˆë˜ë¯€ë¡œ head pitchì— ë” ì˜ì¡´
        let adjustedRelativeY = stabilizedRelativeY;
        if (headPose && baseline.headPose) {
            const relativePitch = headPose.pitch - baseline.headPose.pitch;
            // pitchê°€ ì–‘ìˆ˜ë©´ (ë¨¸ë¦¬ê°€ ì•„ë˜ë¡œ) Yë¥¼ ì¦ê°€ (í™”ë©´ ì•„ë˜ìª½ìœ¼ë¡œ)
            // pitch ê¸°ì—¬ë„: pitch 5ë„ = í™”ë©´ 25% ì´ë™
            const pitchContribution = relativePitch * 0.05;
            adjustedRelativeY += pitchContribution;
        }

        // ìµœì¢… ì‹œì„  ìœ„ì¹˜ ê³„ì‚°
        const rawGazeX = window.innerWidth / 2
            - relativeGazeX * window.innerWidth * GAZE_SENSITIVITY_X  // ì¢Œìš° ë°˜ì „ (ì›¹ìº  ë¯¸ëŸ¬ë§)
            + headCompensationX * window.innerWidth;                   // ë¨¸ë¦¬ íšŒì „ ê¸°ì—¬

        const rawGazeY = window.innerHeight / 2
            + adjustedRelativeY * window.innerHeight * GAZE_SENSITIVITY_Y  // í™ì±„ + pitch ê²°í•©
            + headCompensationY * window.innerHeight;                      // ë¨¸ë¦¬ íšŒì „ ê¸°ì—¬

        // ========== ìŠ¤ë¬´ë”© í•„í„° ì ìš© (Kalman / One Euro) ==========
        const smoother = getSmoothingFilter();
        const filtered = smoother.filter(rawGazeX, rawGazeY);

        // ë””ë²„ê·¸: ê°’ í™•ì¸ (10% ìƒ˜í”Œë§)
        if (Math.random() < 0.10) {
            const relativePitch = headPose && baseline.headPose
                ? headPose.pitch - baseline.headPose.pitch
                : 0;
            console.log('ğŸ” Gaze Debug:', {
                irisRatio: { x: irisRatioX.toFixed(3), y: irisRatioY.toFixed(3) },
                relativeY: `${relativeGazeY.toFixed(4)} + pitch ${(relativePitch * 0.005).toFixed(4)} = ${adjustedRelativeY.toFixed(4)}`,
                headYaw: headPose ? `${headPose.yaw.toFixed(1)}Â° (Î”${(headPose.yaw - (baseline.headPose?.yaw || 0)).toFixed(1)}Â°)` : 'N/A',
                headPitch: headPose ? `${headPose.pitch.toFixed(1)}Â° (Î”${relativePitch.toFixed(1)}Â°)` : 'N/A',
                raw: { x: Math.round(rawGazeX), y: Math.round(rawGazeY) },
                filtered: { x: Math.round(filtered.x), y: Math.round(filtered.y) }
            });
        }

        // í´ë¨í•‘ ì „ ì›ì‹œ ì¢Œí‘œ (ì§‘ì¤‘ë„ íŒë‹¨ìš©)
        const rawGazeResult = { x: filtered.x, y: filtered.y };

        // ê²½ê³„ í´ë¨í•‘ ë° ë§ˆì§€ë§‰ ìœ íš¨ gaze ì €ì¥
        const gazeResult = {
            x: Math.max(0, Math.min(filtered.x, window.innerWidth)),
            y: Math.max(0, Math.min(filtered.y, window.innerHeight))
        };
        // ë§ˆì§€ë§‰ ìœ íš¨ gaze ì €ì¥ (ê¹œë¹¡ì„ ì‹œ ì‚¬ìš©)
        lastValidGazeRef.current = gazeResult;
        return { clamped: gazeResult, raw: rawGazeResult };
    }, [getSmoothingFilter]);

    // EAR ê¸°ë°˜ ëˆˆ ìƒíƒœ ë¶„ì„
    const analyzeEyeState = useCallback((landmarks) => {
        if (!landmarks || landmarks.length < 478) {
            
            // ì–¼êµ´ ë¯¸ê²€ì¶œ ì‹œ null ë°˜í™˜ (ì¡¸ìŒ ê°ì§€ì—ì„œ êµ¬ë¶„í•˜ê¸° ìœ„í•¨)
            return { leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false };
        }

        // ì™¼ìª½ ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
        const leftEyePoints = {
            P1: landmarks[LANDMARK_INDICES.LEFT_EYE.P1],
            P2: landmarks[LANDMARK_INDICES.LEFT_EYE.P2],
            P3: landmarks[LANDMARK_INDICES.LEFT_EYE.P3],
            P4: landmarks[LANDMARK_INDICES.LEFT_EYE.P4],
            P5: landmarks[LANDMARK_INDICES.LEFT_EYE.P5],
            P6: landmarks[LANDMARK_INDICES.LEFT_EYE.P6]
        };

        // ì˜¤ë¥¸ìª½ ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
        const rightEyePoints = {
            P1: landmarks[LANDMARK_INDICES.RIGHT_EYE.P1],
            P2: landmarks[LANDMARK_INDICES.RIGHT_EYE.P2],
            P3: landmarks[LANDMARK_INDICES.RIGHT_EYE.P3],
            P4: landmarks[LANDMARK_INDICES.RIGHT_EYE.P4],
            P5: landmarks[LANDMARK_INDICES.RIGHT_EYE.P5],
            P6: landmarks[LANDMARK_INDICES.RIGHT_EYE.P6]
        };

        const leftEAR = calculateEAR(leftEyePoints);
        const rightEAR = calculateEAR(rightEyePoints);
        const avgEAR = (leftEAR + rightEAR) / 2;
        const isBlinking = avgEAR < EAR_THRESHOLD;

        return { leftEAR, rightEAR, avgEAR, isBlinking, faceDetected: true };
    }, []);

    // ì¡¸ìŒ ê°ì§€ (PERCLOS ê¸°ë°˜) - ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°ë§Œ ê¸°ë¡
    const detectDrowsiness = useCallback((avgEAR) => {
        // ì–¼êµ´ ë¯¸ê²€ì¶œ ì‹œ (avgEAR === null) ì¡¸ìŒ ê°ì§€ ìŠ¤í‚µ
        // ì¤‘ìš”: ì–¼êµ´ ë¯¸ê²€ì¶œì€ ëˆˆ ê°ìŒìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ!
        if (avgEAR === null) {
            // ì—°ì† ëˆˆ ê°ê¹€ ì¹´ìš´í„° ë¦¬ì…‹ (ì–¼êµ´ ë¯¸ê²€ì¶œì€ ëˆˆ ê°ê¹€ì´ ì•„ë‹˜)
            closedFrameCountRef.current = 0;
            return {
                isDrowsy: false,
                perclos: earHistoryRef.current.length > 0
                    ? earHistoryRef.current.filter(e => e.ear < EAR_THRESHOLD).length / earHistoryRef.current.length
                    : 0,
                consecutiveClosedFrames: 0
            };
        }

        const now = Date.now();

        // EAR ê¸°ë¡ ì¶”ê°€
        earHistoryRef.current.push({ ear: avgEAR, timestamp: now });

        // ìœˆë„ìš° ì™¸ë¶€ ë°ì´í„° ì œê±°
        const windowStart = now - PERCLOS_WINDOW_SECONDS * 1000;
        earHistoryRef.current = earHistoryRef.current.filter(
            entry => entry.timestamp >= windowStart
        );

        // PERCLOS ê³„ì‚° (ëˆˆ ê°ì€ ë¹„ìœ¨)
        const totalFrames = earHistoryRef.current.length;
        // ìµœì†Œ 30í”„ë ˆì„ (ì•½ 1ì´ˆ) ì´ìƒ ìˆ˜ì§‘ë˜ì–´ì•¼ ì˜ë¯¸ìˆëŠ” PERCLOS ê³„ì‚°
        const MIN_FRAMES_FOR_PERCLOS = 30;
        if (totalFrames < MIN_FRAMES_FOR_PERCLOS) {
            return { isDrowsy: false, perclos: 0, consecutiveClosedFrames: closedFrameCountRef.current };
        }

        const closedFrames = earHistoryRef.current.filter(
            entry => entry.ear < EAR_THRESHOLD
        ).length;
        const perclos = closedFrames / totalFrames;

        // ì—°ì† ëˆˆ ê°ê¹€ í”„ë ˆì„ ì¹´ìš´íŠ¸
        if (avgEAR < EAR_THRESHOLD) {
            closedFrameCountRef.current++;
        } else {
            closedFrameCountRef.current = 0;
        }

        const isDrowsy = perclos >= PERCLOS_THRESHOLD ||
            closedFrameCountRef.current >= DROWSY_FRAME_THRESHOLD;

        return {
            isDrowsy,
            perclos,
            consecutiveClosedFrames: closedFrameCountRef.current
        };
    }, []);

    // í™ì±„ ìœ„ì¹˜ ì¶”ì¶œ
    const extractIrisPosition = useCallback((landmarks) => {
        if (!landmarks || landmarks.length < 478) {
            return { left: null, right: null };
        }

        const leftIris = LANDMARK_INDICES.LEFT_IRIS.map(idx => landmarks[idx]);
        const rightIris = LANDMARK_INDICES.RIGHT_IRIS.map(idx => landmarks[idx]);

        return {
            left: {
                center: leftIris[0],
                points: leftIris
            },
            right: {
                center: rightIris[0],
                points: rightIris
            }
        };
    }, []);

    // Throttled ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (Maximum update depth ë°©ì§€)
    const updateReactState = useCallback(() => {
        const data = latestDataRef.current;
        setIsFaceDetected(data.isFaceDetected);
        setFaceCount(data.faceCount);
        setDetectedFaces(data.detectedFaces);
        setHeadPose(data.headPose);
        setGazePosition(data.gazePosition);
        setRawGazePosition(data.rawGazePosition);
        setEyeState(data.eyeState);
        setIrisPosition(data.irisPosition);
        setDrowsinessState(data.drowsinessState);
        setNoFaceDuration(data.noFaceDuration);
        setShowNoFaceWarning(data.showNoFaceWarning);
    }, []);

    // ë©”ì¸ ì¶”ì  ë£¨í”„ (ref ê¸°ë°˜ - setState ìµœì†Œí™”)
    const trackingLoop = useCallback(async () => {
        if (!faceLandmarkerRef.current || !videoRef.current || isCleaningUpRef.current) {
            return;
        }

        const video = videoRef.current;
        const now = performance.now();

        try {
            const results = faceLandmarkerRef.current.detectForVideo(video, now);

            // ========== ì–¼êµ´ ê°ì§€ ë””ë°”ìš´ì‹± ì ìš© ==========
            const rawFaceDetected = results.faceLandmarks && results.faceLandmarks.length > 0;

            if (rawFaceDetected) {
                faceDetectionCounterRef.current.detected++;
                faceDetectionCounterRef.current.notDetected = 0;

                // ì—°ì† 3í”„ë ˆì„ ê°ì§€ ì‹œ ì•ˆì •ì  ê°ì§€ë¡œ íŒì •
                if (faceDetectionCounterRef.current.detected >= FACE_DETECTION_DEBOUNCE_FRAMES) {
                    if (!stableFaceDetectedRef.current) {
                        console.log('âœ… Face stably detected (debounced)');
                    }
                    stableFaceDetectedRef.current = true;
                }
            } else {
                faceDetectionCounterRef.current.notDetected++;
                faceDetectionCounterRef.current.detected = 0;

                // ì—°ì† 3í”„ë ˆì„ ë¯¸ê°ì§€ ì‹œ ì•ˆì •ì  ë¯¸ê°ì§€ë¡œ íŒì •
                if (faceDetectionCounterRef.current.notDetected >= FACE_DETECTION_DEBOUNCE_FRAMES) {
                    if (stableFaceDetectedRef.current) {
                        console.log('âš ï¸ Face stably not detected (debounced)');
                    }
                    stableFaceDetectedRef.current = false;
                }
            }

            // ì•ˆì •í™”ëœ ì–¼êµ´ ê°ì§€ ìƒíƒœ ì‚¬ìš©
            const isFaceStablyDetected = stableFaceDetectedRef.current;

            if (isFaceStablyDetected && rawFaceDetected) {
                // ì–¼êµ´ ê°ì§€ë¨ - refì— ì €ì¥ (ë¦¬ë Œë”ë§ ì—†ìŒ)
                latestDataRef.current.isFaceDetected = true;
                latestDataRef.current.faceCount = results.faceLandmarks.length;
                latestDataRef.current.detectedFaces = results.faceLandmarks;

                // ì²« ë²ˆì§¸ ì–¼êµ´ ê¸°ì¤€ ë¶„ì„
                const primaryLandmarks = results.faceLandmarks[0];

                // 3D ì–¼êµ´ ë°©í–¥ (ë¨¼ì € ê³„ì‚° - ì‹œì„  ì¶”ì •ì— ì‚¬ìš©)
                const headPose = calculateHeadPose(primaryLandmarks);
                latestDataRef.current.headPose = headPose;

                // ì‹œì„  ì¶”ì • (í™ì±„ + ë¨¸ë¦¬ ë°©í–¥ í†µí•©)
                const gazeResult = estimateGazeFromIris(primaryLandmarks, video.videoWidth, video.videoHeight, headPose);
                latestDataRef.current.gazePosition = gazeResult.clamped;
                latestDataRef.current.rawGazePosition = gazeResult.raw;

                // ëˆˆ ìƒíƒœ ë¶„ì„
                const eye = analyzeEyeState(primaryLandmarks);
                latestDataRef.current.eyeState = eye;

                // í™ì±„ ìœ„ì¹˜
                latestDataRef.current.irisPosition = extractIrisPosition(primaryLandmarks);

                // ì¡¸ìŒ ê°ì§€
                const drowsiness = detectDrowsiness(eye.avgEAR);
                latestDataRef.current.drowsinessState = drowsiness;

                // ========== Liveness Detection (ì‚¬ì§„/ì˜ìƒ ê°ì§€) ==========
                // ëˆˆ ê¹œë¹¡ì„ ê°ì§€: ëˆˆì´ ê°ê²¼ë‹¤ê°€ ë– ì§€ëŠ” ìˆœê°„ì„ ê°ì§€
                const isCurrentlyBlinking = eye.isBlinking;
                if (wasBlinkingRef.current && !isCurrentlyBlinking) {
                    // ëˆˆì„ ê°ì•˜ë‹¤ê°€ ëœ¸ = ê¹œë¹¡ì„ ì™„ë£Œ
                    lastBlinkTimeRef.current = Date.now();
                    if (livenessWarningRef.current) {
                        livenessWarningRef.current = false;
                        livenessViolationSentRef.current = false; // ë¦¬ì…‹í•˜ì—¬ ë‹¤ìŒ 30ì´ˆ í›„ ì¬ì „ì†¡ ê°€ëŠ¥
                        setLivenessWarning(false);
                        console.log('âœ… Blink detected - liveness confirmed');
                    }
                }
                wasBlinkingRef.current = isCurrentlyBlinking;

                // ì¼ì • ì‹œê°„ ë™ì•ˆ ëˆˆ ê¹œë¹¡ì„ ì—†ìœ¼ë©´ ì‚¬ì§„/ì˜ìƒ ì˜ì‹¬
                const timeSinceLastBlink = Date.now() - lastBlinkTimeRef.current;
                if (timeSinceLastBlink >= LIVENESS_BLINK_TIMEOUT_MS && !livenessWarningRef.current) {
                    livenessWarningRef.current = true;
                    setLivenessWarning(true);
                    console.warn('âš ï¸ Liveness warning: No blink detected for', Math.round(timeSinceLastBlink / 1000), 'seconds');

                    // Liveness ìœ„ë°˜ ì „ì†¡ (1íšŒ) - ë°±ì—”ë“œ íƒ€ì…: MASK_DETECTED (ê¹œë¹¡ì„ ì—†ìŒ ê°ì§€)
                    if (!livenessViolationSentRef.current && sessionIdRef.current) {
                        livenessViolationSentRef.current = true;
                        console.log('ğŸš¨ MASK_DETECTED violation - sessionId:', sessionIdRef.current);
                        sendMonitoringViolation(sessionIdRef.current, 'MASK_DETECTED', {
                            description: `No blink detected for ${Math.round(timeSinceLastBlink / 1000)} seconds - possible photo/video`,
                            timeSinceLastBlink: Math.round(timeSinceLastBlink / 1000)
                        }).then(res => {
                            if (res?.error) {
                                console.error('âŒ MASK_DETECTED violation API error:', res);
                            } else {
                                console.log('âœ… MASK_DETECTED violation API success:', res);
                            }
                        }).catch(err => {
                            console.error('âŒ MASK_DETECTED violation network error:', err);
                        });
                    }
                }

                // NO_FACE ë¦¬ì…‹ (ì´ì „ì— ì–¼êµ´ì´ ì—†ì—ˆë‹¤ê°€ ê°ì§€ëœ ê²½ìš°ë§Œ ë¡œê·¸)
                if (noFaceStartTimeRef.current !== null) {
                    console.log('âœ… Face detected - resetting NO_FACE tracking');
                    noFaceStartTimeRef.current = null;
                    latestDataRef.current.noFaceDuration = 0;
                    latestDataRef.current.showNoFaceWarning = false;
                    warningShownRef.current = false;
                    sustainedViolationSentRef.current = false;
                }

                // ë‹¤ì¤‘ ì¸ë¬¼ ê²½ê³  (2ëª… ì´ìƒ) - 1íšŒë§Œ ì „ì†¡
                if (results.faceLandmarks.length > 1 && !multipleFacesViolationSentRef.current && sessionIdRef.current) {
                    multipleFacesViolationSentRef.current = true;
                    console.log('ğŸš¨ MULTIPLE_FACES violation - sessionId:', sessionIdRef.current);
                    sendMonitoringViolation(sessionIdRef.current, 'MULTIPLE_FACES', {
                        description: `Multiple faces detected: ${results.faceLandmarks.length} people`,
                        faceCount: results.faceLandmarks.length
                    }).then(res => {
                        if (res?.error) {
                            console.error('âŒ MULTIPLE_FACES violation API error:', res);
                        } else {
                            console.log('âœ… MULTIPLE_FACES violation API success:', res);
                        }
                    }).catch(err => {
                        console.error('âŒ MULTIPLE_FACES violation network error:', err);
                    });
                }
                // ë‹¤ì¤‘ ì¸ë¬¼ í•´ì œ ì‹œ í”Œë˜ê·¸ ë¦¬ì…‹ (ë‹¤ì‹œ ê°ì§€ë˜ë©´ ìƒˆë¡œ ì „ì†¡)
                if (results.faceLandmarks.length <= 1 && multipleFacesViolationSentRef.current) {
                    multipleFacesViolationSentRef.current = false;
                }

                // ì¡¸ìŒ ìœ„ë°˜ ì „ì†¡ (1íšŒ) - ë°±ì—”ë“œ íƒ€ì…ëª…: SLEEPING
                if (drowsiness.isDrowsy && !drowsyViolationSentRef.current && sessionIdRef.current) {
                    drowsyViolationSentRef.current = true;
                    console.log('ğŸš¨ SLEEPING violation - sessionId:', sessionIdRef.current);
                    sendMonitoringViolation(sessionIdRef.current, 'SLEEPING', {
                        description: `Drowsiness detected - PERCLOS: ${(drowsiness.perclos * 100).toFixed(1)}%`,
                        perclos: drowsiness.perclos
                    }).then(res => {
                        if (res?.error) {
                            console.error('âŒ SLEEPING violation API error:', res);
                        } else {
                            console.log('âœ… SLEEPING violation API success:', res);
                        }
                    }).catch(err => {
                        console.error('âŒ SLEEPING violation network error:', err);
                    });
                }

                // ì¡¸ìŒ ìƒíƒœ í•´ì œ ì‹œ í”Œë˜ê·¸ ë¦¬ì…‹
                if (!drowsiness.isDrowsy && drowsyViolationSentRef.current) {
                    drowsyViolationSentRef.current = false;
                }

                // ========== ì‹œì„  ì´íƒˆ (GAZE_AWAY) ìœ„ë°˜ ì „ì†¡ ==========
                // rawGazePositionì´ í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°”ëŠ”ì§€ í™•ì¸ (throttled - 5ì´ˆì— 1íšŒ)
                if (gazeResult?.raw) {
                    const rawGaze = gazeResult.raw;
                    const isGazeOutOfBounds =
                        rawGaze.x < 0 || rawGaze.x > window.innerWidth ||
                        rawGaze.y < 0 || rawGaze.y > window.innerHeight;

                    if (isGazeOutOfBounds && sessionIdRef.current) {
                        const currentTime = Date.now();
                        if (currentTime - lastGazeAwayViolationTimeRef.current >= GAZE_AWAY_THROTTLE_MS) {
                            lastGazeAwayViolationTimeRef.current = currentTime;
                            console.log('ğŸš¨ GAZE_AWAY violation - sessionId:', sessionIdRef.current);
                            sendMonitoringViolation(sessionIdRef.current, 'GAZE_AWAY', {
                                description: `Gaze out of bounds: (${Math.round(rawGaze.x)}, ${Math.round(rawGaze.y)})`,
                                gazePosition: { x: Math.round(rawGaze.x), y: Math.round(rawGaze.y) }
                            }).then(res => {
                                if (res?.error) {
                                    console.error('âŒ GAZE_AWAY violation API error:', res);
                                } else {
                                    console.log('âœ… GAZE_AWAY violation API success:', res);
                                }
                            }).catch(err => {
                                console.error('âŒ GAZE_AWAY violation network error:', err);
                            });
                        }
                    }
                }

            } else if (!isFaceStablyDetected) {
                // ì–¼êµ´ ì•ˆì •ì  ë¯¸ê²€ì¶œ (ë””ë°”ìš´ì‹± ì ìš©ë¨) - refì— ì €ì¥
                latestDataRef.current.isFaceDetected = false;
                latestDataRef.current.faceCount = 0;
                latestDataRef.current.detectedFaces = [];

                // NO_FACE ì§€ì† ì‹œê°„ ì¶”ì  (ë””ë°”ìš´ì‹±ëœ ìƒíƒœ ê¸°ì¤€)
                const currentTime = Date.now();
                if (noFaceStartTimeRef.current === null) {
                    noFaceStartTimeRef.current = currentTime;
                    // ë””ë°”ìš´ì‹±ìœ¼ë¡œ ì¸í•´ ì´ ë¡œê·¸ëŠ” í›¨ì”¬ ì ê²Œ ë‚˜íƒ€ë‚¨
                }

                const duration = currentTime - noFaceStartTimeRef.current;
                // refì— ì €ì¥ (throttled ì—…ë°ì´íŠ¸ì—ì„œ React ìƒíƒœë¡œ ë°˜ì˜ë¨)
                latestDataRef.current.noFaceDuration = duration;

                // 5ì´ˆ ì´ìƒ: ê²½ê³  í‘œì‹œ
                if (duration >= NO_FACE_WARNING_THRESHOLD_MS && !warningShownRef.current) {
                    warningShownRef.current = true;
                    latestDataRef.current.showNoFaceWarning = true;
                    console.log('âš ï¸ NO_FACE warning shown (5+ seconds)');

                    if (sessionIdRef.current) {
                        recordMonitoringWarning(sessionIdRef.current).catch(err => {
                            console.warn('Warning record failed:', err);
                        });
                    }
                }

                // 15ì´ˆ ì´ìƒ: ì‹¬ê°í•œ ìœ„ë°˜
                if (duration >= NO_FACE_THRESHOLD_MS && !sustainedViolationSentRef.current && sessionIdRef.current) {
                    sustainedViolationSentRef.current = true;
                    console.log('ğŸš¨ NO_FACE_SUSTAINED violation - sessionId:', sessionIdRef.current);

                    sendMonitoringViolation(sessionIdRef.current, 'NO_FACE_SUSTAINED', {
                        description: `Face not detected for ${Math.round(duration / 1000)} seconds - serious violation`,
                        duration: Math.round(duration / 1000),
                        severity: 'HIGH'
                    }).then(res => {
                        if (res?.error) {
                            console.error('âŒ NO_FACE_SUSTAINED violation API error:', res);
                        } else {
                            console.log('âœ… NO_FACE_SUSTAINED violation API success:', res);
                        }
                    }).catch(err => {
                        console.error('âŒ NO_FACE_SUSTAINED violation network error:', err);
                    });
                }
            }
            // else: ìƒíƒœ ì „í™˜ ì¤‘ (ë””ë°”ìš´ì‹± ëŒ€ê¸°) - ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ

            // Throttled ìƒíƒœ ì—…ë°ì´íŠ¸ (100msë§ˆë‹¤ = 10fps)
            if (now - lastStateUpdateRef.current >= STATE_UPDATE_INTERVAL_MS) {
                lastStateUpdateRef.current = now;
                updateReactState();
            }

            // ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° (ref ì‚¬ìš©ìœ¼ë¡œ ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
            if (debugModeRef.current && canvasRef.current && drawDebugOverlayRef.current) {
                drawDebugOverlayRef.current(results);
            }

        } catch (error) {
            console.error('Tracking loop error:', error);
        }

        // ë‹¤ìŒ í”„ë ˆì„ ì˜ˆì•½
        if (!isCleaningUpRef.current) {
            animationFrameRef.current = requestAnimationFrame(trackingLoop);
        }
    }, [
        // sessionIdëŠ” sessionIdRefë¡œ ì ‘ê·¼í•˜ì—¬ stale closure ë°©ì§€
        calculateHeadPose,
        estimateGazeFromIris,
        analyzeEyeState,
        extractIrisPosition,
        detectDrowsiness,
        updateReactState
        // livenessWarningì€ refë¡œ ì ‘ê·¼í•˜ì—¬ ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€
        // drawDebugOverlayëŠ” trackingLoop ì´í›„ì— ì •ì˜ë˜ì–´ ref íŒ¨í„´ìœ¼ë¡œ ì ‘ê·¼
    ]);

    // ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
    const drawDebugOverlay = useCallback((results) => {
        const canvas = canvasRef.current;
        const video = videoRef.current;
        if (!canvas || !video) {
            console.warn('drawDebugOverlay: canvas or video not ready', { canvas: !!canvas, video: !!video });
            return;
        }

        // ìº”ë²„ìŠ¤ í¬ê¸°ê°€ ë¹„ë””ì˜¤ì™€ ë§ì§€ ì•Šìœ¼ë©´ ì¡°ì •
        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
            canvas.width = video.videoWidth || 640;
            canvas.height = video.videoHeight || 480;
        }

        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // ë¹„ë””ì˜¤ ê·¸ë¦¬ê¸° (ê±°ìš¸ ëª¨ë“œ) - í•­ìƒ ê·¸ë¦¬ê¸°
        ctx.save();
        ctx.scale(-1, 1);
        ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
        ctx.restore();

        if (results && results.faceLandmarks) {
            results.faceLandmarks.forEach((landmarks, faceIndex) => {
                const color = faceIndex === 0 ? '#22c55e' : '#f59e0b'; // ì²« ë²ˆì§¸: ì´ˆë¡, ë‚˜ë¨¸ì§€: ì£¼í™©

                // ëª¨ë“  ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                landmarks.forEach((landmark, idx) => {
                    const x = (1 - landmark.x) * canvas.width; // ê±°ìš¸ ëª¨ë“œ
                    const y = landmark.y * canvas.height;

                    // í™ì±„ í¬ì¸íŠ¸ëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ
                    const isIris = [...LANDMARK_INDICES.LEFT_IRIS, ...LANDMARK_INDICES.RIGHT_IRIS].includes(idx);
                    ctx.fillStyle = isIris ? '#ef4444' : color;
                    ctx.beginPath();
                    ctx.arc(x, y, isIris ? 3 : 1, 0, 2 * Math.PI);
                    ctx.fill();
                });

                // ëˆˆ ì˜ì—­ í‘œì‹œ
                const leftEye = [
                    LANDMARK_INDICES.LEFT_EYE.P1,
                    LANDMARK_INDICES.LEFT_EYE.P2,
                    LANDMARK_INDICES.LEFT_EYE.P3,
                    LANDMARK_INDICES.LEFT_EYE.P4,
                    LANDMARK_INDICES.LEFT_EYE.P5,
                    LANDMARK_INDICES.LEFT_EYE.P6
                ];
                const rightEye = [
                    LANDMARK_INDICES.RIGHT_EYE.P1,
                    LANDMARK_INDICES.RIGHT_EYE.P2,
                    LANDMARK_INDICES.RIGHT_EYE.P3,
                    LANDMARK_INDICES.RIGHT_EYE.P4,
                    LANDMARK_INDICES.RIGHT_EYE.P5,
                    LANDMARK_INDICES.RIGHT_EYE.P6
                ];

                [leftEye, rightEye].forEach(eyeIndices => {
                    ctx.beginPath();
                    ctx.strokeStyle = '#3b82f6';
                    ctx.lineWidth = 2;
                    eyeIndices.forEach((idx, i) => {
                        const lm = landmarks[idx];
                        const x = (1 - lm.x) * canvas.width;
                        const y = lm.y * canvas.height;
                        if (i === 0) ctx.moveTo(x, y);
                        else ctx.lineTo(x, y);
                    });
                    ctx.closePath();
                    ctx.stroke();
                });
            });
        }

        // ì •ë³´ ì˜¤ë²„ë ˆì´ (refì—ì„œ ìµœì‹  ë°ì´í„° ì½ê¸° - ë¦¬ë Œë”ë§ ì˜ì¡´ì„± ì œê±°)
        const data = latestDataRef.current;
        ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
        ctx.fillRect(10, 10, 280, 200);
        ctx.fillStyle = '#ffffff';
        ctx.font = '12px monospace';

        // null ì•ˆì „ ì²˜ë¦¬
        const leftEAR = data.eyeState?.leftEAR;
        const rightEAR = data.eyeState?.rightEAR;
        const earText = leftEAR !== null && leftEAR !== undefined
            ? `L=${leftEAR.toFixed(3)} R=${rightEAR.toFixed(3)}`
            : 'N/A (no face)';

        const lines = [
            `Faces: ${data.faceCount}`,
            `Face Detected: ${data.isFaceDetected ? 'âœ… YES' : 'âŒ NO'}`,
            `EAR: ${earText}`,
            `Blink: ${data.eyeState?.isBlinking ? 'YES' : 'NO'}`,
            `PERCLOS: ${(data.drowsinessState?.perclos * 100 || 0).toFixed(1)}%`,
            `Drowsy: ${data.drowsinessState?.isDrowsy ? 'âš ï¸ YES' : 'NO'}`,
            `Head: P=${data.headPose?.pitch?.toFixed(1) || 0}Â° Y=${data.headPose?.yaw?.toFixed(1) || 0}Â° R=${data.headPose?.roll?.toFixed(1) || 0}Â°`,
            `Gaze: (${Math.round(data.gazePosition?.x || 0)}, ${Math.round(data.gazePosition?.y || 0)})`,
            `Filter: ${filterTypeRef.current} ${filterTypeRef.current === 'KALMAN' && smoothingFilterRef.current?.state ? `(vel: ${Math.round(smoothingFilterRef.current.state.vx)}, ${Math.round(smoothingFilterRef.current.state.vy)})` : ''}`
        ];

        lines.forEach((line, i) => {
            ctx.fillText(line, 20, 30 + i * 18);
        });

    }, []); // ì˜ì¡´ì„± ì œê±° - ref ì‚¬ìš©ìœ¼ë¡œ í•­ìƒ ìµœì‹  ë°ì´í„°

    // drawDebugOverlayë¥¼ refì— í• ë‹¹ (ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
    useEffect(() => {
        drawDebugOverlayRef.current = drawDebugOverlay;
    }, [drawDebugOverlay]);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘ (3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤€ë¹„)
    const startCalibration = useCallback(() => {
        console.log('MediaPipe 3-point calibration starting...');
        // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ë¦¬ì…‹
        calibrationDataRef.current = null;
        hasManualCalibrationRef.current = false;
        isBaselineCalibratedRef.current = false;
        calibrationAccumulatorRef.current = {
            headPose: { pitch: 0, yaw: 0, roll: 0 },
            irisOffset: { x: 0, y: 0 },
            count: 0
        };
    }, []);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ (3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì €ì¥)
    const completeCalibration = useCallback((calibrationData = null) => {
        if (calibrationData) {
            // 3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì €ì¥
            calibrationDataRef.current = calibrationData;
            hasManualCalibrationRef.current = true;

            // ìƒì„¸ ë””ë²„ê·¸ ë¡œê·¸
            console.log('âœ… 3-point calibration complete');
            console.log('ğŸ“ Baseline:', {
                screenX: Math.round(calibrationData.baseline?.screenX || 0),
                screenY: Math.round(calibrationData.baseline?.screenY || 0),
                irisOffset: calibrationData.baseline?.irisOffset,
                headPose: calibrationData.baseline?.headPose
            });
            console.log('ğŸ“ Sensitivity:', calibrationData.sensitivity);
            console.log('âš–ï¸ Weights:', {
                irisRatio: calibrationData.irisRatio,
                headRatio: calibrationData.headRatio
            });

            // ê°ë„ê°€ 0ì´ë©´ ê²½ê³ 
            if (calibrationData.sensitivity) {
                const sens = calibrationData.sensitivity;
                if (Math.abs(sens.irisX) < 1 && Math.abs(sens.headX) < 1) {
                    console.warn('âš ï¸ X-axis sensitivity is very low! Gaze X movement will be minimal');
                }
                if (Math.abs(sens.irisY) < 1 && Math.abs(sens.headY) < 1) {
                    console.warn('âš ï¸ Y-axis sensitivity is very low! Gaze Y movement will be minimal');
                }
            }

            // ìŠ¤ë¬´ë”© í•„í„° ë¦¬ì…‹ (ìƒˆ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì— ë§ê²Œ)
            if (smoothingFilterRef.current) {
                smoothingFilterRef.current.reset();
                console.log(`ğŸ”„ ${filterTypeRef.current} filter reset for new calibration`);
            }
        } else {
            // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì—†ì´ ì™„ë£Œ (ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‚¬ìš©)
            hasManualCalibrationRef.current = false;
            console.log('âœ… Calibration complete (will use auto baseline)');

            // ìŠ¤ë¬´ë”© í•„í„° ë¦¬ì…‹
            if (smoothingFilterRef.current) {
                smoothingFilterRef.current.reset();
            }
        }
        setIsCalibrated(true);
    }, []);

    // ì¶”ì  ì‹œì‘
    const startTracking = useCallback(async () => {
        if (!isCalibrated || !problemId) return;

        isCleaningUpRef.current = false;

        // ========== ì¶”ì  ì‹œì‘ ì‹œ ìƒíƒœ ì´ˆê¸°í™” ==========
        // EAR íˆìŠ¤í† ë¦¬ ë¦¬ì…‹ (PERCLOS 100% ì¦‰ì‹œ ê°ì§€ ë°©ì§€)
        earHistoryRef.current = [];
        closedFrameCountRef.current = 0;
        drowsyViolationSentRef.current = false;
        lastGazeAwayViolationTimeRef.current = 0;
        // Liveness ë¦¬ì…‹
        lastBlinkTimeRef.current = Date.now();
        wasBlinkingRef.current = false;
        livenessWarningRef.current = false;
        livenessViolationSentRef.current = false;
        multipleFacesViolationSentRef.current = false;
        setLivenessWarning(false);
        // ì–¼êµ´ ê°ì§€ ìƒíƒœ ë¦¬ì…‹
        faceDetectionCounterRef.current = { detected: 0, notDetected: 0 };
        stableFaceDetectedRef.current = false;
        console.log('ğŸ”„ Tracking state reset for new session');

        // ì›¹ìº  ì„¤ì • (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ ì´ë¯¸ ì„¤ì •ë˜ì—ˆìœ¼ë©´ ì¬ì‚¬ìš©)
        if (videoRef.current && streamRef.current) {
            console.log('âœ… Webcam already set up from calibration, reusing existing stream');
        } else {
            const webcamReady = await setupWebcam();
            if (!webcamReady) {
                console.error('Failed to setup webcam');
                return;
            }
        }

        try {
            // ì„¸ì…˜ ì‹œì‘
            const response = await startMonitoringSession(problemId, timeLimitMinutes);
            console.log('ğŸ“¡ Session start API response:', JSON.stringify(response, null, 2));

            const newSessionId = response.data?.sessionId || response.sessionId;
            if (!newSessionId) {
                console.error('âŒ Failed to get sessionId from response:', response);
            }
            sessionIdRef.current = newSessionId; // Sync ref update for trackingLoop
            setSessionId(newSessionId);
            setIsTracking(true);

            console.log('ğŸ¯ MediaPipe monitoring session started, sessionId:', newSessionId, 'sessionIdRef:', sessionIdRef.current);

            // ì¶”ì  ë£¨í”„ ì‹œì‘
            trackingLoop();

        } catch (error) {
            console.error('Failed to start monitoring session:', error);
        }
    }, [isCalibrated, problemId, timeLimitMinutes, setupWebcam, trackingLoop]);

    // ì¶”ì  ì¢…ë£Œ
    const stopTracking = useCallback(async (remainingSeconds = null, focusScoreStats = null) => {
        if (isCleaningUpRef.current) {
            console.log('âš ï¸ stopTracking already in progress, skipping...');
            return;
        }
        isCleaningUpRef.current = true;

        try {
            // ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ì·¨ì†Œ
            if (animationFrameRef.current) {
                cancelAnimationFrame(animationFrameRef.current);
                animationFrameRef.current = null;
            }

            // ì„¸ì…˜ ì¢…ë£Œ (ì§‘ì¤‘ë„ ì ìˆ˜ í†µê³„ í¬í•¨)
            const currentSessionId = sessionIdRef.current;
            if (currentSessionId) {
                try {
                    await endMonitoringSession(currentSessionId, remainingSeconds, focusScoreStats);
                    console.log('âœ… Monitoring session ended, sessionId:', currentSessionId, 'focusScoreStats:', focusScoreStats);
                } catch (error) {
                    console.error('Failed to end monitoring session:', error);
                }
            }

            // FaceLandmarker ë¨¼ì € ë‹«ê¸° (ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì°¸ì¡° í•´ì œ)
            if (faceLandmarkerRef.current) {
                console.log('ğŸ”’ Closing FaceLandmarker before stream cleanup...');
                faceLandmarkerRef.current.close();
                faceLandmarkerRef.current = null;
                console.log('âœ… FaceLandmarker closed');
            }

            // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ (streamRef ìš°ì„  ì‚¬ìš©)
            console.log('ğŸ¥ Cleaning up webcam stream:', {
                hasStreamRef: !!streamRef.current,
                hasVideoRef: !!videoRef.current,
                hasVideoSrcObject: !!videoRef.current?.srcObject
            });

            // 1. streamRefì—ì„œ ì§ì ‘ ì¢…ë£Œ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
            if (streamRef.current) {
                const tracks = streamRef.current.getTracks();
                console.log('ğŸ›‘ Stopping tracks from streamRef:', tracks.map(t => ({
                    kind: t.kind,
                    label: t.label,
                    readyState: t.readyState
                })));
                tracks.forEach(track => {
                    track.stop();
                    console.log('âœ… Track stopped:', track.kind, track.readyState);
                });
                streamRef.current = null;
            }

            // 2. videoRef ì •ë¦¬ (ë¹„ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ â†’ ìŠ¤íŠ¸ë¦¼ í•´ì œ â†’ ë¦¬ì…‹)
            if (videoRef.current) {
                // ë¹„ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ (ë¸Œë¼ìš°ì €ê°€ ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œí•˜ë„ë¡)
                videoRef.current.pause();

                if (videoRef.current.srcObject) {
                    const tracks = videoRef.current.srcObject.getTracks();
                    tracks.forEach(track => track.stop());
                    videoRef.current.srcObject = null;
                }

                // ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ë¦¬ì…‹ (Safari/Chromeì—ì„œ í™•ì‹¤í•œ í•´ì œ)
                videoRef.current.load();
                console.log('âœ… Video element reset');
            }
            videoRef.current = null;

            // DOM ìš”ì†Œ ì •ë¦¬
            const debugContainer = document.getElementById('mediapipeDebugContainer');
            if (debugContainer) {
                debugContainer.remove();
            }

            // ì‹œì„  ë„íŠ¸ ì œê±°
            const gazeDot = document.getElementById('mediapipeGazeDot');
            if (gazeDot) {
                gazeDot.remove();
            }

            console.log('âœ… MediaPipe tracking stopped');

            setIsTracking(false);
            sessionIdRef.current = null;
            setSessionId(null);

            // ìƒíƒœ ë¦¬ì…‹
            noFaceStartTimeRef.current = null;
            latestDataRef.current.noFaceDuration = 0;
            latestDataRef.current.showNoFaceWarning = false;
            setNoFaceDuration(0);
            setShowNoFaceWarning(false);
            warningShownRef.current = false;
            sustainedViolationSentRef.current = false;
            drowsyViolationSentRef.current = false;
            lastGazeAwayViolationTimeRef.current = 0;
            earHistoryRef.current = [];
            closedFrameCountRef.current = 0;

            // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ë¦¬ì…‹ (ë‹¤ìŒ ì„¸ì…˜ì„ ìœ„í•´)
            isBaselineCalibratedRef.current = false;
            calibrationAccumulatorRef.current = {
                headPose: { pitch: 0, yaw: 0, roll: 0 },
                irisOffset: { x: 0, y: 0 },
                count: 0
            };

            // ìŠ¤ë¬´ë”© í•„í„° ë¦¬ì…‹
            if (smoothingFilterRef.current) {
                smoothingFilterRef.current.reset();
            }

        } catch (error) {
            console.error('Error during stopTracking:', error);
        } finally {
            // ì •ë¦¬ í”Œë˜ê·¸ ë¦¬ì…‹ (ë‹¤ìŒ ì„¸ì…˜ì—ì„œ stopTracking í˜¸ì¶œ ê°€ëŠ¥í•˜ë„ë¡)
            isCleaningUpRef.current = false;
        }
    }, []); // sessionIdëŠ” sessionIdRefë¡œ ì ‘ê·¼

    // ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
    const toggleDebugMode = useCallback(() => {
        const newDebugMode = !debugModeRef.current;
        debugModeRef.current = newDebugMode; // ref ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (tracking loopì—ì„œ ì‚¬ìš©)
        setDebugMode(newDebugMode); // ìƒíƒœë„ ì—…ë°ì´íŠ¸ (UI ë°˜ì˜)

        if (newDebugMode) {
            // ë””ë²„ê·¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            setTimeout(() => {
                let container = document.getElementById('mediapipeDebugContainer');
                if (!container) {
                    container = document.createElement('div');
                    container.id = 'mediapipeDebugContainer';
                    container.style.cssText = `
                        position: fixed;
                        top: 120px;
                        left: 20px;
                        z-index: 10000;
                        border: 4px solid #22c55e;
                        border-radius: 12px;
                        overflow: hidden;
                        box-shadow: 0 4px 20px rgba(34, 197, 94, 0.4);
                        background: #18181b;
                        width: 320px;
                        height: 240px;
                    `;
                    document.body.appendChild(container);
                }

                // ìº”ë²„ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
                if (!canvasRef.current && videoRef.current) {
                    const canvas = document.createElement('canvas');
                    canvas.id = 'mediapipeOverlay';
                    canvas.width = videoRef.current.videoWidth || 640;
                    canvas.height = videoRef.current.videoHeight || 480;
                    canvasRef.current = canvas;
                }

                if (canvasRef.current) {
                    canvasRef.current.style.cssText = `
                        width: 100%;
                        height: 100%;
                        object-fit: cover;
                    `;
                    // ì´ë¯¸ ì»¨í…Œì´ë„ˆì— ìˆëŠ”ì§€ í™•ì¸
                    if (!container.contains(canvasRef.current)) {
                        container.appendChild(canvasRef.current);
                    }
                }

                // ì‹œì„  ë„íŠ¸ ìƒì„±
                let gazeDot = document.getElementById('mediapipeGazeDot');
                if (!gazeDot) {
                    gazeDot = document.createElement('div');
                    gazeDot.id = 'mediapipeGazeDot';
                    gazeDot.style.cssText = `
                        position: fixed;
                        width: 40px;
                        height: 40px;
                        margin-left: -20px;
                        margin-top: -20px;
                        border-radius: 50%;
                        background: #ef4444;
                        border: 4px solid #ffffff;
                        box-shadow: 0 0 30px rgba(239, 68, 68, 1), 0 0 60px rgba(239, 68, 68, 0.5);
                        pointer-events: none;
                        z-index: 999999;
                        transition: left 0.05s ease-out, top 0.05s ease-out;
                    `;
                    document.body.appendChild(gazeDot);
                }

                console.log('ğŸ”§ MediaPipe Debug mode ON', {
                    hasVideo: !!videoRef.current,
                    hasCanvas: !!canvasRef.current,
                    videoSize: videoRef.current ? `${videoRef.current.videoWidth}x${videoRef.current.videoHeight}` : 'N/A'
                });
            }, 100);
        } else {
            // ë””ë²„ê·¸ ìš”ì†Œ ì œê±° (ìº”ë²„ìŠ¤ëŠ” ìœ ì§€, ì»¨í…Œì´ë„ˆë§Œ ì œê±°)
            const container = document.getElementById('mediapipeDebugContainer');
            if (container) {
                // ìº”ë²„ìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì—ì„œ ë¶„ë¦¬ (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
                if (canvasRef.current && container.contains(canvasRef.current)) {
                    container.removeChild(canvasRef.current);
                }
                container.remove();
            }

            const gazeDot = document.getElementById('mediapipeGazeDot');
            if (gazeDot) gazeDot.remove();

            console.log('ğŸ”§ MediaPipe Debug mode OFF');
        }
    }, []);

    // ì‹œì„  ë„íŠ¸ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
    useEffect(() => {
        if (!debugMode) return;

        const gazeDot = document.getElementById('mediapipeGazeDot');
        if (gazeDot && gazePosition) {
            gazeDot.style.left = `${gazePosition.x}px`;
            gazeDot.style.top = `${gazePosition.y}px`;
        }
    }, [debugMode, gazePosition]);

    // ì–¼êµ´ ê°ì§€ ìƒíƒœì— ë”°ë¥¸ ì»¨í…Œì´ë„ˆ í…Œë‘ë¦¬ ìƒ‰ìƒ
    useEffect(() => {
        if (!debugMode) return;

        const container = document.getElementById('mediapipeDebugContainer');
        if (!container) return;

        if (!isFaceDetected) {
            container.style.borderColor = '#ef4444';
            container.style.boxShadow = '0 4px 20px rgba(239, 68, 68, 0.6)';
        } else {
            container.style.borderColor = '#22c55e';
            container.style.boxShadow = '0 4px 20px rgba(34, 197, 94, 0.4)';
        }
    }, [debugMode, isFaceDetected]);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì‹œ ìë™ ì¶”ì  ì‹œì‘
    useEffect(() => {
        if (isCalibrated && !isTracking && problemId) {
            startTracking();
        }
    }, [isCalibrated, isTracking, problemId, startTracking]);

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    useEffect(() => {
        return () => {
            console.log('ğŸ§¹ useMediaPipeTracking unmount cleanup');
            if (animationFrameRef.current) {
                cancelAnimationFrame(animationFrameRef.current);
            }
            // streamRef ìš°ì„  ì •ë¦¬
            if (streamRef.current) {
                const tracks = streamRef.current.getTracks();
                tracks.forEach(track => track.stop());
                streamRef.current = null;
            }
            // videoRef ì •ë¦¬ (pause â†’ srcObject í•´ì œ â†’ load ë¦¬ì…‹)
            if (videoRef.current) {
                videoRef.current.pause();
                if (videoRef.current.srcObject) {
                    const tracks = videoRef.current.srcObject.getTracks();
                    tracks.forEach(track => track.stop());
                    videoRef.current.srcObject = null;
                }
                videoRef.current.load();
            }
            videoRef.current = null;
        };
    }, []);

    return {
        // ê¸°ë³¸ (WebGazer í˜¸í™˜)
        isCalibrated,
        isTracking,
        sessionId,
        monitoringSessionId: sessionId,
        startCalibration,
        completeCalibration,
        stopTracking,

        // NO_FACE ìƒíƒœ (WebGazer í˜¸í™˜)
        noFaceDuration,
        showNoFaceWarning,
        noFaceProgress: noFaceDuration / NO_FACE_THRESHOLD_MS,

        // ë””ë²„ê·¸ (WebGazer í˜¸í™˜)
        debugMode,
        toggleDebugMode,
        isFaceDetected,

        // MediaPipe ì¶”ê°€ ê¸°ëŠ¥
        faceCount,              // ê°ì§€ëœ ì–¼êµ´ ìˆ˜
        detectedFaces,          // ëª¨ë“  ê°ì§€ëœ ì–¼êµ´ ëœë“œë§ˆí¬
        headPose,               // 3D ì–¼êµ´ ë°©í–¥ { pitch, yaw, roll }
        gazePosition,           // ì¶”ì •ëœ ì‹œì„  ìœ„ì¹˜ { x, y } (í´ë¨í•‘ë¨, ì‹œì„ ì  í‘œì‹œìš©)
        rawGazePosition,        // ì¶”ì •ëœ ì‹œì„  ìœ„ì¹˜ { x, y } (í´ë¨í•‘ ì•ˆë¨, ì§‘ì¤‘ë„ íŒë‹¨ìš©)
        eyeState,               // ëˆˆ ìƒíƒœ { leftEAR, rightEAR, avgEAR, isBlinking }
        irisPosition,           // í™ì±„ ìœ„ì¹˜ { left, right }
        drowsinessState,        // ì¡¸ìŒ ìƒíƒœ { isDrowsy, perclos, consecutiveClosedFrames }
        livenessWarning,        // ì‚¬ì§„/ì˜ìƒ ê°ì§€ ê²½ê³  (30ì´ˆ ë™ì•ˆ ëˆˆ ê¹œë¹¡ì„ ì—†ìŒ)

        // 3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ìš© refs (MediaPipeCalibrationScreenì—ì„œ ì‚¬ìš©)
        faceLandmarkerRef,      // FaceLandmarker ì¸ìŠ¤í„´ìŠ¤ ref
        videoRef,               // ì›¹ìº  ë¹„ë””ì˜¤ ìš”ì†Œ ref
        setupWebcam             // ì›¹ìº  ì„¤ì • í•¨ìˆ˜
    };
};
