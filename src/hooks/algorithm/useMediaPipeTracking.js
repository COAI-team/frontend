import { useState, useEffect, useCallback, useRef } from 'react';
import {
    startMonitoringSession,
    sendMonitoringViolation,
    endMonitoringSession,
    recordMonitoringWarning
} from '../../service/algorithm/algorithmApi';

/**
 * MediaPipe ê¸°ë°˜ ì‹œì„ /ì–¼êµ´ ì¶”ì  ì»¤ìŠ¤í…€ í›…
 *
 * WebGazer ëŒ€ì•ˆìœ¼ë¡œ MediaPipe Face Landmarker ì‚¬ìš©
 * ì¶”ê°€ ê¸°ëŠ¥: ì¡¸ìŒ ê°ì§€, ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€, 3D ì–¼êµ´ ë°©í–¥, í™ì±„ ì¶”ì 
 *
 * @param {number} problemId - í˜„ì¬ ë¬¸ì œ ID
 * @param {boolean} isActive - ì¶”ì  í™œì„±í™” ì—¬ë¶€
 * @param {number} timeLimitMinutes - ì œí•œ ì‹œê°„ (ë¶„, ê¸°ë³¸ 30ë¶„)
 * @returns {object} - ì¶”ì  ìƒíƒœ ë° ì œì–´ í•¨ìˆ˜
 */

// ìƒìˆ˜ ì •ì˜
const NO_FACE_THRESHOLD_MS = 15000; // 15ì´ˆ ì´ìƒ NO_FACE ì‹œ ì‹¬ê°í•œ ìœ„ë°˜
const NO_FACE_WARNING_THRESHOLD_MS = 5000; // 5ì´ˆ ì´ìƒ ì‹œ ê²½ê³  í‘œì‹œ ì‹œì‘

// ì¡¸ìŒ ê°ì§€ ìƒìˆ˜
const EAR_THRESHOLD = 0.20; // Eye Aspect Ratio ì„ê³„ê°’ (ëˆˆ ê°ê¹€ íŒë‹¨) - 0.25ì—ì„œ í•˜í–¥ (ë” í™•ì‹¤í•œ ëˆˆ ê°ê¹€ë§Œ ê°ì§€)
const DROWSY_FRAME_THRESHOLD = 90; // ì—°ì† í”„ë ˆì„ ìˆ˜ (90í”„ë ˆì„ â‰ˆ 3ì´ˆ) - 30ì—ì„œ ìƒí–¥ (ì˜¤íƒ ê°ì†Œ)
const PERCLOS_THRESHOLD = 0.8; // PERCLOS ì„ê³„ê°’ (80% ì´ìƒ ì‹œ ì¡¸ìŒ)
const PERCLOS_WINDOW_SECONDS = 60; // PERCLOS ê³„ì‚° ìœˆë„ìš° (60ì´ˆ)

// MediaPipe ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (478ê°œ ì¤‘ ì£¼ìš” í¬ì¸íŠ¸)
const LANDMARK_INDICES = {
    // ëˆˆ (Eye Aspect Ratio ê³„ì‚°ìš©)
    LEFT_EYE: {
        P1: 33,   // ì™¼ìª½ ë
        P2: 160,  // ìƒë‹¨ 1
        P3: 158,  // ìƒë‹¨ 2
        P4: 133,  // ì˜¤ë¥¸ìª½ ë
        P5: 153,  // í•˜ë‹¨ 1
        P6: 144   // í•˜ë‹¨ 2
    },
    RIGHT_EYE: {
        P1: 362,  // ì™¼ìª½ ë
        P2: 385,  // ìƒë‹¨ 1
        P3: 387,  // ìƒë‹¨ 2
        P4: 263,  // ì˜¤ë¥¸ìª½ ë
        P5: 373,  // í•˜ë‹¨ 1
        P6: 380   // í•˜ë‹¨ 2
    },
    // í™ì±„ (Iris)
    LEFT_IRIS: [468, 469, 470, 471, 472],  // ì™¼ìª½ í™ì±„ ì¤‘ì‹¬ ë° ì£¼ë³€
    RIGHT_IRIS: [473, 474, 475, 476, 477], // ì˜¤ë¥¸ìª½ í™ì±„ ì¤‘ì‹¬ ë° ì£¼ë³€
    // ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš©
    NOSE_TIP: 1,
    CHIN: 152,
    LEFT_EYE_OUTER: 33,
    RIGHT_EYE_OUTER: 263,
    LEFT_MOUTH_CORNER: 61,
    RIGHT_MOUTH_CORNER: 291
};

// ìœ í‹¸ë¦¬í‹°: ë‘ ì  ì‚¬ì´ ê±°ë¦¬ ê³„ì‚°
const distance = (p1, p2) => {
    return Math.sqrt(
        Math.pow(p2.x - p1.x, 2) +
        Math.pow(p2.y - p1.y, 2) +
        Math.pow((p2.z || 0) - (p1.z || 0), 2)
    );
};

// Eye Aspect Ratio (EAR) ê³„ì‚°
const calculateEAR = (eyeLandmarks) => {
    const { P1, P2, P3, P4, P5, P6 } = eyeLandmarks;
    const vertical1 = distance(P2, P6);
    const vertical2 = distance(P3, P5);
    const horizontal = distance(P1, P4);
    return (vertical1 + vertical2) / (2.0 * horizontal);
};

export const useMediaPipeTracking = (problemId, isActive = false, timeLimitMinutes = 30) => {
    // ê¸°ë³¸ ìƒíƒœ
    const [isCalibrated, setIsCalibrated] = useState(false);
    const [isTracking, setIsTracking] = useState(false);
    const [sessionId, setSessionId] = useState(null);

    // NO_FACE ìƒíƒœ
    const noFaceStartTimeRef = useRef(null);
    const [noFaceDuration, setNoFaceDuration] = useState(0);
    const [showNoFaceWarning, setShowNoFaceWarning] = useState(false);
    const warningShownRef = useRef(false);
    const sustainedViolationSentRef = useRef(false);

    // ë””ë²„ê·¸ ëª¨ë“œ
    const [debugMode, setDebugMode] = useState(false);
    const debugModeRef = useRef(false); // tracking loopì—ì„œ ì‚¬ìš©í•  ref
    const [isFaceDetected, setIsFaceDetected] = useState(true);

    // MediaPipe ê´€ë ¨ ìƒíƒœ
    const faceLandmarkerRef = useRef(null);
    const videoRef = useRef(null);
    const canvasRef = useRef(null);
    const animationFrameRef = useRef(null);
    const isCleaningUpRef = useRef(false);

    // ì¶”ê°€ ê¸°ëŠ¥ ìƒíƒœ - UI í‘œì‹œìš© (throttled update)
    const [detectedFaces, setDetectedFaces] = useState([]); // ë‹¤ì¤‘ ì¸ë¬¼
    const [faceCount, setFaceCount] = useState(0);
    const [headPose, setHeadPose] = useState({ pitch: 0, yaw: 0, roll: 0 }); // 3D ì–¼êµ´ ë°©í–¥
    const [gazePosition, setGazePosition] = useState({ x: window.innerWidth / 2, y: window.innerHeight / 2 }); // ì‹œì„  ìœ„ì¹˜
    const [eyeState, setEyeState] = useState({ leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false });
    const [irisPosition, setIrisPosition] = useState({ left: null, right: null });

    // ì¡¸ìŒ ê°ì§€ ìƒíƒœ
    const [drowsinessState, setDrowsinessState] = useState({
        isDrowsy: false,
        perclos: 0,
        consecutiveClosedFrames: 0
    });
    const closedFrameCountRef = useRef(0);
    const earHistoryRef = useRef([]); // PERCLOS ê³„ì‚°ìš©
    const drowsyViolationSentRef = useRef(false);

    // ê³ ë¹ˆë„ ë°ì´í„°ë¥¼ ìœ„í•œ refs (setState í˜¸ì¶œ ìµœì†Œí™” - Maximum update depth ë°©ì§€)
    const latestDataRef = useRef({
        isFaceDetected: false,
        faceCount: 0,
        detectedFaces: [],
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        gazePosition: { x: window.innerWidth / 2, y: window.innerHeight / 2 },
        eyeState: { leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false },
        irisPosition: { left: null, right: null },
        drowsinessState: { isDrowsy: false, perclos: 0, consecutiveClosedFrames: 0 },
        noFaceDuration: 0,
        showNoFaceWarning: false
    });
    const lastStateUpdateRef = useRef(0);
    const STATE_UPDATE_INTERVAL_MS = 100; // 100msë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (10fps - UIì— ì¶©ë¶„)

    // MediaPipe FaceLandmarker ì´ˆê¸°í™”
    useEffect(() => {
        if (!isActive) return;

        const initMediaPipe = async () => {
            try {
                // MediaPipe Vision ë™ì  ë¡œë“œ
                const vision = await import('@mediapipe/tasks-vision');
                const { FaceLandmarker, FilesetResolver } = vision;

                // WASM íŒŒì¼ ë¡œë“œ
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
                );

                // FaceLandmarker ìƒì„±
                const faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                        delegate: 'GPU' // GPU ê°€ì† ì‚¬ìš©
                    },
                    outputFaceBlendshapes: true, // í‘œì • ë¶„ì„
                    outputFacialTransformationMatrixes: true, // 3D ë³€í™˜ í–‰ë ¬
                    runningMode: 'VIDEO',
                    numFaces: 5 // ìµœëŒ€ 5ëª… ê°ì§€
                });

                faceLandmarkerRef.current = faceLandmarker;
                console.log('âœ… MediaPipe FaceLandmarker initialized');
            } catch (error) {
                console.error('âŒ MediaPipe initialization failed:', error);
            }
        };

        initMediaPipe();

        return () => {
            if (faceLandmarkerRef.current) {
                faceLandmarkerRef.current.close();
                faceLandmarkerRef.current = null;
            }
        };
    }, [isActive]);

    // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì„¤ì •
    const setupWebcam = useCallback(async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                }
            });

            // ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
            const video = document.createElement('video');
            video.id = 'mediapipeVideoFeed';
            video.srcObject = stream;
            video.autoplay = true;
            video.playsInline = true;
            video.muted = true;

            await new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    video.play();
                    resolve();
                };
            });

            videoRef.current = video;

            // ìº”ë²„ìŠ¤ ìƒì„± (ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ìš©)
            const canvas = document.createElement('canvas');
            canvas.id = 'mediapipeOverlay';
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvasRef.current = canvas;

            console.log('âœ… Webcam stream ready:', video.videoWidth, 'x', video.videoHeight);
            return true;
        } catch (error) {
            console.error('âŒ Webcam setup failed:', error);
            return false;
        }
    }, []);

    // 3D ì–¼êµ´ ë°©í–¥ ê³„ì‚° (Pitch, Yaw, Roll)
    const calculateHeadPose = useCallback((landmarks) => {
        if (!landmarks || landmarks.length === 0) return { pitch: 0, yaw: 0, roll: 0 };

        const noseTip = landmarks[LANDMARK_INDICES.NOSE_TIP];
        const chin = landmarks[LANDMARK_INDICES.CHIN];
        const leftEye = landmarks[LANDMARK_INDICES.LEFT_EYE_OUTER];
        const rightEye = landmarks[LANDMARK_INDICES.RIGHT_EYE_OUTER];

        // Yaw (ì¢Œìš° íšŒì „) - ì½”ì™€ ì–‘ ëˆˆ ì¤‘ì‹¬ ë¹„êµ
        const eyeCenter = {
            x: (leftEye.x + rightEye.x) / 2,
            y: (leftEye.y + rightEye.y) / 2,
            z: ((leftEye.z || 0) + (rightEye.z || 0)) / 2
        };
        const yaw = Math.atan2(noseTip.x - eyeCenter.x, noseTip.z - eyeCenter.z) * (180 / Math.PI);

        // Pitch (ìƒí•˜ íšŒì „) - ì½”ì™€ í„± ë¹„êµ
        const pitch = Math.atan2(noseTip.y - chin.y, noseTip.z - chin.z) * (180 / Math.PI);

        // Roll (ê¸°ìš¸ê¸°) - ì–‘ ëˆˆì˜ ë†’ì´ ì°¨ì´
        const roll = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x) * (180 / Math.PI);

        return { pitch, yaw, roll };
    }, []);

    // í™ì±„ ê¸°ë°˜ ì‹œì„  ì¶”ì • (ê°œì„ ëœ ê³µì‹)
    const estimateGazeFromIris = useCallback((landmarks, videoWidth, videoHeight) => {
        if (!landmarks || landmarks.length < 478) return { x: window.innerWidth / 2, y: window.innerHeight / 2 };

        // ì™¼ìª½ í™ì±„ ì¤‘ì‹¬
        const leftIrisCenter = landmarks[LANDMARK_INDICES.LEFT_IRIS[0]];
        // ì˜¤ë¥¸ìª½ í™ì±„ ì¤‘ì‹¬
        const rightIrisCenter = landmarks[LANDMARK_INDICES.RIGHT_IRIS[0]];

        // í™ì±„ ì¤‘ì‹¬ í‰ê· 
        const irisCenter = {
            x: (leftIrisCenter.x + rightIrisCenter.x) / 2,
            y: (leftIrisCenter.y + rightIrisCenter.y) / 2
        };

        // ì™¼ìª½/ì˜¤ë¥¸ìª½ ëˆˆì˜ ê²½ê³„
        const leftEyeLeft = landmarks[LANDMARK_INDICES.LEFT_EYE.P1];
        const leftEyeRight = landmarks[LANDMARK_INDICES.LEFT_EYE.P4];
        const rightEyeLeft = landmarks[LANDMARK_INDICES.RIGHT_EYE.P1];
        const rightEyeRight = landmarks[LANDMARK_INDICES.RIGHT_EYE.P4];

        // ëˆˆ ë„ˆë¹„ ê³„ì‚° (ì •ê·œí™” ê¸°ì¤€)
        const leftEyeWidth = Math.abs(leftEyeRight.x - leftEyeLeft.x);
        const rightEyeWidth = Math.abs(rightEyeRight.x - rightEyeLeft.x);
        const avgEyeWidth = (leftEyeWidth + rightEyeWidth) / 2;

        // ëˆˆ ì˜ì—­ ì¤‘ì‹¬
        const eyeRegionCenter = {
            x: (leftEyeLeft.x + leftEyeRight.x + rightEyeLeft.x + rightEyeRight.x) / 4,
            y: (leftEyeLeft.y + leftEyeRight.y + rightEyeLeft.y + rightEyeRight.y) / 4
        };

        // í™ì±„ ì˜¤í”„ì…‹ì„ ëˆˆ ë„ˆë¹„ ëŒ€ë¹„ ë¹„ìœ¨ë¡œ ì •ê·œí™” (-1 ~ +1 ë²”ìœ„)
        const normalizedOffsetX = avgEyeWidth > 0
            ? (irisCenter.x - eyeRegionCenter.x) / (avgEyeWidth / 2)
            : 0;
        const normalizedOffsetY = avgEyeWidth > 0
            ? (irisCenter.y - eyeRegionCenter.y) / (avgEyeWidth / 2)
            : 0;

        // ê°ë„ ì¡°ì ˆ (í™”ë©´ ë²”ìœ„ì˜ ë¹„ìœ¨)
        const GAZE_SENSITIVITY_X = 0.5; // í™”ë©´ ë„ˆë¹„ì˜ 50%ê¹Œì§€ ì»¤ë²„
        const GAZE_SENSITIVITY_Y = 0.4; // í™”ë©´ ë†’ì´ì˜ 40%ê¹Œì§€ ì»¤ë²„

        // í™”ë©´ ì¢Œí‘œ ë³€í™˜ (ê±°ìš¸ ëª¨ë“œ: xì¶• ë°˜ì „ - ì‚¬ìš©ì ì‹œì ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ)
        // ì›¹ìº  ì¢Œí‘œê³„ì—ì„œ ì˜¤ë¥¸ìª½ì´ í™”ë©´ ì¢Œì¸¡ì— ë§¤í•‘ë˜ë„ë¡ ë°˜ì „
        const gazeX = window.innerWidth / 2 - normalizedOffsetX * window.innerWidth * GAZE_SENSITIVITY_X;
        const gazeY = window.innerHeight / 2 + normalizedOffsetY * window.innerHeight * GAZE_SENSITIVITY_Y;

        // ê²½ê³„ í´ë¨í•‘
        return {
            x: Math.max(0, Math.min(gazeX, window.innerWidth)),
            y: Math.max(0, Math.min(gazeY, window.innerHeight))
        };
    }, []);

    // EAR ê¸°ë°˜ ëˆˆ ìƒíƒœ ë¶„ì„
    const analyzeEyeState = useCallback((landmarks) => {
        if (!landmarks || landmarks.length < 478) {
            // ì–¼êµ´ ë¯¸ê²€ì¶œ ì‹œ null ë°˜í™˜ (ì¡¸ìŒ ê°ì§€ì—ì„œ êµ¬ë¶„í•˜ê¸° ìœ„í•¨)
            return { leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false };
        }

        // ì™¼ìª½ ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
        const leftEyePoints = {
            P1: landmarks[LANDMARK_INDICES.LEFT_EYE.P1],
            P2: landmarks[LANDMARK_INDICES.LEFT_EYE.P2],
            P3: landmarks[LANDMARK_INDICES.LEFT_EYE.P3],
            P4: landmarks[LANDMARK_INDICES.LEFT_EYE.P4],
            P5: landmarks[LANDMARK_INDICES.LEFT_EYE.P5],
            P6: landmarks[LANDMARK_INDICES.LEFT_EYE.P6]
        };

        // ì˜¤ë¥¸ìª½ ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
        const rightEyePoints = {
            P1: landmarks[LANDMARK_INDICES.RIGHT_EYE.P1],
            P2: landmarks[LANDMARK_INDICES.RIGHT_EYE.P2],
            P3: landmarks[LANDMARK_INDICES.RIGHT_EYE.P3],
            P4: landmarks[LANDMARK_INDICES.RIGHT_EYE.P4],
            P5: landmarks[LANDMARK_INDICES.RIGHT_EYE.P5],
            P6: landmarks[LANDMARK_INDICES.RIGHT_EYE.P6]
        };

        const leftEAR = calculateEAR(leftEyePoints);
        const rightEAR = calculateEAR(rightEyePoints);
        const avgEAR = (leftEAR + rightEAR) / 2;
        const isBlinking = avgEAR < EAR_THRESHOLD;

        return { leftEAR, rightEAR, avgEAR, isBlinking, faceDetected: true };
    }, []);

    // ì¡¸ìŒ ê°ì§€ (PERCLOS ê¸°ë°˜) - ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°ë§Œ ê¸°ë¡
    const detectDrowsiness = useCallback((avgEAR) => {
        // ì–¼êµ´ ë¯¸ê²€ì¶œ ì‹œ (avgEAR === null) ì¡¸ìŒ ê°ì§€ ìŠ¤í‚µ
        // ì¤‘ìš”: ì–¼êµ´ ë¯¸ê²€ì¶œì€ ëˆˆ ê°ìŒìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ!
        if (avgEAR === null) {
            // ì—°ì† ëˆˆ ê°ê¹€ ì¹´ìš´í„° ë¦¬ì…‹ (ì–¼êµ´ ë¯¸ê²€ì¶œì€ ëˆˆ ê°ê¹€ì´ ì•„ë‹˜)
            closedFrameCountRef.current = 0;
            return {
                isDrowsy: false,
                perclos: earHistoryRef.current.length > 0
                    ? earHistoryRef.current.filter(e => e.ear < EAR_THRESHOLD).length / earHistoryRef.current.length
                    : 0,
                consecutiveClosedFrames: 0
            };
        }

        const now = Date.now();

        // EAR ê¸°ë¡ ì¶”ê°€
        earHistoryRef.current.push({ ear: avgEAR, timestamp: now });

        // ìœˆë„ìš° ì™¸ë¶€ ë°ì´í„° ì œê±°
        const windowStart = now - PERCLOS_WINDOW_SECONDS * 1000;
        earHistoryRef.current = earHistoryRef.current.filter(
            entry => entry.timestamp >= windowStart
        );

        // PERCLOS ê³„ì‚° (ëˆˆ ê°ì€ ë¹„ìœ¨)
        const totalFrames = earHistoryRef.current.length;
        if (totalFrames === 0) return { isDrowsy: false, perclos: 0, consecutiveClosedFrames: 0 };

        const closedFrames = earHistoryRef.current.filter(
            entry => entry.ear < EAR_THRESHOLD
        ).length;
        const perclos = closedFrames / totalFrames;

        // ì—°ì† ëˆˆ ê°ê¹€ í”„ë ˆì„ ì¹´ìš´íŠ¸
        if (avgEAR < EAR_THRESHOLD) {
            closedFrameCountRef.current++;
        } else {
            closedFrameCountRef.current = 0;
        }

        const isDrowsy = perclos >= PERCLOS_THRESHOLD ||
            closedFrameCountRef.current >= DROWSY_FRAME_THRESHOLD;

        return {
            isDrowsy,
            perclos,
            consecutiveClosedFrames: closedFrameCountRef.current
        };
    }, []);

    // í™ì±„ ìœ„ì¹˜ ì¶”ì¶œ
    const extractIrisPosition = useCallback((landmarks) => {
        if (!landmarks || landmarks.length < 478) {
            return { left: null, right: null };
        }

        const leftIris = LANDMARK_INDICES.LEFT_IRIS.map(idx => landmarks[idx]);
        const rightIris = LANDMARK_INDICES.RIGHT_IRIS.map(idx => landmarks[idx]);

        return {
            left: {
                center: leftIris[0],
                points: leftIris
            },
            right: {
                center: rightIris[0],
                points: rightIris
            }
        };
    }, []);

    // Throttled ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (Maximum update depth ë°©ì§€)
    const updateReactState = useCallback(() => {
        const data = latestDataRef.current;
        setIsFaceDetected(data.isFaceDetected);
        setFaceCount(data.faceCount);
        setDetectedFaces(data.detectedFaces);
        setHeadPose(data.headPose);
        setGazePosition(data.gazePosition);
        setEyeState(data.eyeState);
        setIrisPosition(data.irisPosition);
        setDrowsinessState(data.drowsinessState);
        setNoFaceDuration(data.noFaceDuration);
        setShowNoFaceWarning(data.showNoFaceWarning);
    }, []);

    // ë©”ì¸ ì¶”ì  ë£¨í”„ (ref ê¸°ë°˜ - setState ìµœì†Œí™”)
    const trackingLoop = useCallback(async () => {
        if (!faceLandmarkerRef.current || !videoRef.current || isCleaningUpRef.current) {
            return;
        }

        const video = videoRef.current;
        const now = performance.now();

        try {
            const results = faceLandmarkerRef.current.detectForVideo(video, now);

            if (results.faceLandmarks && results.faceLandmarks.length > 0) {
                // ì–¼êµ´ ê°ì§€ë¨ - refì— ì €ì¥ (ë¦¬ë Œë”ë§ ì—†ìŒ)
                latestDataRef.current.isFaceDetected = true;
                latestDataRef.current.faceCount = results.faceLandmarks.length;
                latestDataRef.current.detectedFaces = results.faceLandmarks;

                // ì²« ë²ˆì§¸ ì–¼êµ´ ê¸°ì¤€ ë¶„ì„
                const primaryLandmarks = results.faceLandmarks[0];

                // 3D ì–¼êµ´ ë°©í–¥
                latestDataRef.current.headPose = calculateHeadPose(primaryLandmarks);

                // ì‹œì„  ì¶”ì •
                latestDataRef.current.gazePosition = estimateGazeFromIris(primaryLandmarks, video.videoWidth, video.videoHeight);

                // ëˆˆ ìƒíƒœ ë¶„ì„
                const eye = analyzeEyeState(primaryLandmarks);
                latestDataRef.current.eyeState = eye;

                // í™ì±„ ìœ„ì¹˜
                latestDataRef.current.irisPosition = extractIrisPosition(primaryLandmarks);

                // ì¡¸ìŒ ê°ì§€
                const drowsiness = detectDrowsiness(eye.avgEAR);
                latestDataRef.current.drowsinessState = drowsiness;

                // NO_FACE ë¦¬ì…‹ (ì´ì „ì— ì–¼êµ´ì´ ì—†ì—ˆë‹¤ê°€ ê°ì§€ëœ ê²½ìš°ë§Œ ë¡œê·¸)
                if (noFaceStartTimeRef.current !== null) {
                    console.log('âœ… Face detected - resetting NO_FACE tracking');
                    noFaceStartTimeRef.current = null;
                    latestDataRef.current.noFaceDuration = 0;
                    latestDataRef.current.showNoFaceWarning = false;
                    warningShownRef.current = false;
                    sustainedViolationSentRef.current = false;
                }

                // ë‹¤ì¤‘ ì¸ë¬¼ ê²½ê³  (2ëª… ì´ìƒ)
                if (results.faceLandmarks.length > 1 && sessionId) {
                    sendMonitoringViolation(sessionId, 'MULTIPLE_FACES', {
                        description: `Multiple faces detected: ${results.faceLandmarks.length} people`,
                        faceCount: results.faceLandmarks.length
                    }).catch(err => {
                        console.warn('MULTIPLE_FACES violation send failed:', err);
                    });
                }

                // ì¡¸ìŒ ìœ„ë°˜ ì „ì†¡ (1íšŒ)
                if (drowsiness.isDrowsy && !drowsyViolationSentRef.current && sessionId) {
                    drowsyViolationSentRef.current = true;
                    sendMonitoringViolation(sessionId, 'DROWSINESS_DETECTED', {
                        description: `Drowsiness detected - PERCLOS: ${(drowsiness.perclos * 100).toFixed(1)}%`,
                        perclos: drowsiness.perclos
                    }).catch(err => {
                        console.warn('DROWSINESS violation send failed:', err);
                    });
                }

                // ì¡¸ìŒ ìƒíƒœ í•´ì œ ì‹œ í”Œë˜ê·¸ ë¦¬ì…‹
                if (!drowsiness.isDrowsy && drowsyViolationSentRef.current) {
                    drowsyViolationSentRef.current = false;
                }

            } else {
                // ì–¼êµ´ ë¯¸ê²€ì¶œ - refì— ì €ì¥
                latestDataRef.current.isFaceDetected = false;
                latestDataRef.current.faceCount = 0;
                latestDataRef.current.detectedFaces = [];

                // NO_FACE ì§€ì† ì‹œê°„ ì¶”ì 
                const currentTime = Date.now();
                if (noFaceStartTimeRef.current === null) {
                    noFaceStartTimeRef.current = currentTime;
                    console.log('âš ï¸ Face not detected - starting NO_FACE tracking');
                }

                const duration = currentTime - noFaceStartTimeRef.current;
                // refì— ì €ì¥ (throttled ì—…ë°ì´íŠ¸ì—ì„œ React ìƒíƒœë¡œ ë°˜ì˜ë¨)
                latestDataRef.current.noFaceDuration = duration;

                // 5ì´ˆ ì´ìƒ: ê²½ê³  í‘œì‹œ
                if (duration >= NO_FACE_WARNING_THRESHOLD_MS && !warningShownRef.current) {
                    warningShownRef.current = true;
                    latestDataRef.current.showNoFaceWarning = true;
                    console.log('âš ï¸ NO_FACE warning shown (5+ seconds)');

                    if (sessionId) {
                        recordMonitoringWarning(sessionId).catch(err => {
                            console.warn('Warning record failed:', err);
                        });
                    }
                }

                // 15ì´ˆ ì´ìƒ: ì‹¬ê°í•œ ìœ„ë°˜
                if (duration >= NO_FACE_THRESHOLD_MS && !sustainedViolationSentRef.current && sessionId) {
                    sustainedViolationSentRef.current = true;
                    console.log('ğŸš¨ NO_FACE_SUSTAINED violation sent (15+ seconds)');

                    sendMonitoringViolation(sessionId, 'NO_FACE_SUSTAINED', {
                        description: `Face not detected for ${Math.round(duration / 1000)} seconds - serious violation`,
                        duration: Math.round(duration / 1000),
                        severity: 'HIGH'
                    }).catch(err => {
                        console.warn('NO_FACE_SUSTAINED violation send failed:', err);
                    });
                }
            }

            // Throttled ìƒíƒœ ì—…ë°ì´íŠ¸ (100msë§ˆë‹¤ = 10fps)
            if (now - lastStateUpdateRef.current >= STATE_UPDATE_INTERVAL_MS) {
                lastStateUpdateRef.current = now;
                updateReactState();
            }

            // ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° (ref ì‚¬ìš©ìœ¼ë¡œ ìµœì‹  ìƒíƒœ ë°˜ì˜)
            if (debugModeRef.current && canvasRef.current) {
                drawDebugOverlay(results);
            }

        } catch (error) {
            console.error('Tracking loop error:', error);
        }

        // ë‹¤ìŒ í”„ë ˆì„ ì˜ˆì•½
        if (!isCleaningUpRef.current) {
            animationFrameRef.current = requestAnimationFrame(trackingLoop);
        }
    }, [
        sessionId,
        calculateHeadPose,
        estimateGazeFromIris,
        analyzeEyeState,
        extractIrisPosition,
        detectDrowsiness,
        updateReactState
    ]);

    // ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
    const drawDebugOverlay = useCallback((results) => {
        const canvas = canvasRef.current;
        const video = videoRef.current;
        if (!canvas || !video) {
            console.warn('drawDebugOverlay: canvas or video not ready', { canvas: !!canvas, video: !!video });
            return;
        }

        // ìº”ë²„ìŠ¤ í¬ê¸°ê°€ ë¹„ë””ì˜¤ì™€ ë§ì§€ ì•Šìœ¼ë©´ ì¡°ì •
        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
            canvas.width = video.videoWidth || 640;
            canvas.height = video.videoHeight || 480;
        }

        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // ë¹„ë””ì˜¤ ê·¸ë¦¬ê¸° (ê±°ìš¸ ëª¨ë“œ) - í•­ìƒ ê·¸ë¦¬ê¸°
        ctx.save();
        ctx.scale(-1, 1);
        ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
        ctx.restore();

        if (results && results.faceLandmarks) {
            results.faceLandmarks.forEach((landmarks, faceIndex) => {
                const color = faceIndex === 0 ? '#22c55e' : '#f59e0b'; // ì²« ë²ˆì§¸: ì´ˆë¡, ë‚˜ë¨¸ì§€: ì£¼í™©

                // ëª¨ë“  ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                landmarks.forEach((landmark, idx) => {
                    const x = (1 - landmark.x) * canvas.width; // ê±°ìš¸ ëª¨ë“œ
                    const y = landmark.y * canvas.height;

                    // í™ì±„ í¬ì¸íŠ¸ëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ
                    const isIris = [...LANDMARK_INDICES.LEFT_IRIS, ...LANDMARK_INDICES.RIGHT_IRIS].includes(idx);
                    ctx.fillStyle = isIris ? '#ef4444' : color;
                    ctx.beginPath();
                    ctx.arc(x, y, isIris ? 3 : 1, 0, 2 * Math.PI);
                    ctx.fill();
                });

                // ëˆˆ ì˜ì—­ í‘œì‹œ
                const leftEye = [
                    LANDMARK_INDICES.LEFT_EYE.P1,
                    LANDMARK_INDICES.LEFT_EYE.P2,
                    LANDMARK_INDICES.LEFT_EYE.P3,
                    LANDMARK_INDICES.LEFT_EYE.P4,
                    LANDMARK_INDICES.LEFT_EYE.P5,
                    LANDMARK_INDICES.LEFT_EYE.P6
                ];
                const rightEye = [
                    LANDMARK_INDICES.RIGHT_EYE.P1,
                    LANDMARK_INDICES.RIGHT_EYE.P2,
                    LANDMARK_INDICES.RIGHT_EYE.P3,
                    LANDMARK_INDICES.RIGHT_EYE.P4,
                    LANDMARK_INDICES.RIGHT_EYE.P5,
                    LANDMARK_INDICES.RIGHT_EYE.P6
                ];

                [leftEye, rightEye].forEach(eyeIndices => {
                    ctx.beginPath();
                    ctx.strokeStyle = '#3b82f6';
                    ctx.lineWidth = 2;
                    eyeIndices.forEach((idx, i) => {
                        const lm = landmarks[idx];
                        const x = (1 - lm.x) * canvas.width;
                        const y = lm.y * canvas.height;
                        if (i === 0) ctx.moveTo(x, y);
                        else ctx.lineTo(x, y);
                    });
                    ctx.closePath();
                    ctx.stroke();
                });
            });
        }

        // ì •ë³´ ì˜¤ë²„ë ˆì´ (refì—ì„œ ìµœì‹  ë°ì´í„° ì½ê¸° - ë¦¬ë Œë”ë§ ì˜ì¡´ì„± ì œê±°)
        const data = latestDataRef.current;
        ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
        ctx.fillRect(10, 10, 260, 180);
        ctx.fillStyle = '#ffffff';
        ctx.font = '12px monospace';

        // null ì•ˆì „ ì²˜ë¦¬
        const leftEAR = data.eyeState?.leftEAR;
        const rightEAR = data.eyeState?.rightEAR;
        const earText = leftEAR !== null && leftEAR !== undefined
            ? `L=${leftEAR.toFixed(3)} R=${rightEAR.toFixed(3)}`
            : 'N/A (no face)';

        const lines = [
            `Faces: ${data.faceCount}`,
            `Face Detected: ${data.isFaceDetected ? 'âœ… YES' : 'âŒ NO'}`,
            `EAR: ${earText}`,
            `Blink: ${data.eyeState?.isBlinking ? 'YES' : 'NO'}`,
            `PERCLOS: ${(data.drowsinessState?.perclos * 100 || 0).toFixed(1)}%`,
            `Drowsy: ${data.drowsinessState?.isDrowsy ? 'âš ï¸ YES' : 'NO'}`,
            `Head: P=${data.headPose?.pitch?.toFixed(1) || 0}Â° Y=${data.headPose?.yaw?.toFixed(1) || 0}Â° R=${data.headPose?.roll?.toFixed(1) || 0}Â°`,
            `Gaze: (${Math.round(data.gazePosition?.x || 0)}, ${Math.round(data.gazePosition?.y || 0)})`
        ];

        lines.forEach((line, i) => {
            ctx.fillText(line, 20, 30 + i * 18);
        });

    }, []); // ì˜ì¡´ì„± ì œê±° - ref ì‚¬ìš©ìœ¼ë¡œ í•­ìƒ ìµœì‹  ë°ì´í„°

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘ (MediaPipeëŠ” ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë¶ˆí•„ìš”)
    const startCalibration = useCallback(() => {
        console.log('MediaPipe calibration ready (no calibration needed)');
    }, []);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ
    const completeCalibration = useCallback(() => {
        setIsCalibrated(true);
    }, []);

    // ì¶”ì  ì‹œì‘
    const startTracking = useCallback(async () => {
        if (!isCalibrated || !problemId) return;

        isCleaningUpRef.current = false;

        // ì›¹ìº  ì„¤ì •
        const webcamReady = await setupWebcam();
        if (!webcamReady) {
            console.error('Failed to setup webcam');
            return;
        }

        try {
            // ì„¸ì…˜ ì‹œì‘
            const response = await startMonitoringSession(problemId, timeLimitMinutes);
            const newSessionId = response.data?.sessionId || response.sessionId;
            setSessionId(newSessionId);
            setIsTracking(true);

            console.log('ğŸ¯ MediaPipe monitoring session started, sessionId:', newSessionId);

            // ì¶”ì  ë£¨í”„ ì‹œì‘
            trackingLoop();

        } catch (error) {
            console.error('Failed to start monitoring session:', error);
        }
    }, [isCalibrated, problemId, timeLimitMinutes, setupWebcam, trackingLoop]);

    // ì¶”ì  ì¢…ë£Œ
    const stopTracking = useCallback(async (remainingSeconds = null) => {
        if (isCleaningUpRef.current) {
            console.log('âš ï¸ stopTracking already in progress, skipping...');
            return;
        }
        isCleaningUpRef.current = true;

        try {
            // ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ì·¨ì†Œ
            if (animationFrameRef.current) {
                cancelAnimationFrame(animationFrameRef.current);
                animationFrameRef.current = null;
            }

            // ì„¸ì…˜ ì¢…ë£Œ
            if (sessionId) {
                try {
                    await endMonitoringSession(sessionId, remainingSeconds);
                    console.log('âœ… Monitoring session ended, sessionId:', sessionId);
                } catch (error) {
                    console.error('Failed to end monitoring session:', error);
                }
            }

            // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
            if (videoRef.current?.srcObject) {
                const tracks = videoRef.current.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                videoRef.current.srcObject = null;
            }

            // DOM ìš”ì†Œ ì •ë¦¬
            const debugContainer = document.getElementById('mediapipeDebugContainer');
            if (debugContainer) {
                debugContainer.remove();
            }

            // ì‹œì„  ë„íŠ¸ ì œê±°
            const gazeDot = document.getElementById('mediapipeGazeDot');
            if (gazeDot) {
                gazeDot.remove();
            }

            console.log('âœ… MediaPipe tracking stopped');

            setIsTracking(false);
            setSessionId(null);

            // ìƒíƒœ ë¦¬ì…‹
            noFaceStartTimeRef.current = null;
            latestDataRef.current.noFaceDuration = 0;
            latestDataRef.current.showNoFaceWarning = false;
            setNoFaceDuration(0);
            setShowNoFaceWarning(false);
            warningShownRef.current = false;
            sustainedViolationSentRef.current = false;
            drowsyViolationSentRef.current = false;
            earHistoryRef.current = [];
            closedFrameCountRef.current = 0;

        } catch (error) {
            console.error('Error during stopTracking:', error);
        }
    }, [sessionId]);

    // ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
    const toggleDebugMode = useCallback(() => {
        const newDebugMode = !debugModeRef.current;
        debugModeRef.current = newDebugMode; // ref ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (tracking loopì—ì„œ ì‚¬ìš©)
        setDebugMode(newDebugMode); // ìƒíƒœë„ ì—…ë°ì´íŠ¸ (UI ë°˜ì˜)

        if (newDebugMode) {
            // ë””ë²„ê·¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            setTimeout(() => {
                let container = document.getElementById('mediapipeDebugContainer');
                if (!container) {
                    container = document.createElement('div');
                    container.id = 'mediapipeDebugContainer';
                    container.style.cssText = `
                        position: fixed;
                        top: 120px;
                        left: 20px;
                        z-index: 10000;
                        border: 4px solid #22c55e;
                        border-radius: 12px;
                        overflow: hidden;
                        box-shadow: 0 4px 20px rgba(34, 197, 94, 0.4);
                        background: #18181b;
                        width: 320px;
                        height: 240px;
                    `;
                    document.body.appendChild(container);
                }

                // ìº”ë²„ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
                if (!canvasRef.current && videoRef.current) {
                    const canvas = document.createElement('canvas');
                    canvas.id = 'mediapipeOverlay';
                    canvas.width = videoRef.current.videoWidth || 640;
                    canvas.height = videoRef.current.videoHeight || 480;
                    canvasRef.current = canvas;
                }

                if (canvasRef.current) {
                    canvasRef.current.style.cssText = `
                        width: 100%;
                        height: 100%;
                        object-fit: cover;
                    `;
                    // ì´ë¯¸ ì»¨í…Œì´ë„ˆì— ìˆëŠ”ì§€ í™•ì¸
                    if (!container.contains(canvasRef.current)) {
                        container.appendChild(canvasRef.current);
                    }
                }

                // ì‹œì„  ë„íŠ¸ ìƒì„±
                let gazeDot = document.getElementById('mediapipeGazeDot');
                if (!gazeDot) {
                    gazeDot = document.createElement('div');
                    gazeDot.id = 'mediapipeGazeDot';
                    gazeDot.style.cssText = `
                        position: fixed;
                        width: 40px;
                        height: 40px;
                        margin-left: -20px;
                        margin-top: -20px;
                        border-radius: 50%;
                        background: #ef4444;
                        border: 4px solid #ffffff;
                        box-shadow: 0 0 30px rgba(239, 68, 68, 1), 0 0 60px rgba(239, 68, 68, 0.5);
                        pointer-events: none;
                        z-index: 999999;
                        transition: left 0.05s ease-out, top 0.05s ease-out;
                    `;
                    document.body.appendChild(gazeDot);
                }

                console.log('ğŸ”§ MediaPipe Debug mode ON', {
                    hasVideo: !!videoRef.current,
                    hasCanvas: !!canvasRef.current,
                    videoSize: videoRef.current ? `${videoRef.current.videoWidth}x${videoRef.current.videoHeight}` : 'N/A'
                });
            }, 100);
        } else {
            // ë””ë²„ê·¸ ìš”ì†Œ ì œê±° (ìº”ë²„ìŠ¤ëŠ” ìœ ì§€, ì»¨í…Œì´ë„ˆë§Œ ì œê±°)
            const container = document.getElementById('mediapipeDebugContainer');
            if (container) {
                // ìº”ë²„ìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì—ì„œ ë¶„ë¦¬ (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
                if (canvasRef.current && container.contains(canvasRef.current)) {
                    container.removeChild(canvasRef.current);
                }
                container.remove();
            }

            const gazeDot = document.getElementById('mediapipeGazeDot');
            if (gazeDot) gazeDot.remove();

            console.log('ğŸ”§ MediaPipe Debug mode OFF');
        }
    }, []);

    // ì‹œì„  ë„íŠ¸ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
    useEffect(() => {
        if (!debugMode) return;

        const gazeDot = document.getElementById('mediapipeGazeDot');
        if (gazeDot && gazePosition) {
            gazeDot.style.left = `${gazePosition.x}px`;
            gazeDot.style.top = `${gazePosition.y}px`;
        }
    }, [debugMode, gazePosition]);

    // ì–¼êµ´ ê°ì§€ ìƒíƒœì— ë”°ë¥¸ ì»¨í…Œì´ë„ˆ í…Œë‘ë¦¬ ìƒ‰ìƒ
    useEffect(() => {
        if (!debugMode) return;

        const container = document.getElementById('mediapipeDebugContainer');
        if (!container) return;

        if (!isFaceDetected) {
            container.style.borderColor = '#ef4444';
            container.style.boxShadow = '0 4px 20px rgba(239, 68, 68, 0.6)';
        } else {
            container.style.borderColor = '#22c55e';
            container.style.boxShadow = '0 4px 20px rgba(34, 197, 94, 0.4)';
        }
    }, [debugMode, isFaceDetected]);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì‹œ ìë™ ì¶”ì  ì‹œì‘
    useEffect(() => {
        if (isCalibrated && !isTracking && problemId) {
            startTracking();
        }
    }, [isCalibrated, isTracking, problemId, startTracking]);

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    useEffect(() => {
        return () => {
            if (animationFrameRef.current) {
                cancelAnimationFrame(animationFrameRef.current);
            }
            if (videoRef.current?.srcObject) {
                const tracks = videoRef.current.srcObject.getTracks();
                tracks.forEach(track => track.stop());
            }
        };
    }, []);

    return {
        // ê¸°ë³¸ (WebGazer í˜¸í™˜)
        isCalibrated,
        isTracking,
        sessionId,
        monitoringSessionId: sessionId,
        startCalibration,
        completeCalibration,
        stopTracking,

        // NO_FACE ìƒíƒœ (WebGazer í˜¸í™˜)
        noFaceDuration,
        showNoFaceWarning,
        noFaceProgress: noFaceDuration / NO_FACE_THRESHOLD_MS,

        // ë””ë²„ê·¸ (WebGazer í˜¸í™˜)
        debugMode,
        toggleDebugMode,
        isFaceDetected,

        // MediaPipe ì¶”ê°€ ê¸°ëŠ¥
        faceCount,              // ê°ì§€ëœ ì–¼êµ´ ìˆ˜
        detectedFaces,          // ëª¨ë“  ê°ì§€ëœ ì–¼êµ´ ëœë“œë§ˆí¬
        headPose,               // 3D ì–¼êµ´ ë°©í–¥ { pitch, yaw, roll }
        gazePosition,           // ì¶”ì •ëœ ì‹œì„  ìœ„ì¹˜ { x, y }
        eyeState,               // ëˆˆ ìƒíƒœ { leftEAR, rightEAR, avgEAR, isBlinking }
        irisPosition,           // í™ì±„ ìœ„ì¹˜ { left, right }
        drowsinessState         // ì¡¸ìŒ ìƒíƒœ { isDrowsy, perclos, consecutiveClosedFrames }
    };
};
