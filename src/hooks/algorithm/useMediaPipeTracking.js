import { useState, useEffect, useCallback, useRef } from 'react';
import {
    startMonitoringSession,
    sendMonitoringViolation,
    endMonitoringSession,
    recordMonitoringWarning
} from '../../service/algorithm/algorithmApi';

/**
 * MediaPipe ê¸°ë°˜ ì‹œì„ /ì–¼êµ´ ì¶”ì  ì»¤ìŠ¤í…€ í›…
 *
 * WebGazer ëŒ€ì•ˆìœ¼ë¡œ MediaPipe Face Landmarker ì‚¬ìš©
 * ì¶”ê°€ ê¸°ëŠ¥: ì¡¸ìŒ ê°ì§€, ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€, 3D ì–¼êµ´ ë°©í–¥, í™ì±„ ì¶”ì 
 *
 * @param {number} problemId - í˜„ì¬ ë¬¸ì œ ID
 * @param {boolean} isActive - ì¶”ì  í™œì„±í™” ì—¬ë¶€
 * @param {number} timeLimitMinutes - ì œí•œ ì‹œê°„ (ë¶„, ê¸°ë³¸ 30ë¶„)
 * @returns {object} - ì¶”ì  ìƒíƒœ ë° ì œì–´ í•¨ìˆ˜
 */

// ìƒìˆ˜ ì •ì˜
const NO_FACE_THRESHOLD_MS = 15000; // 15ì´ˆ ì´ìƒ NO_FACE ì‹œ ì‹¬ê°í•œ ìœ„ë°˜
const NO_FACE_WARNING_THRESHOLD_MS = 5000; // 5ì´ˆ ì´ìƒ ì‹œ ê²½ê³  í‘œì‹œ ì‹œì‘

// ì¡¸ìŒ ê°ì§€ ìƒìˆ˜
const EAR_THRESHOLD = 0.20; // Eye Aspect Ratio ì„ê³„ê°’ (ëˆˆ ê°ê¹€ íŒë‹¨) - 0.25ì—ì„œ í•˜í–¥ (ë” í™•ì‹¤í•œ ëˆˆ ê°ê¹€ë§Œ ê°ì§€)
const DROWSY_FRAME_THRESHOLD = 90; // ì—°ì† í”„ë ˆì„ ìˆ˜ (90í”„ë ˆì„ â‰ˆ 3ì´ˆ) - 30ì—ì„œ ìƒí–¥ (ì˜¤íƒ ê°ì†Œ)
const PERCLOS_THRESHOLD = 0.8; // PERCLOS ì„ê³„ê°’ (80% ì´ìƒ ì‹œ ì¡¸ìŒ)
const PERCLOS_WINDOW_SECONDS = 60; // PERCLOS ê³„ì‚° ìœˆë„ìš° (60ì´ˆ)

// MediaPipe ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (478ê°œ ì¤‘ ì£¼ìš” í¬ì¸íŠ¸)
const LANDMARK_INDICES = {
    // ëˆˆ (Eye Aspect Ratio ê³„ì‚°ìš©)
    LEFT_EYE: {
        P1: 33,   // ì™¼ìª½ ë
        P2: 160,  // ìƒë‹¨ 1
        P3: 158,  // ìƒë‹¨ 2
        P4: 133,  // ì˜¤ë¥¸ìª½ ë
        P5: 153,  // í•˜ë‹¨ 1
        P6: 144   // í•˜ë‹¨ 2
    },
    RIGHT_EYE: {
        P1: 362,  // ì™¼ìª½ ë
        P2: 385,  // ìƒë‹¨ 1
        P3: 387,  // ìƒë‹¨ 2
        P4: 263,  // ì˜¤ë¥¸ìª½ ë
        P5: 373,  // í•˜ë‹¨ 1
        P6: 380   // í•˜ë‹¨ 2
    },
    // í™ì±„ (Iris)
    LEFT_IRIS: [468, 469, 470, 471, 472],  // ì™¼ìª½ í™ì±„ ì¤‘ì‹¬ ë° ì£¼ë³€
    RIGHT_IRIS: [473, 474, 475, 476, 477], // ì˜¤ë¥¸ìª½ í™ì±„ ì¤‘ì‹¬ ë° ì£¼ë³€
    // ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš©
    NOSE_TIP: 1,
    CHIN: 152,
    LEFT_EYE_OUTER: 33,
    RIGHT_EYE_OUTER: 263,
    LEFT_MOUTH_CORNER: 61,
    RIGHT_MOUTH_CORNER: 291
};

// ìœ í‹¸ë¦¬í‹°: ë‘ ì  ì‚¬ì´ ê±°ë¦¬ ê³„ì‚°
const distance = (p1, p2) => {
    return Math.sqrt(
        Math.pow(p2.x - p1.x, 2) +
        Math.pow(p2.y - p1.y, 2) +
        Math.pow((p2.z || 0) - (p1.z || 0), 2)
    );
};

// Eye Aspect Ratio (EAR) ê³„ì‚°
const calculateEAR = (eyeLandmarks) => {
    const { P1, P2, P3, P4, P5, P6 } = eyeLandmarks;
    const vertical1 = distance(P2, P6);
    const vertical2 = distance(P3, P5);
    const horizontal = distance(P1, P4);
    return (vertical1 + vertical2) / (2.0 * horizontal);
};

// ========== Kalman Filter for 2D Gaze Tracking ==========
// State: [x, y, vx, vy] (position + velocity)
// Measurement: [x, y] (position only)
class KalmanFilter2D {
    constructor() {
        // ìƒíƒœ ë²¡í„°: [x, y, vx, vy]
        this.state = {
            x: window.innerWidth / 2,
            y: window.innerHeight / 2,
            vx: 0,
            vy: 0
        };

        // ì˜¤ì°¨ ê³µë¶„ì‚° í–‰ë ¬ P (4x4, ëŒ€ê°ì„ ë§Œ ì‚¬ìš© - ë‹¨ìˆœí™”)
        this.P = {
            x: 1000,   // ì´ˆê¸° ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„± (í° ê°’)
            y: 1000,
            vx: 1000,  // ì´ˆê¸° ì†ë„ ë¶ˆí™•ì‹¤ì„±
            vy: 1000
        };

        // í”„ë¡œì„¸ìŠ¤ ë…¸ì´ì¦ˆ Q (ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±)
        // ê°’ì´ í´ìˆ˜ë¡ ì¸¡ì •ê°’ì„ ë” ì‹ ë¢°
        this.Q = {
            x: 0.1,    // ìœ„ì¹˜ ë…¸ì´ì¦ˆ
            y: 0.1,
            vx: 1.0,   // ì†ë„ ë…¸ì´ì¦ˆ (ê°€ì† í—ˆìš©)
            vy: 1.0
        };

        // ì¸¡ì • ë…¸ì´ì¦ˆ R (ì¸¡ì •ê°’ ë¶ˆí™•ì‹¤ì„±)
        // ê°’ì´ í´ìˆ˜ë¡ ì˜ˆì¸¡ê°’ì„ ë” ì‹ ë¢° (ìŠ¤ë¬´ë”© íš¨ê³¼ ì¦ê°€)
        // ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¸¡ì •ê°’ì„ ë” ì‹ ë¢° (ë°˜ì‘ ì†ë„ ì¦ê°€)
        this.R = {
            x: 20,     // ì‹œì„  ì¸¡ì • ë…¸ì´ì¦ˆ (í”½ì…€ ë‹¨ìœ„) - 50ì—ì„œ 20ìœ¼ë¡œ ê°ì†Œ (ë°˜ì‘ì„± í–¥ìƒ)
            y: 20
        };

        this.lastTime = performance.now();
        this.initialized = false;
    }

    // ì˜ˆì¸¡ ë‹¨ê³„ (Predict)
    predict(dt = null) {
        const now = performance.now();
        if (dt === null) {
            dt = (now - this.lastTime) / 1000; // ì´ˆ ë‹¨ìœ„
        }
        this.lastTime = now;

        // dtê°€ ë„ˆë¬´ í¬ë©´ (0.5ì´ˆ ì´ìƒ) ë¦¬ì…‹
        if (dt > 0.5) {
            dt = 0.033; // 30fps ê¸°ì¤€
        }

        // ìƒíƒœ ì „ì´: x' = x + vx * dt
        this.state.x += this.state.vx * dt;
        this.state.y += this.state.vy * dt;

        // ìœ„ì¹˜ ê²½ê³„ í´ë¨í•‘ (í™”ë©´ ë°–ìœ¼ë¡œ ë„ˆë¬´ ë©€ë¦¬ ë‚˜ê°€ì§€ ì•Šë„ë¡)
        const MARGIN = 200;
        this.state.x = Math.max(-MARGIN, Math.min(this.state.x, window.innerWidth + MARGIN));
        this.state.y = Math.max(-MARGIN, Math.min(this.state.y, window.innerHeight + MARGIN));

        // ì˜¤ì°¨ ê³µë¶„ì‚° ì—…ë°ì´íŠ¸: P' = F * P * F^T + Q
        // ë‹¨ìˆœí™”ëœ ë²„ì „ (ëŒ€ê° í–‰ë ¬ ê°€ì •)
        this.P.x += this.P.vx * dt * dt + this.Q.x;
        this.P.y += this.P.vy * dt * dt + this.Q.y;
        this.P.vx += this.Q.vx;
        this.P.vy += this.Q.vy;

        return { x: this.state.x, y: this.state.y };
    }

    // ì—…ë°ì´íŠ¸ ë‹¨ê³„ (Update/Correct)
    update(measurementX, measurementY) {
        if (!this.initialized) {
            // ì²« ì¸¡ì •ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            this.state.x = measurementX;
            this.state.y = measurementY;
            this.state.vx = 0;
            this.state.vy = 0;
            this.initialized = true;
            return { x: measurementX, y: measurementY };
        }

        // ì¹¼ë§Œ ì´ë“ ê³„ì‚°: K = P * H^T * (H * P * H^T + R)^-1
        // H = [[1, 0, 0, 0], [0, 1, 0, 0]] (ìœ„ì¹˜ë§Œ ì¸¡ì •)
        const Kx = this.P.x / (this.P.x + this.R.x);
        const Ky = this.P.y / (this.P.y + this.R.y);

        // ì†ë„ì— ëŒ€í•œ ì¹¼ë§Œ ì´ë“ (ìœ„ì¹˜ ì”ì°¨ì—ì„œ ì†ë„ ì¶”ì •)
        const Kvx = this.P.vx / (this.P.x + this.R.x) * 0.5;
        const Kvy = this.P.vy / (this.P.y + this.R.y) * 0.5;

        // ì”ì°¨ (Innovation): y = z - H * x
        let residualX = measurementX - this.state.x;
        let residualY = measurementY - this.state.y;

        // ì”ì°¨ í´ë¨í•‘ (ë„ˆë¬´ í° ì í”„ ë°©ì§€ - í™”ë©´ 1/2 ì´ìƒ ì í”„ ì œí•œ)
        // 1/3 â†’ 1/2ë¡œ ë³€ê²½: ë¹ ë¥¸ ì‹œì„  ì´ë™ í—ˆìš© ë²”ìœ„ í™•ëŒ€
        const MAX_RESIDUAL = Math.max(window.innerWidth, window.innerHeight) / 2;
        residualX = Math.max(-MAX_RESIDUAL, Math.min(MAX_RESIDUAL, residualX));
        residualY = Math.max(-MAX_RESIDUAL, Math.min(MAX_RESIDUAL, residualY));

        // ìƒíƒœ ì—…ë°ì´íŠ¸: x = x + K * y
        this.state.x += Kx * residualX;
        this.state.y += Ky * residualY;

        // ì†ë„ ì—…ë°ì´íŠ¸ (ì”ì°¨ ê¸°ë°˜)
        this.state.vx += Kvx * residualX;
        this.state.vy += Kvy * residualY;

        // ì†ë„ í´ë¨í•‘ (í­ì£¼ ë°©ì§€ - 1ì´ˆì— í™”ë©´ 1ë°° ì´ìƒ ì´ë™ ë¶ˆê°€)
        const MAX_VELOCITY = window.innerWidth;
        this.state.vx = Math.max(-MAX_VELOCITY, Math.min(MAX_VELOCITY, this.state.vx));
        this.state.vy = Math.max(-MAX_VELOCITY, Math.min(MAX_VELOCITY, this.state.vy));

        // ì†ë„ ê°ì‡  (ì„œì„œíˆ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ë„ë¡ - ì•ˆì •ì„±)
        // 0.95 â†’ 0.98ë¡œ ë³€ê²½: ê°ì‡ ë¥¼ ì¤„ì—¬ ë¹ ë¥¸ ì›€ì§ì„ ì¶”ì  ê°œì„ 
        this.state.vx *= 0.98;
        this.state.vy *= 0.98;

        // ì˜¤ì°¨ ê³µë¶„ì‚° ì—…ë°ì´íŠ¸: P = (I - K * H) * P
        this.P.x *= (1 - Kx);
        this.P.y *= (1 - Ky);
        this.P.vx *= (1 - Kvx * 0.3);
        this.P.vy *= (1 - Kvy * 0.3);

        // ê³µë¶„ì‚° í´ë¨í•‘ (ìˆ˜ì¹˜ ì•ˆì •ì„±)
        const MIN_P = 0.01;
        const MAX_P = 10000;
        this.P.x = Math.max(MIN_P, Math.min(MAX_P, this.P.x));
        this.P.y = Math.max(MIN_P, Math.min(MAX_P, this.P.y));
        this.P.vx = Math.max(MIN_P, Math.min(MAX_P, this.P.vx));
        this.P.vy = Math.max(MIN_P, Math.min(MAX_P, this.P.vy));

        // ìµœì¢… NaN ì²´í¬ (ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°)
        if (!Number.isFinite(this.state.x) || !Number.isFinite(this.state.y) ||
            !Number.isFinite(this.state.vx) || !Number.isFinite(this.state.vy) ||
            !Number.isFinite(this.P.x) || !Number.isFinite(this.P.y)) {
            console.error('ğŸš¨ Kalman state became NaN/Infinity, resetting...');
            this.reset();
            return { x: window.innerWidth / 2, y: window.innerHeight / 2 };
        }

        return { x: this.state.x, y: this.state.y };
    }

    // ì˜ˆì¸¡ + ì—…ë°ì´íŠ¸ í•œë²ˆì— (ì¼ë°˜ì ì¸ ì‚¬ìš©)
    filter(measurementX, measurementY) {
        // NaN/Infinity ê²€ì¦ - ì˜ëª»ëœ ì…ë ¥ ë°©ì§€
        if (!Number.isFinite(measurementX) || !Number.isFinite(measurementY)) {
            console.warn('âš ï¸ Kalman filter received invalid input:', { measurementX, measurementY });
            // í˜„ì¬ ìƒíƒœ ë°˜í™˜ (ì˜ˆì¸¡ë§Œ ìˆ˜í–‰)
            this.predict();
            return { x: this.state.x, y: this.state.y };
        }

        this.predict();
        const result = this.update(measurementX, measurementY);

        // ê²°ê³¼ NaN ê²€ì¦
        if (!Number.isFinite(result.x) || !Number.isFinite(result.y)) {
            console.error('ğŸš¨ Kalman filter produced NaN, resetting...');
            this.reset();
            return { x: window.innerWidth / 2, y: window.innerHeight / 2 };
        }

        return result;
    }

    // í˜„ì¬ ìƒíƒœ ë°˜í™˜
    getState() {
        return { ...this.state };
    }

    // í•„í„° ë¦¬ì…‹
    reset() {
        this.state = {
            x: window.innerWidth / 2,
            y: window.innerHeight / 2,
            vx: 0,
            vy: 0
        };
        this.P = { x: 1000, y: 1000, vx: 1000, vy: 1000 };
        this.initialized = false;
        this.lastTime = performance.now();
    }

    // ì¸¡ì • ë…¸ì´ì¦ˆ ì¡°ì • (ë™ì  ì¡°ì •ìš©)
    setMeasurementNoise(rx, ry) {
        this.R.x = rx;
        this.R.y = ry;
    }
}

export const useMediaPipeTracking = (problemId, isActive = false, timeLimitMinutes = 30) => {
    // ê¸°ë³¸ ìƒíƒœ
    const [isCalibrated, setIsCalibrated] = useState(false);
    const [isTracking, setIsTracking] = useState(false);
    const [sessionId, setSessionId] = useState(null);

    // NO_FACE ìƒíƒœ
    const noFaceStartTimeRef = useRef(null);
    const [noFaceDuration, setNoFaceDuration] = useState(0);
    const [showNoFaceWarning, setShowNoFaceWarning] = useState(false);
    const warningShownRef = useRef(false);
    const sustainedViolationSentRef = useRef(false);

    // ë””ë²„ê·¸ ëª¨ë“œ
    const [debugMode, setDebugMode] = useState(false);
    const debugModeRef = useRef(false); // tracking loopì—ì„œ ì‚¬ìš©í•  ref
    const [isFaceDetected, setIsFaceDetected] = useState(true);

    // MediaPipe ê´€ë ¨ ìƒíƒœ
    const faceLandmarkerRef = useRef(null);
    const videoRef = useRef(null);
    const canvasRef = useRef(null);
    const animationFrameRef = useRef(null);
    const isCleaningUpRef = useRef(false);

    // ì¶”ê°€ ê¸°ëŠ¥ ìƒíƒœ - UI í‘œì‹œìš© (throttled update)
    const [detectedFaces, setDetectedFaces] = useState([]); // ë‹¤ì¤‘ ì¸ë¬¼
    const [faceCount, setFaceCount] = useState(0);
    const [headPose, setHeadPose] = useState({ pitch: 0, yaw: 0, roll: 0 }); // 3D ì–¼êµ´ ë°©í–¥
    const [gazePosition, setGazePosition] = useState({ x: window.innerWidth / 2, y: window.innerHeight / 2 }); // ì‹œì„  ìœ„ì¹˜
    const [eyeState, setEyeState] = useState({ leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false });
    const [irisPosition, setIrisPosition] = useState({ left: null, right: null });

    // ì¡¸ìŒ ê°ì§€ ìƒíƒœ
    const [drowsinessState, setDrowsinessState] = useState({
        isDrowsy: false,
        perclos: 0,
        consecutiveClosedFrames: 0
    });
    const closedFrameCountRef = useRef(0);
    const earHistoryRef = useRef([]); // PERCLOS ê³„ì‚°ìš©
    const drowsyViolationSentRef = useRef(false);

    // ========== Liveness Detection (ì‚¬ì§„/ì˜ìƒ ê°ì§€) ==========
    // ëˆˆ ê¹œë¹¡ì„ì´ ì¼ì • ì‹œê°„ ë™ì•ˆ ì—†ìœ¼ë©´ ì‚¬ì§„/ì˜ìƒìœ¼ë¡œ íŒì •
    const LIVENESS_BLINK_TIMEOUT_MS = 30000; // 30ì´ˆ ë™ì•ˆ ëˆˆ ê¹œë¹¡ì„ ì—†ìœ¼ë©´ ê²½ê³ 
    const lastBlinkTimeRef = useRef(Date.now()); // ë§ˆì§€ë§‰ ëˆˆ ê¹œë¹¡ì„ ì‹œê°„
    const wasBlinkingRef = useRef(false); // ì´ì „ í”„ë ˆì„ ëˆˆ ê°ê¹€ ìƒíƒœ
    const [livenessWarning, setLivenessWarning] = useState(false); // ì‚¬ì§„ ê°ì§€ ê²½ê³ 

    // ê³ ë¹ˆë„ ë°ì´í„°ë¥¼ ìœ„í•œ refs (setState í˜¸ì¶œ ìµœì†Œí™” - Maximum update depth ë°©ì§€)
    const latestDataRef = useRef({
        isFaceDetected: false,
        faceCount: 0,
        detectedFaces: [],
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        gazePosition: { x: window.innerWidth / 2, y: window.innerHeight / 2 },
        eyeState: { leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false },
        irisPosition: { left: null, right: null },
        drowsinessState: { isDrowsy: false, perclos: 0, consecutiveClosedFrames: 0 },
        noFaceDuration: 0,
        showNoFaceWarning: false
    });
    const lastStateUpdateRef = useRef(0);
    const STATE_UPDATE_INTERVAL_MS = 100; // 100msë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (10fps - UIì— ì¶©ë¶„)

    // ========== 3-Point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ==========
    // MediaPipeCalibrationScreenì—ì„œ ì „ë‹¬ë°›ì€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°
    const calibrationDataRef = useRef(null);
    const hasManualCalibrationRef = useRef(false); // ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì—¬ë¶€

    // ========== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (Baseline) - ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ì„ ë•Œ í´ë°± ==========
    // ì‹œì‘ í›„ ì²˜ìŒ ëª‡ í”„ë ˆì„ì˜ í‰ê· ê°’ì„ ê¸°ì¤€ì ìœ¼ë¡œ ì €ì¥
    const CALIBRATION_FRAMES = 30; // 30í”„ë ˆì„ (~1ì´ˆ) ë™ì•ˆ í‰ê·  ê³„ì‚°
    const isBaselineCalibratedRef = useRef(false);
    const baselineRef = useRef({
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        irisOffset: { x: 0, y: 0 } // ì •ë©´ ë³¼ ë•Œ í™ì±„ ì˜¤í”„ì…‹
    });
    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ ëˆ„ì ê°’
    const calibrationAccumulatorRef = useRef({
        headPose: { pitch: 0, yaw: 0, roll: 0 },
        irisOffset: { x: 0, y: 0 },
        count: 0
    });

    // ========== Kalman Filter ìŠ¤ë¬´ë”© (EMA ëŒ€ì²´) ==========
    // ìœ„ì¹˜ + ì†ë„ ê¸°ë°˜ ì˜ˆì¸¡ìœ¼ë¡œ ë” ì•ˆì •ì ì¸ ì‹œì„  ì¶”ì 
    const kalmanFilterRef = useRef(null);

    // Kalman Filter ì´ˆê¸°í™” (lazy initialization)
    const getKalmanFilter = useCallback(() => {
        if (!kalmanFilterRef.current) {
            kalmanFilterRef.current = new KalmanFilter2D();
            console.log('âœ… Kalman Filter initialized');
        }
        return kalmanFilterRef.current;
    }, []);

    // ========== ì–¼êµ´ ê°ì§€ ì•ˆì •í™” (ë””ë°”ìš´ì‹±) ==========
    // ì—°ì† Ní”„ë ˆì„ ë™ì•ˆ ê°™ì€ ìƒíƒœì—¬ì•¼ ë³€ê²½
    const FACE_DETECTION_DEBOUNCE_FRAMES = 3; // 3í”„ë ˆì„ ì—°ì† í•„ìš”
    const faceDetectionCounterRef = useRef({ detected: 0, notDetected: 0 });
    const stableFaceDetectedRef = useRef(false);

    // drawDebugOverlayë¥¼ refë¡œ ê´€ë¦¬ (ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
    const drawDebugOverlayRef = useRef(null);

    // MediaPipe FaceLandmarker ì´ˆê¸°í™”
    useEffect(() => {
        if (!isActive) return;

        const initMediaPipe = async () => {
            try {
                // MediaPipe Vision ë™ì  ë¡œë“œ
                const vision = await import('@mediapipe/tasks-vision');
                const { FaceLandmarker, FilesetResolver } = vision;

                // WASM íŒŒì¼ ë¡œë“œ
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
                );

                // FaceLandmarker ìƒì„±
                const faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                        delegate: 'GPU' // GPU ê°€ì† ì‚¬ìš©
                    },
                    outputFaceBlendshapes: true, // í‘œì • ë¶„ì„
                    outputFacialTransformationMatrixes: true, // 3D ë³€í™˜ í–‰ë ¬
                    runningMode: 'VIDEO',
                    numFaces: 5 // ìµœëŒ€ 5ëª… ê°ì§€
                });

                faceLandmarkerRef.current = faceLandmarker;
                console.log('âœ… MediaPipe FaceLandmarker initialized');
            } catch (error) {
                console.error('âŒ MediaPipe initialization failed:', error);
            }
        };

        initMediaPipe();

        return () => {
            if (faceLandmarkerRef.current) {
                faceLandmarkerRef.current.close();
                faceLandmarkerRef.current = null;
            }
        };
    }, [isActive]);

    // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì„¤ì •
    const setupWebcam = useCallback(async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                }
            });

            // ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
            const video = document.createElement('video');
            video.id = 'mediapipeVideoFeed';
            video.srcObject = stream;
            video.autoplay = true;
            video.playsInline = true;
            video.muted = true;

            await new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    video.play();
                    resolve();
                };
            });

            videoRef.current = video;

            // ìº”ë²„ìŠ¤ ìƒì„± (ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ìš©)
            const canvas = document.createElement('canvas');
            canvas.id = 'mediapipeOverlay';
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvasRef.current = canvas;

            console.log('âœ… Webcam stream ready:', video.videoWidth, 'x', video.videoHeight);
            return true;
        } catch (error) {
            console.error('âŒ Webcam setup failed:', error);
            return false;
        }
    }, []);

    // 3D ì–¼êµ´ ë°©í–¥ ê³„ì‚° (Pitch, Yaw, Roll)
    const calculateHeadPose = useCallback((landmarks) => {
        if (!landmarks || landmarks.length === 0) return { pitch: 0, yaw: 0, roll: 0 };

        const noseTip = landmarks[LANDMARK_INDICES.NOSE_TIP];
        const chin = landmarks[LANDMARK_INDICES.CHIN];
        const leftEye = landmarks[LANDMARK_INDICES.LEFT_EYE_OUTER];
        const rightEye = landmarks[LANDMARK_INDICES.RIGHT_EYE_OUTER];

        // ëœë“œë§ˆí¬ ìœ íš¨ì„± ê²€ì¦
        if (!noseTip || !chin || !leftEye || !rightEye) {
            return { pitch: 0, yaw: 0, roll: 0 };
        }

        // Yaw (ì¢Œìš° íšŒì „) - ì½”ì™€ ì–‘ ëˆˆ ì¤‘ì‹¬ ë¹„êµ
        const eyeCenter = {
            x: (leftEye.x + rightEye.x) / 2,
            y: (leftEye.y + rightEye.y) / 2,
            z: ((leftEye.z || 0) + (rightEye.z || 0)) / 2
        };

        // z ì¢Œí‘œê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        const noseZ = noseTip.z || 0;
        const chinZ = chin.z || 0;
        const eyeCenterZ = eyeCenter.z || 0;

        // z ì°¨ì´ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ yaw/pitch ê³„ì‚°ì´ ë¶ˆì•ˆì •í•´ì§
        const zDiffYaw = Math.abs(noseZ - eyeCenterZ);
        const zDiffPitch = Math.abs(noseZ - chinZ);

        let yaw = 0, pitch = 0, roll = 0;

        // Yaw ê³„ì‚° (z ê¹Šì´ê°€ ì¶©ë¶„íˆ ìˆì„ ë•Œë§Œ)
        if (zDiffYaw > 0.001) {
            yaw = Math.atan2(noseTip.x - eyeCenter.x, noseZ - eyeCenterZ) * (180 / Math.PI);
        } else {
            // zê°€ ê±°ì˜ ì—†ìœ¼ë©´ x ê¸°ë°˜ ë‹¨ìˆœ ê³„ì‚°
            yaw = (noseTip.x - eyeCenter.x) * 100; // ìŠ¤ì¼€ì¼ ì¡°ì •
        }

        // Pitch ê³„ì‚° (z ê¹Šì´ê°€ ì¶©ë¶„íˆ ìˆì„ ë•Œë§Œ)
        if (zDiffPitch > 0.001) {
            pitch = Math.atan2(noseTip.y - chin.y, noseZ - chinZ) * (180 / Math.PI);
        } else {
            pitch = (noseTip.y - chin.y) * 100;
        }

        // Roll (ê¸°ìš¸ê¸°) - ì–‘ ëˆˆì˜ ë†’ì´ ì°¨ì´
        roll = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x) * (180 / Math.PI);

        // NaN ê²€ì¦ ë° ë²”ìœ„ í´ë¨í•‘ (ì‹¤ì œ ë¨¸ë¦¬ íšŒì „ ë²”ìœ„: ì•½ Â±60ë„)
        const MAX_ANGLE = 60;
        if (!Number.isFinite(pitch)) pitch = 0;
        if (!Number.isFinite(yaw)) yaw = 0;
        if (!Number.isFinite(roll)) roll = 0;

        pitch = Math.max(-MAX_ANGLE, Math.min(MAX_ANGLE, pitch));
        yaw = Math.max(-MAX_ANGLE, Math.min(MAX_ANGLE, yaw));
        roll = Math.max(-MAX_ANGLE, Math.min(MAX_ANGLE, roll));

        return { pitch, yaw, roll };
    }, []);

    // ========== 3D ë²¡í„° ê¸°ë°˜ ì‹œì„  ì¶”ì • ==========
    // MediaPipeì˜ 3D ì¢Œí‘œ(x, y, z)ë¥¼ í™œìš©í•˜ì—¬ ì‹œì„  ë²¡í„°ë¥¼ ê³„ì‚°í•˜ê³  í™”ë©´ì— íˆ¬ì˜
    const estimateGazeFromIris = useCallback((landmarks, videoWidth, videoHeight, headPose = null) => {
        if (!landmarks || landmarks.length < 478) return { x: window.innerWidth / 2, y: window.innerHeight / 2 };

        // ========== 3D ì¢Œí‘œ ì¶”ì¶œ ==========
        // ì™¼ìª½ í™ì±„ ì¤‘ì‹¬ (3D)
        const leftIris3D = landmarks[LANDMARK_INDICES.LEFT_IRIS[0]];
        // ì˜¤ë¥¸ìª½ í™ì±„ ì¤‘ì‹¬ (3D)
        const rightIris3D = landmarks[LANDMARK_INDICES.RIGHT_IRIS[0]];

        // ì™¼ìª½/ì˜¤ë¥¸ìª½ ëˆˆì˜ ê²½ê³„ (3D)
        const leftEyeLeft3D = landmarks[LANDMARK_INDICES.LEFT_EYE.P1];
        const leftEyeRight3D = landmarks[LANDMARK_INDICES.LEFT_EYE.P4];
        const rightEyeLeft3D = landmarks[LANDMARK_INDICES.RIGHT_EYE.P1];
        const rightEyeRight3D = landmarks[LANDMARK_INDICES.RIGHT_EYE.P4];

        // ëˆˆ ì¤‘ì‹¬ (3D) - ì–‘ìª½ ëˆˆì˜ ì¤‘ê°„ì 
        const eyeCenter3D = {
            x: (leftEyeLeft3D.x + leftEyeRight3D.x + rightEyeLeft3D.x + rightEyeRight3D.x) / 4,
            y: (leftEyeLeft3D.y + leftEyeRight3D.y + rightEyeLeft3D.y + rightEyeRight3D.y) / 4,
            z: ((leftEyeLeft3D.z || 0) + (leftEyeRight3D.z || 0) + (rightEyeLeft3D.z || 0) + (rightEyeRight3D.z || 0)) / 4
        };

        // í™ì±„ ì¤‘ì‹¬ (3D)
        const irisCenter3D = {
            x: (leftIris3D.x + rightIris3D.x) / 2,
            y: (leftIris3D.y + rightIris3D.y) / 2,
            z: ((leftIris3D.z || 0) + (rightIris3D.z || 0)) / 2
        };

        // ========== 3D ì‹œì„  ë²¡í„° ê³„ì‚° ==========
        // ì‹œì„  ë°©í–¥ = í™ì±„ ìœ„ì¹˜ - ëˆˆ ì¤‘ì‹¬ ìœ„ì¹˜ (ì •ê·œí™”ëœ ë°©í–¥ ë²¡í„°)
        const gazeVector = {
            x: irisCenter3D.x - eyeCenter3D.x,
            y: irisCenter3D.y - eyeCenter3D.y,
            z: (irisCenter3D.z - eyeCenter3D.z) || 0.01 // zê°€ 0ì´ë©´ ì‘ì€ ê°’ ì‚¬ìš©
        };

        // ì‹œì„  ë²¡í„° ì •ê·œí™”
        const gazeMagnitude = Math.sqrt(gazeVector.x ** 2 + gazeVector.y ** 2 + gazeVector.z ** 2);
        const normalizedGaze = {
            x: gazeVector.x / (gazeMagnitude || 1),
            y: gazeVector.y / (gazeMagnitude || 1),
            z: gazeVector.z / (gazeMagnitude || 1)
        };

        // ========== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (baseline ì €ì¥) ==========
        if (!isBaselineCalibratedRef.current && headPose) {
            const acc = calibrationAccumulatorRef.current;
            acc.headPose.pitch += headPose.pitch;
            acc.headPose.yaw += headPose.yaw;
            acc.headPose.roll += headPose.roll;
            // 3D ë²¡í„° ëˆ„ì 
            acc.irisOffset.x += normalizedGaze.x;
            acc.irisOffset.y += normalizedGaze.y;
            acc.count++;

            if (acc.count >= CALIBRATION_FRAMES) {
                baselineRef.current = {
                    headPose: {
                        pitch: acc.headPose.pitch / acc.count,
                        yaw: acc.headPose.yaw / acc.count,
                        roll: acc.headPose.roll / acc.count
                    },
                    irisOffset: {
                        x: acc.irisOffset.x / acc.count,
                        y: acc.irisOffset.y / acc.count
                    }
                };
                isBaselineCalibratedRef.current = true;
                console.log('âœ… 3D Gaze baseline calibration complete:', baselineRef.current);
            }

            return { x: window.innerWidth / 2, y: window.innerHeight / 2 };
        }

        // ========== 3-Point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‚¬ìš© (ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì‹œ) ==========
        if (hasManualCalibrationRef.current && calibrationDataRef.current) {
            const calibData = calibrationDataRef.current;
            const baseline = calibData.baseline;
            const sensitivity = calibData.sensitivity;

            // 3D ë²¡í„° ê¸°ë°˜ ìƒëŒ€ê°’
            const deltaGazeX = normalizedGaze.x - baseline.irisOffset.x;
            const deltaGazeY = normalizedGaze.y - baseline.irisOffset.y;

            let deltaYaw = 0;
            let deltaPitch = 0;
            if (headPose) {
                deltaYaw = headPose.yaw - baseline.headPose.yaw;
                deltaPitch = headPose.pitch - baseline.headPose.pitch;
                // Delta í´ë¨í•‘ (ë¨¸ë¦¬ê°€ ê°‘ìê¸° 120ë„ ëŒì•„ê°€ì§€ ì•ŠìŒ)
                const MAX_DELTA = 30;
                deltaYaw = Math.max(-MAX_DELTA, Math.min(MAX_DELTA, deltaYaw));
                deltaPitch = Math.max(-MAX_DELTA, Math.min(MAX_DELTA, deltaPitch));
            }

            // 3D ë²¡í„°ë¥¼ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
            // sensitivityëŠ” ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì—ì„œ (deltaScreen / deltaIris)ë¡œ ê³„ì‚°ë¨
            // ë”°ë¼ì„œ deltaIris * sensitivity = deltaScreen ê´€ê³„ê°€ ì„±ë¦½
            let rawGazeX = baseline.screenX
                + deltaGazeX * sensitivity.irisX * 1.5  // âœ… ë”í•˜ê¸°ë¡œ ìˆ˜ì • (sensitivityê°€ ìŒìˆ˜ì´ë¯€ë¡œ)
                + deltaYaw * sensitivity.headX;

            let rawGazeY = baseline.screenY
                + deltaGazeY * sensitivity.irisY * 1.5
                - deltaPitch * sensitivity.headY;

            // Raw gaze í´ë¨í•‘ (í™”ë©´ ë°–ìœ¼ë¡œ ë„ˆë¬´ ë©€ë¦¬ ë‚˜ê°€ì§€ ì•Šë„ë¡ - Kalman ì•ˆì •ì„±)
            const SCREEN_MARGIN = 500; // í™”ë©´ ë°– 500pxê¹Œì§€ë§Œ í—ˆìš©
            rawGazeX = Math.max(-SCREEN_MARGIN, Math.min(rawGazeX, window.innerWidth + SCREEN_MARGIN));
            rawGazeY = Math.max(-SCREEN_MARGIN, Math.min(rawGazeY, window.innerHeight + SCREEN_MARGIN));

            // Kalman Filter ìŠ¤ë¬´ë”© (EMA ëŒ€ì²´)
            const kalman = getKalmanFilter();
            const filtered = kalman.filter(rawGazeX, rawGazeY);

            // ë””ë²„ê·¸: ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²½ë¡œ ê°’ í™•ì¸ (10% í™•ë¥ ë¡œ ì¶œë ¥)
            if (Math.random() < 0.10) {
                console.log('ğŸ” [Manual Calib] Gaze Debug:', {
                    normalizedGaze: { x: normalizedGaze.x.toFixed(4), y: normalizedGaze.y.toFixed(4) },
                    baselineIris: { x: baseline.irisOffset.x.toFixed(4), y: baseline.irisOffset.y.toFixed(4) },
                    delta: { x: deltaGazeX.toFixed(4), y: deltaGazeY.toFixed(4) },
                    sensitivity: { iX: sensitivity.irisX.toFixed(1), iY: sensitivity.irisY.toFixed(1), hX: sensitivity.headX.toFixed(1), hY: sensitivity.headY.toFixed(1) },
                    baselineScreen: { x: Math.round(baseline.screenX), y: Math.round(baseline.screenY) },
                    headDelta: { yaw: deltaYaw.toFixed(2), pitch: deltaPitch.toFixed(2) },
                    raw: { x: Math.round(rawGazeX), y: Math.round(rawGazeY) },
                    filtered: { x: Math.round(filtered.x), y: Math.round(filtered.y) },
                    kalmanVel: { vx: kalman.state.vx.toFixed(2), vy: kalman.state.vy.toFixed(2) }
                });
            }

            return {
                x: Math.max(0, Math.min(filtered.x, window.innerWidth)),
                y: Math.max(0, Math.min(filtered.y, window.innerHeight))
            };
        }

        // ========== ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ: baseline ê¸°ì¤€ ìƒëŒ€ê°’ ==========
        const baseline = baselineRef.current;

        // 3D ì‹œì„  ë²¡í„°ì˜ ìƒëŒ€ì  ë³€í™”
        const relativeGazeX = normalizedGaze.x - baseline.irisOffset.x;
        const relativeGazeY = normalizedGaze.y - baseline.irisOffset.y;

        // ë¨¸ë¦¬ íšŒì „ ë³´ì •
        let headCompensationX = 0;
        let headCompensationY = 0;

        if (headPose) {
            const relativeYaw = headPose.yaw - baseline.headPose.yaw;
            const relativePitch = headPose.pitch - baseline.headPose.pitch;

            // ë¨¸ë¦¬ íšŒì „ì„ ì‹œì„  ë²¡í„°ì— í†µí•©
            // ë¨¸ë¦¬ê°€ ëŒì•„ê°„ ë°©í–¥ìœ¼ë¡œ ì‹œì„ ë„ ì´ë™ (ê°ë„ ì¡°ì ˆ)
            const HEAD_WEIGHT = 0.025; // ë¨¸ë¦¬ íšŒì „ 1ë„ë‹¹ í™”ë©´ 2.5% ì´ë™
            headCompensationX = relativeYaw * HEAD_WEIGHT;  // ì¢Œìš° ë°˜ì „ ìˆ˜ì •: - ì œê±°
            headCompensationY = -relativePitch * HEAD_WEIGHT;
        }

        // ========== 3D ë²¡í„°ë¥¼ í™”ë©´ ì¢Œí‘œë¡œ íˆ¬ì˜ ==========
        // ì‹œì„  ë²¡í„°ë¥¼ í™”ë©´ì— íˆ¬ì˜ (ê³ ì • ê°ë„ ë°©ì‹)
        // Note: Ray-casting íˆ¬ì˜ì€ ì œê±°ë¨ (ê³ ì • ê°ë„ê°€ ë” ì•ˆì •ì )

        // ì‹œì„  ê°ë„ (3D ë²¡í„° â†’ í™”ë©´ í”½ì…€)
        const GAZE_SENSITIVITY_X = 2.5; // ì‹œì„  ë²¡í„° ë³€í™”ì— ëŒ€í•œ í™”ë©´ ì´ë™ ë°°ìœ¨
        const GAZE_SENSITIVITY_Y = 2.0;

        // ìµœì¢… ì‹œì„  ìœ„ì¹˜ ê³„ì‚°
        const rawGazeX = window.innerWidth / 2
            + relativeGazeX * window.innerWidth * GAZE_SENSITIVITY_X  // 3D ë²¡í„° ê¸°ì—¬ (ì¢Œìš° ë°˜ì „ ìˆ˜ì •)
            + headCompensationX * window.innerWidth;                   // ë¨¸ë¦¬ íšŒì „ ê¸°ì—¬

        const rawGazeY = window.innerHeight / 2
            + relativeGazeY * window.innerHeight * GAZE_SENSITIVITY_Y  // 3D ë²¡í„° ê¸°ì—¬
            + headCompensationY * window.innerHeight;                  // ë¨¸ë¦¬ íšŒì „ ê¸°ì—¬

        // ========== Kalman Filter ìŠ¤ë¬´ë”© ì ìš© (EMA ëŒ€ì²´) ==========
        const kalman = getKalmanFilter();
        const filtered = kalman.filter(rawGazeX, rawGazeY);

        // ë””ë²„ê·¸: ê°’ í™•ì¸
        if (Math.random() < 0.02) { // 2% ìƒ˜í”Œë§
            console.log('ğŸ” Gaze Debug:', {
                normalizedGaze: { x: normalizedGaze.x.toFixed(4), y: normalizedGaze.y.toFixed(4), z: normalizedGaze.z.toFixed(4) },
                baseline: { x: baseline.irisOffset.x.toFixed(4), y: baseline.irisOffset.y.toFixed(4) },
                relative: { x: relativeGazeX.toFixed(4), y: relativeGazeY.toFixed(4) },
                raw: { x: Math.round(rawGazeX), y: Math.round(rawGazeY) },
                filtered: { x: Math.round(filtered.x), y: Math.round(filtered.y) },
                screen: { w: window.innerWidth, h: window.innerHeight }
            });
        }

        // ê²½ê³„ í´ë¨í•‘
        return {
            x: Math.max(0, Math.min(filtered.x, window.innerWidth)),
            y: Math.max(0, Math.min(filtered.y, window.innerHeight))
        };
    }, [getKalmanFilter]);

    // EAR ê¸°ë°˜ ëˆˆ ìƒíƒœ ë¶„ì„
    const analyzeEyeState = useCallback((landmarks) => {
        if (!landmarks || landmarks.length < 478) {
            
            // ì–¼êµ´ ë¯¸ê²€ì¶œ ì‹œ null ë°˜í™˜ (ì¡¸ìŒ ê°ì§€ì—ì„œ êµ¬ë¶„í•˜ê¸° ìœ„í•¨)
            return { leftEAR: null, rightEAR: null, avgEAR: null, isBlinking: false, faceDetected: false };
        }

        // ì™¼ìª½ ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
        const leftEyePoints = {
            P1: landmarks[LANDMARK_INDICES.LEFT_EYE.P1],
            P2: landmarks[LANDMARK_INDICES.LEFT_EYE.P2],
            P3: landmarks[LANDMARK_INDICES.LEFT_EYE.P3],
            P4: landmarks[LANDMARK_INDICES.LEFT_EYE.P4],
            P5: landmarks[LANDMARK_INDICES.LEFT_EYE.P5],
            P6: landmarks[LANDMARK_INDICES.LEFT_EYE.P6]
        };

        // ì˜¤ë¥¸ìª½ ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
        const rightEyePoints = {
            P1: landmarks[LANDMARK_INDICES.RIGHT_EYE.P1],
            P2: landmarks[LANDMARK_INDICES.RIGHT_EYE.P2],
            P3: landmarks[LANDMARK_INDICES.RIGHT_EYE.P3],
            P4: landmarks[LANDMARK_INDICES.RIGHT_EYE.P4],
            P5: landmarks[LANDMARK_INDICES.RIGHT_EYE.P5],
            P6: landmarks[LANDMARK_INDICES.RIGHT_EYE.P6]
        };

        const leftEAR = calculateEAR(leftEyePoints);
        const rightEAR = calculateEAR(rightEyePoints);
        const avgEAR = (leftEAR + rightEAR) / 2;
        const isBlinking = avgEAR < EAR_THRESHOLD;

        return { leftEAR, rightEAR, avgEAR, isBlinking, faceDetected: true };
    }, []);

    // ì¡¸ìŒ ê°ì§€ (PERCLOS ê¸°ë°˜) - ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°ë§Œ ê¸°ë¡
    const detectDrowsiness = useCallback((avgEAR) => {
        // ì–¼êµ´ ë¯¸ê²€ì¶œ ì‹œ (avgEAR === null) ì¡¸ìŒ ê°ì§€ ìŠ¤í‚µ
        // ì¤‘ìš”: ì–¼êµ´ ë¯¸ê²€ì¶œì€ ëˆˆ ê°ìŒìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ!
        if (avgEAR === null) {
            // ì—°ì† ëˆˆ ê°ê¹€ ì¹´ìš´í„° ë¦¬ì…‹ (ì–¼êµ´ ë¯¸ê²€ì¶œì€ ëˆˆ ê°ê¹€ì´ ì•„ë‹˜)
            closedFrameCountRef.current = 0;
            return {
                isDrowsy: false,
                perclos: earHistoryRef.current.length > 0
                    ? earHistoryRef.current.filter(e => e.ear < EAR_THRESHOLD).length / earHistoryRef.current.length
                    : 0,
                consecutiveClosedFrames: 0
            };
        }

        const now = Date.now();

        // EAR ê¸°ë¡ ì¶”ê°€
        earHistoryRef.current.push({ ear: avgEAR, timestamp: now });

        // ìœˆë„ìš° ì™¸ë¶€ ë°ì´í„° ì œê±°
        const windowStart = now - PERCLOS_WINDOW_SECONDS * 1000;
        earHistoryRef.current = earHistoryRef.current.filter(
            entry => entry.timestamp >= windowStart
        );

        // PERCLOS ê³„ì‚° (ëˆˆ ê°ì€ ë¹„ìœ¨)
        const totalFrames = earHistoryRef.current.length;
        // ìµœì†Œ 30í”„ë ˆì„ (ì•½ 1ì´ˆ) ì´ìƒ ìˆ˜ì§‘ë˜ì–´ì•¼ ì˜ë¯¸ìˆëŠ” PERCLOS ê³„ì‚°
        const MIN_FRAMES_FOR_PERCLOS = 30;
        if (totalFrames < MIN_FRAMES_FOR_PERCLOS) {
            return { isDrowsy: false, perclos: 0, consecutiveClosedFrames: closedFrameCountRef.current };
        }

        const closedFrames = earHistoryRef.current.filter(
            entry => entry.ear < EAR_THRESHOLD
        ).length;
        const perclos = closedFrames / totalFrames;

        // ì—°ì† ëˆˆ ê°ê¹€ í”„ë ˆì„ ì¹´ìš´íŠ¸
        if (avgEAR < EAR_THRESHOLD) {
            closedFrameCountRef.current++;
        } else {
            closedFrameCountRef.current = 0;
        }

        const isDrowsy = perclos >= PERCLOS_THRESHOLD ||
            closedFrameCountRef.current >= DROWSY_FRAME_THRESHOLD;

        return {
            isDrowsy,
            perclos,
            consecutiveClosedFrames: closedFrameCountRef.current
        };
    }, []);

    // í™ì±„ ìœ„ì¹˜ ì¶”ì¶œ
    const extractIrisPosition = useCallback((landmarks) => {
        if (!landmarks || landmarks.length < 478) {
            return { left: null, right: null };
        }

        const leftIris = LANDMARK_INDICES.LEFT_IRIS.map(idx => landmarks[idx]);
        const rightIris = LANDMARK_INDICES.RIGHT_IRIS.map(idx => landmarks[idx]);

        return {
            left: {
                center: leftIris[0],
                points: leftIris
            },
            right: {
                center: rightIris[0],
                points: rightIris
            }
        };
    }, []);

    // Throttled ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (Maximum update depth ë°©ì§€)
    const updateReactState = useCallback(() => {
        const data = latestDataRef.current;
        setIsFaceDetected(data.isFaceDetected);
        setFaceCount(data.faceCount);
        setDetectedFaces(data.detectedFaces);
        setHeadPose(data.headPose);
        setGazePosition(data.gazePosition);
        setEyeState(data.eyeState);
        setIrisPosition(data.irisPosition);
        setDrowsinessState(data.drowsinessState);
        setNoFaceDuration(data.noFaceDuration);
        setShowNoFaceWarning(data.showNoFaceWarning);
    }, []);

    // ë©”ì¸ ì¶”ì  ë£¨í”„ (ref ê¸°ë°˜ - setState ìµœì†Œí™”)
    const trackingLoop = useCallback(async () => {
        if (!faceLandmarkerRef.current || !videoRef.current || isCleaningUpRef.current) {
            return;
        }

        const video = videoRef.current;
        const now = performance.now();

        try {
            const results = faceLandmarkerRef.current.detectForVideo(video, now);

            // ========== ì–¼êµ´ ê°ì§€ ë””ë°”ìš´ì‹± ì ìš© ==========
            const rawFaceDetected = results.faceLandmarks && results.faceLandmarks.length > 0;

            if (rawFaceDetected) {
                faceDetectionCounterRef.current.detected++;
                faceDetectionCounterRef.current.notDetected = 0;

                // ì—°ì† 3í”„ë ˆì„ ê°ì§€ ì‹œ ì•ˆì •ì  ê°ì§€ë¡œ íŒì •
                if (faceDetectionCounterRef.current.detected >= FACE_DETECTION_DEBOUNCE_FRAMES) {
                    if (!stableFaceDetectedRef.current) {
                        console.log('âœ… Face stably detected (debounced)');
                    }
                    stableFaceDetectedRef.current = true;
                }
            } else {
                faceDetectionCounterRef.current.notDetected++;
                faceDetectionCounterRef.current.detected = 0;

                // ì—°ì† 3í”„ë ˆì„ ë¯¸ê°ì§€ ì‹œ ì•ˆì •ì  ë¯¸ê°ì§€ë¡œ íŒì •
                if (faceDetectionCounterRef.current.notDetected >= FACE_DETECTION_DEBOUNCE_FRAMES) {
                    if (stableFaceDetectedRef.current) {
                        console.log('âš ï¸ Face stably not detected (debounced)');
                    }
                    stableFaceDetectedRef.current = false;
                }
            }

            // ì•ˆì •í™”ëœ ì–¼êµ´ ê°ì§€ ìƒíƒœ ì‚¬ìš©
            const isFaceStablyDetected = stableFaceDetectedRef.current;

            if (isFaceStablyDetected && rawFaceDetected) {
                // ì–¼êµ´ ê°ì§€ë¨ - refì— ì €ì¥ (ë¦¬ë Œë”ë§ ì—†ìŒ)
                latestDataRef.current.isFaceDetected = true;
                latestDataRef.current.faceCount = results.faceLandmarks.length;
                latestDataRef.current.detectedFaces = results.faceLandmarks;

                // ì²« ë²ˆì§¸ ì–¼êµ´ ê¸°ì¤€ ë¶„ì„
                const primaryLandmarks = results.faceLandmarks[0];

                // 3D ì–¼êµ´ ë°©í–¥ (ë¨¼ì € ê³„ì‚° - ì‹œì„  ì¶”ì •ì— ì‚¬ìš©)
                const headPose = calculateHeadPose(primaryLandmarks);
                latestDataRef.current.headPose = headPose;

                // ì‹œì„  ì¶”ì • (í™ì±„ + ë¨¸ë¦¬ ë°©í–¥ í†µí•©)
                latestDataRef.current.gazePosition = estimateGazeFromIris(primaryLandmarks, video.videoWidth, video.videoHeight, headPose);

                // ëˆˆ ìƒíƒœ ë¶„ì„
                const eye = analyzeEyeState(primaryLandmarks);
                latestDataRef.current.eyeState = eye;

                // í™ì±„ ìœ„ì¹˜
                latestDataRef.current.irisPosition = extractIrisPosition(primaryLandmarks);

                // ì¡¸ìŒ ê°ì§€
                const drowsiness = detectDrowsiness(eye.avgEAR);
                latestDataRef.current.drowsinessState = drowsiness;

                // ========== Liveness Detection (ì‚¬ì§„/ì˜ìƒ ê°ì§€) ==========
                // ëˆˆ ê¹œë¹¡ì„ ê°ì§€: ëˆˆì´ ê°ê²¼ë‹¤ê°€ ë– ì§€ëŠ” ìˆœê°„ì„ ê°ì§€
                const isCurrentlyBlinking = eye.isBlinking;
                if (wasBlinkingRef.current && !isCurrentlyBlinking) {
                    // ëˆˆì„ ê°ì•˜ë‹¤ê°€ ëœ¸ = ê¹œë¹¡ì„ ì™„ë£Œ
                    lastBlinkTimeRef.current = Date.now();
                    if (livenessWarning) {
                        setLivenessWarning(false);
                        console.log('âœ… Blink detected - liveness confirmed');
                    }
                }
                wasBlinkingRef.current = isCurrentlyBlinking;

                // ì¼ì • ì‹œê°„ ë™ì•ˆ ëˆˆ ê¹œë¹¡ì„ ì—†ìœ¼ë©´ ì‚¬ì§„/ì˜ìƒ ì˜ì‹¬
                const timeSinceLastBlink = Date.now() - lastBlinkTimeRef.current;
                if (timeSinceLastBlink >= LIVENESS_BLINK_TIMEOUT_MS && !livenessWarning) {
                    setLivenessWarning(true);
                    console.warn('âš ï¸ Liveness warning: No blink detected for', Math.round(timeSinceLastBlink / 1000), 'seconds');
                }

                // NO_FACE ë¦¬ì…‹ (ì´ì „ì— ì–¼êµ´ì´ ì—†ì—ˆë‹¤ê°€ ê°ì§€ëœ ê²½ìš°ë§Œ ë¡œê·¸)
                if (noFaceStartTimeRef.current !== null) {
                    console.log('âœ… Face detected - resetting NO_FACE tracking');
                    noFaceStartTimeRef.current = null;
                    latestDataRef.current.noFaceDuration = 0;
                    latestDataRef.current.showNoFaceWarning = false;
                    warningShownRef.current = false;
                    sustainedViolationSentRef.current = false;
                }

                // ë‹¤ì¤‘ ì¸ë¬¼ ê²½ê³  (2ëª… ì´ìƒ)
                if (results.faceLandmarks.length > 1 && sessionId) {
                    sendMonitoringViolation(sessionId, 'MULTIPLE_FACES', {
                        description: `Multiple faces detected: ${results.faceLandmarks.length} people`,
                        faceCount: results.faceLandmarks.length
                    }).catch(err => {
                        console.warn('MULTIPLE_FACES violation send failed:', err);
                    });
                }

                // ì¡¸ìŒ ìœ„ë°˜ ì „ì†¡ (1íšŒ)
                if (drowsiness.isDrowsy && !drowsyViolationSentRef.current && sessionId) {
                    drowsyViolationSentRef.current = true;
                    sendMonitoringViolation(sessionId, 'DROWSINESS_DETECTED', {
                        description: `Drowsiness detected - PERCLOS: ${(drowsiness.perclos * 100).toFixed(1)}%`,
                        perclos: drowsiness.perclos
                    }).catch(err => {
                        console.warn('DROWSINESS violation send failed:', err);
                    });
                }

                // ì¡¸ìŒ ìƒíƒœ í•´ì œ ì‹œ í”Œë˜ê·¸ ë¦¬ì…‹
                if (!drowsiness.isDrowsy && drowsyViolationSentRef.current) {
                    drowsyViolationSentRef.current = false;
                }

            } else if (!isFaceStablyDetected) {
                // ì–¼êµ´ ì•ˆì •ì  ë¯¸ê²€ì¶œ (ë””ë°”ìš´ì‹± ì ìš©ë¨) - refì— ì €ì¥
                latestDataRef.current.isFaceDetected = false;
                latestDataRef.current.faceCount = 0;
                latestDataRef.current.detectedFaces = [];

                // NO_FACE ì§€ì† ì‹œê°„ ì¶”ì  (ë””ë°”ìš´ì‹±ëœ ìƒíƒœ ê¸°ì¤€)
                const currentTime = Date.now();
                if (noFaceStartTimeRef.current === null) {
                    noFaceStartTimeRef.current = currentTime;
                    // ë””ë°”ìš´ì‹±ìœ¼ë¡œ ì¸í•´ ì´ ë¡œê·¸ëŠ” í›¨ì”¬ ì ê²Œ ë‚˜íƒ€ë‚¨
                }

                const duration = currentTime - noFaceStartTimeRef.current;
                // refì— ì €ì¥ (throttled ì—…ë°ì´íŠ¸ì—ì„œ React ìƒíƒœë¡œ ë°˜ì˜ë¨)
                latestDataRef.current.noFaceDuration = duration;

                // 5ì´ˆ ì´ìƒ: ê²½ê³  í‘œì‹œ
                if (duration >= NO_FACE_WARNING_THRESHOLD_MS && !warningShownRef.current) {
                    warningShownRef.current = true;
                    latestDataRef.current.showNoFaceWarning = true;
                    console.log('âš ï¸ NO_FACE warning shown (5+ seconds)');

                    if (sessionId) {
                        recordMonitoringWarning(sessionId).catch(err => {
                            console.warn('Warning record failed:', err);
                        });
                    }
                }

                // 15ì´ˆ ì´ìƒ: ì‹¬ê°í•œ ìœ„ë°˜
                if (duration >= NO_FACE_THRESHOLD_MS && !sustainedViolationSentRef.current && sessionId) {
                    sustainedViolationSentRef.current = true;
                    console.log('ğŸš¨ NO_FACE_SUSTAINED violation sent (15+ seconds)');

                    sendMonitoringViolation(sessionId, 'NO_FACE_SUSTAINED', {
                        description: `Face not detected for ${Math.round(duration / 1000)} seconds - serious violation`,
                        duration: Math.round(duration / 1000),
                        severity: 'HIGH'
                    }).catch(err => {
                        console.warn('NO_FACE_SUSTAINED violation send failed:', err);
                    });
                }
            }
            // else: ìƒíƒœ ì „í™˜ ì¤‘ (ë””ë°”ìš´ì‹± ëŒ€ê¸°) - ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ

            // Throttled ìƒíƒœ ì—…ë°ì´íŠ¸ (100msë§ˆë‹¤ = 10fps)
            if (now - lastStateUpdateRef.current >= STATE_UPDATE_INTERVAL_MS) {
                lastStateUpdateRef.current = now;
                updateReactState();
            }

            // ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° (ref ì‚¬ìš©ìœ¼ë¡œ ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
            if (debugModeRef.current && canvasRef.current && drawDebugOverlayRef.current) {
                drawDebugOverlayRef.current(results);
            }

        } catch (error) {
            console.error('Tracking loop error:', error);
        }

        // ë‹¤ìŒ í”„ë ˆì„ ì˜ˆì•½
        if (!isCleaningUpRef.current) {
            animationFrameRef.current = requestAnimationFrame(trackingLoop);
        }
    }, [
        sessionId,
        calculateHeadPose,
        estimateGazeFromIris,
        analyzeEyeState,
        extractIrisPosition,
        detectDrowsiness,
        updateReactState,
        livenessWarning
        // drawDebugOverlayëŠ” trackingLoop ì´í›„ì— ì •ì˜ë˜ì–´ ref íŒ¨í„´ìœ¼ë¡œ ì ‘ê·¼
    ]);

    // ë””ë²„ê·¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
    const drawDebugOverlay = useCallback((results) => {
        const canvas = canvasRef.current;
        const video = videoRef.current;
        if (!canvas || !video) {
            console.warn('drawDebugOverlay: canvas or video not ready', { canvas: !!canvas, video: !!video });
            return;
        }

        // ìº”ë²„ìŠ¤ í¬ê¸°ê°€ ë¹„ë””ì˜¤ì™€ ë§ì§€ ì•Šìœ¼ë©´ ì¡°ì •
        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
            canvas.width = video.videoWidth || 640;
            canvas.height = video.videoHeight || 480;
        }

        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // ë¹„ë””ì˜¤ ê·¸ë¦¬ê¸° (ê±°ìš¸ ëª¨ë“œ) - í•­ìƒ ê·¸ë¦¬ê¸°
        ctx.save();
        ctx.scale(-1, 1);
        ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
        ctx.restore();

        if (results && results.faceLandmarks) {
            results.faceLandmarks.forEach((landmarks, faceIndex) => {
                const color = faceIndex === 0 ? '#22c55e' : '#f59e0b'; // ì²« ë²ˆì§¸: ì´ˆë¡, ë‚˜ë¨¸ì§€: ì£¼í™©

                // ëª¨ë“  ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                landmarks.forEach((landmark, idx) => {
                    const x = (1 - landmark.x) * canvas.width; // ê±°ìš¸ ëª¨ë“œ
                    const y = landmark.y * canvas.height;

                    // í™ì±„ í¬ì¸íŠ¸ëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ
                    const isIris = [...LANDMARK_INDICES.LEFT_IRIS, ...LANDMARK_INDICES.RIGHT_IRIS].includes(idx);
                    ctx.fillStyle = isIris ? '#ef4444' : color;
                    ctx.beginPath();
                    ctx.arc(x, y, isIris ? 3 : 1, 0, 2 * Math.PI);
                    ctx.fill();
                });

                // ëˆˆ ì˜ì—­ í‘œì‹œ
                const leftEye = [
                    LANDMARK_INDICES.LEFT_EYE.P1,
                    LANDMARK_INDICES.LEFT_EYE.P2,
                    LANDMARK_INDICES.LEFT_EYE.P3,
                    LANDMARK_INDICES.LEFT_EYE.P4,
                    LANDMARK_INDICES.LEFT_EYE.P5,
                    LANDMARK_INDICES.LEFT_EYE.P6
                ];
                const rightEye = [
                    LANDMARK_INDICES.RIGHT_EYE.P1,
                    LANDMARK_INDICES.RIGHT_EYE.P2,
                    LANDMARK_INDICES.RIGHT_EYE.P3,
                    LANDMARK_INDICES.RIGHT_EYE.P4,
                    LANDMARK_INDICES.RIGHT_EYE.P5,
                    LANDMARK_INDICES.RIGHT_EYE.P6
                ];

                [leftEye, rightEye].forEach(eyeIndices => {
                    ctx.beginPath();
                    ctx.strokeStyle = '#3b82f6';
                    ctx.lineWidth = 2;
                    eyeIndices.forEach((idx, i) => {
                        const lm = landmarks[idx];
                        const x = (1 - lm.x) * canvas.width;
                        const y = lm.y * canvas.height;
                        if (i === 0) ctx.moveTo(x, y);
                        else ctx.lineTo(x, y);
                    });
                    ctx.closePath();
                    ctx.stroke();
                });
            });
        }

        // ì •ë³´ ì˜¤ë²„ë ˆì´ (refì—ì„œ ìµœì‹  ë°ì´í„° ì½ê¸° - ë¦¬ë Œë”ë§ ì˜ì¡´ì„± ì œê±°)
        const data = latestDataRef.current;
        ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
        ctx.fillRect(10, 10, 280, 200);
        ctx.fillStyle = '#ffffff';
        ctx.font = '12px monospace';

        // null ì•ˆì „ ì²˜ë¦¬
        const leftEAR = data.eyeState?.leftEAR;
        const rightEAR = data.eyeState?.rightEAR;
        const earText = leftEAR !== null && leftEAR !== undefined
            ? `L=${leftEAR.toFixed(3)} R=${rightEAR.toFixed(3)}`
            : 'N/A (no face)';

        const lines = [
            `Faces: ${data.faceCount}`,
            `Face Detected: ${data.isFaceDetected ? 'âœ… YES' : 'âŒ NO'}`,
            `EAR: ${earText}`,
            `Blink: ${data.eyeState?.isBlinking ? 'YES' : 'NO'}`,
            `PERCLOS: ${(data.drowsinessState?.perclos * 100 || 0).toFixed(1)}%`,
            `Drowsy: ${data.drowsinessState?.isDrowsy ? 'âš ï¸ YES' : 'NO'}`,
            `Head: P=${data.headPose?.pitch?.toFixed(1) || 0}Â° Y=${data.headPose?.yaw?.toFixed(1) || 0}Â° R=${data.headPose?.roll?.toFixed(1) || 0}Â°`,
            `Gaze: (${Math.round(data.gazePosition?.x || 0)}, ${Math.round(data.gazePosition?.y || 0)})`,
            `Filter: Kalman (vel: ${kalmanFilterRef.current ? Math.round(kalmanFilterRef.current.state.vx) : 0}, ${kalmanFilterRef.current ? Math.round(kalmanFilterRef.current.state.vy) : 0})`
        ];

        lines.forEach((line, i) => {
            ctx.fillText(line, 20, 30 + i * 18);
        });

    }, []); // ì˜ì¡´ì„± ì œê±° - ref ì‚¬ìš©ìœ¼ë¡œ í•­ìƒ ìµœì‹  ë°ì´í„°

    // drawDebugOverlayë¥¼ refì— í• ë‹¹ (ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€)
    useEffect(() => {
        drawDebugOverlayRef.current = drawDebugOverlay;
    }, [drawDebugOverlay]);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘ (3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤€ë¹„)
    const startCalibration = useCallback(() => {
        console.log('MediaPipe 3-point calibration starting...');
        // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ë¦¬ì…‹
        calibrationDataRef.current = null;
        hasManualCalibrationRef.current = false;
        isBaselineCalibratedRef.current = false;
        calibrationAccumulatorRef.current = {
            headPose: { pitch: 0, yaw: 0, roll: 0 },
            irisOffset: { x: 0, y: 0 },
            count: 0
        };
    }, []);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ (3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì €ì¥)
    const completeCalibration = useCallback((calibrationData = null) => {
        if (calibrationData) {
            // 3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì €ì¥
            calibrationDataRef.current = calibrationData;
            hasManualCalibrationRef.current = true;

            // ìƒì„¸ ë””ë²„ê·¸ ë¡œê·¸
            console.log('âœ… 3-point calibration complete');
            console.log('ğŸ“ Baseline:', {
                screenX: Math.round(calibrationData.baseline?.screenX || 0),
                screenY: Math.round(calibrationData.baseline?.screenY || 0),
                irisOffset: calibrationData.baseline?.irisOffset,
                headPose: calibrationData.baseline?.headPose
            });
            console.log('ğŸ“ Sensitivity:', calibrationData.sensitivity);
            console.log('âš–ï¸ Weights:', {
                irisRatio: calibrationData.irisRatio,
                headRatio: calibrationData.headRatio
            });

            // ê°ë„ê°€ 0ì´ë©´ ê²½ê³ 
            if (calibrationData.sensitivity) {
                const sens = calibrationData.sensitivity;
                if (Math.abs(sens.irisX) < 1 && Math.abs(sens.headX) < 1) {
                    console.warn('âš ï¸ X-axis sensitivity is very low! Gaze X movement will be minimal');
                }
                if (Math.abs(sens.irisY) < 1 && Math.abs(sens.headY) < 1) {
                    console.warn('âš ï¸ Y-axis sensitivity is very low! Gaze Y movement will be minimal');
                }
            }

            // Kalman Filter ë¦¬ì…‹ (ìƒˆ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì— ë§ê²Œ)
            if (kalmanFilterRef.current) {
                kalmanFilterRef.current.reset();
                console.log('ğŸ”„ Kalman filter reset for new calibration');
            }
        } else {
            // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì—†ì´ ì™„ë£Œ (ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‚¬ìš©)
            hasManualCalibrationRef.current = false;
            console.log('âœ… Calibration complete (will use auto baseline)');

            // Kalman Filter ë¦¬ì…‹
            if (kalmanFilterRef.current) {
                kalmanFilterRef.current.reset();
            }
        }
        setIsCalibrated(true);
    }, []);

    // ì¶”ì  ì‹œì‘
    const startTracking = useCallback(async () => {
        if (!isCalibrated || !problemId) return;

        isCleaningUpRef.current = false;

        // ========== ì¶”ì  ì‹œì‘ ì‹œ ìƒíƒœ ì´ˆê¸°í™” ==========
        // EAR íˆìŠ¤í† ë¦¬ ë¦¬ì…‹ (PERCLOS 100% ì¦‰ì‹œ ê°ì§€ ë°©ì§€)
        earHistoryRef.current = [];
        closedFrameCountRef.current = 0;
        drowsyViolationSentRef.current = false;
        // Liveness ë¦¬ì…‹
        lastBlinkTimeRef.current = Date.now();
        wasBlinkingRef.current = false;
        setLivenessWarning(false);
        // ì–¼êµ´ ê°ì§€ ìƒíƒœ ë¦¬ì…‹
        faceDetectionCounterRef.current = { detected: 0, notDetected: 0 };
        stableFaceDetectedRef.current = false;
        console.log('ğŸ”„ Tracking state reset for new session');

        // ì›¹ìº  ì„¤ì •
        const webcamReady = await setupWebcam();
        if (!webcamReady) {
            console.error('Failed to setup webcam');
            return;
        }

        try {
            // ì„¸ì…˜ ì‹œì‘
            const response = await startMonitoringSession(problemId, timeLimitMinutes);
            const newSessionId = response.data?.sessionId || response.sessionId;
            setSessionId(newSessionId);
            setIsTracking(true);

            console.log('ğŸ¯ MediaPipe monitoring session started, sessionId:', newSessionId);

            // ì¶”ì  ë£¨í”„ ì‹œì‘
            trackingLoop();

        } catch (error) {
            console.error('Failed to start monitoring session:', error);
        }
    }, [isCalibrated, problemId, timeLimitMinutes, setupWebcam, trackingLoop]);

    // ì¶”ì  ì¢…ë£Œ
    const stopTracking = useCallback(async (remainingSeconds = null) => {
        if (isCleaningUpRef.current) {
            console.log('âš ï¸ stopTracking already in progress, skipping...');
            return;
        }
        isCleaningUpRef.current = true;

        try {
            // ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ì·¨ì†Œ
            if (animationFrameRef.current) {
                cancelAnimationFrame(animationFrameRef.current);
                animationFrameRef.current = null;
            }

            // ì„¸ì…˜ ì¢…ë£Œ
            if (sessionId) {
                try {
                    await endMonitoringSession(sessionId, remainingSeconds);
                    console.log('âœ… Monitoring session ended, sessionId:', sessionId);
                } catch (error) {
                    console.error('Failed to end monitoring session:', error);
                }
            }

            // ì›¹ìº  ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
            if (videoRef.current?.srcObject) {
                const tracks = videoRef.current.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                videoRef.current.srcObject = null;
            }

            // DOM ìš”ì†Œ ì •ë¦¬
            const debugContainer = document.getElementById('mediapipeDebugContainer');
            if (debugContainer) {
                debugContainer.remove();
            }

            // ì‹œì„  ë„íŠ¸ ì œê±°
            const gazeDot = document.getElementById('mediapipeGazeDot');
            if (gazeDot) {
                gazeDot.remove();
            }

            console.log('âœ… MediaPipe tracking stopped');

            setIsTracking(false);
            setSessionId(null);

            // ìƒíƒœ ë¦¬ì…‹
            noFaceStartTimeRef.current = null;
            latestDataRef.current.noFaceDuration = 0;
            latestDataRef.current.showNoFaceWarning = false;
            setNoFaceDuration(0);
            setShowNoFaceWarning(false);
            warningShownRef.current = false;
            sustainedViolationSentRef.current = false;
            drowsyViolationSentRef.current = false;
            earHistoryRef.current = [];
            closedFrameCountRef.current = 0;

            // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ë¦¬ì…‹ (ë‹¤ìŒ ì„¸ì…˜ì„ ìœ„í•´)
            isBaselineCalibratedRef.current = false;
            calibrationAccumulatorRef.current = {
                headPose: { pitch: 0, yaw: 0, roll: 0 },
                irisOffset: { x: 0, y: 0 },
                count: 0
            };

            // Kalman Filter ë¦¬ì…‹
            if (kalmanFilterRef.current) {
                kalmanFilterRef.current.reset();
            }

        } catch (error) {
            console.error('Error during stopTracking:', error);
        }
    }, [sessionId]);

    // ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
    const toggleDebugMode = useCallback(() => {
        const newDebugMode = !debugModeRef.current;
        debugModeRef.current = newDebugMode; // ref ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (tracking loopì—ì„œ ì‚¬ìš©)
        setDebugMode(newDebugMode); // ìƒíƒœë„ ì—…ë°ì´íŠ¸ (UI ë°˜ì˜)

        if (newDebugMode) {
            // ë””ë²„ê·¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            setTimeout(() => {
                let container = document.getElementById('mediapipeDebugContainer');
                if (!container) {
                    container = document.createElement('div');
                    container.id = 'mediapipeDebugContainer';
                    container.style.cssText = `
                        position: fixed;
                        top: 120px;
                        left: 20px;
                        z-index: 10000;
                        border: 4px solid #22c55e;
                        border-radius: 12px;
                        overflow: hidden;
                        box-shadow: 0 4px 20px rgba(34, 197, 94, 0.4);
                        background: #18181b;
                        width: 320px;
                        height: 240px;
                    `;
                    document.body.appendChild(container);
                }

                // ìº”ë²„ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
                if (!canvasRef.current && videoRef.current) {
                    const canvas = document.createElement('canvas');
                    canvas.id = 'mediapipeOverlay';
                    canvas.width = videoRef.current.videoWidth || 640;
                    canvas.height = videoRef.current.videoHeight || 480;
                    canvasRef.current = canvas;
                }

                if (canvasRef.current) {
                    canvasRef.current.style.cssText = `
                        width: 100%;
                        height: 100%;
                        object-fit: cover;
                    `;
                    // ì´ë¯¸ ì»¨í…Œì´ë„ˆì— ìˆëŠ”ì§€ í™•ì¸
                    if (!container.contains(canvasRef.current)) {
                        container.appendChild(canvasRef.current);
                    }
                }

                // ì‹œì„  ë„íŠ¸ ìƒì„±
                let gazeDot = document.getElementById('mediapipeGazeDot');
                if (!gazeDot) {
                    gazeDot = document.createElement('div');
                    gazeDot.id = 'mediapipeGazeDot';
                    gazeDot.style.cssText = `
                        position: fixed;
                        width: 40px;
                        height: 40px;
                        margin-left: -20px;
                        margin-top: -20px;
                        border-radius: 50%;
                        background: #ef4444;
                        border: 4px solid #ffffff;
                        box-shadow: 0 0 30px rgba(239, 68, 68, 1), 0 0 60px rgba(239, 68, 68, 0.5);
                        pointer-events: none;
                        z-index: 999999;
                        transition: left 0.05s ease-out, top 0.05s ease-out;
                    `;
                    document.body.appendChild(gazeDot);
                }

                console.log('ğŸ”§ MediaPipe Debug mode ON', {
                    hasVideo: !!videoRef.current,
                    hasCanvas: !!canvasRef.current,
                    videoSize: videoRef.current ? `${videoRef.current.videoWidth}x${videoRef.current.videoHeight}` : 'N/A'
                });
            }, 100);
        } else {
            // ë””ë²„ê·¸ ìš”ì†Œ ì œê±° (ìº”ë²„ìŠ¤ëŠ” ìœ ì§€, ì»¨í…Œì´ë„ˆë§Œ ì œê±°)
            const container = document.getElementById('mediapipeDebugContainer');
            if (container) {
                // ìº”ë²„ìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆì—ì„œ ë¶„ë¦¬ (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
                if (canvasRef.current && container.contains(canvasRef.current)) {
                    container.removeChild(canvasRef.current);
                }
                container.remove();
            }

            const gazeDot = document.getElementById('mediapipeGazeDot');
            if (gazeDot) gazeDot.remove();

            console.log('ğŸ”§ MediaPipe Debug mode OFF');
        }
    }, []);

    // ì‹œì„  ë„íŠ¸ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
    useEffect(() => {
        if (!debugMode) return;

        const gazeDot = document.getElementById('mediapipeGazeDot');
        if (gazeDot && gazePosition) {
            gazeDot.style.left = `${gazePosition.x}px`;
            gazeDot.style.top = `${gazePosition.y}px`;
        }
    }, [debugMode, gazePosition]);

    // ì–¼êµ´ ê°ì§€ ìƒíƒœì— ë”°ë¥¸ ì»¨í…Œì´ë„ˆ í…Œë‘ë¦¬ ìƒ‰ìƒ
    useEffect(() => {
        if (!debugMode) return;

        const container = document.getElementById('mediapipeDebugContainer');
        if (!container) return;

        if (!isFaceDetected) {
            container.style.borderColor = '#ef4444';
            container.style.boxShadow = '0 4px 20px rgba(239, 68, 68, 0.6)';
        } else {
            container.style.borderColor = '#22c55e';
            container.style.boxShadow = '0 4px 20px rgba(34, 197, 94, 0.4)';
        }
    }, [debugMode, isFaceDetected]);

    // ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ì‹œ ìë™ ì¶”ì  ì‹œì‘
    useEffect(() => {
        if (isCalibrated && !isTracking && problemId) {
            startTracking();
        }
    }, [isCalibrated, isTracking, problemId, startTracking]);

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    useEffect(() => {
        return () => {
            if (animationFrameRef.current) {
                cancelAnimationFrame(animationFrameRef.current);
            }
            if (videoRef.current?.srcObject) {
                const tracks = videoRef.current.srcObject.getTracks();
                tracks.forEach(track => track.stop());
            }
        };
    }, []);

    return {
        // ê¸°ë³¸ (WebGazer í˜¸í™˜)
        isCalibrated,
        isTracking,
        sessionId,
        monitoringSessionId: sessionId,
        startCalibration,
        completeCalibration,
        stopTracking,

        // NO_FACE ìƒíƒœ (WebGazer í˜¸í™˜)
        noFaceDuration,
        showNoFaceWarning,
        noFaceProgress: noFaceDuration / NO_FACE_THRESHOLD_MS,

        // ë””ë²„ê·¸ (WebGazer í˜¸í™˜)
        debugMode,
        toggleDebugMode,
        isFaceDetected,

        // MediaPipe ì¶”ê°€ ê¸°ëŠ¥
        faceCount,              // ê°ì§€ëœ ì–¼êµ´ ìˆ˜
        detectedFaces,          // ëª¨ë“  ê°ì§€ëœ ì–¼êµ´ ëœë“œë§ˆí¬
        headPose,               // 3D ì–¼êµ´ ë°©í–¥ { pitch, yaw, roll }
        gazePosition,           // ì¶”ì •ëœ ì‹œì„  ìœ„ì¹˜ { x, y }
        eyeState,               // ëˆˆ ìƒíƒœ { leftEAR, rightEAR, avgEAR, isBlinking }
        irisPosition,           // í™ì±„ ìœ„ì¹˜ { left, right }
        drowsinessState,        // ì¡¸ìŒ ìƒíƒœ { isDrowsy, perclos, consecutiveClosedFrames }
        livenessWarning,        // ì‚¬ì§„/ì˜ìƒ ê°ì§€ ê²½ê³  (30ì´ˆ ë™ì•ˆ ëˆˆ ê¹œë¹¡ì„ ì—†ìŒ)

        // 3-point ìº˜ë¦¬ë¸Œë ˆì´ì…˜ìš© refs (MediaPipeCalibrationScreenì—ì„œ ì‚¬ìš©)
        faceLandmarkerRef,      // FaceLandmarker ì¸ìŠ¤í„´ìŠ¤ ref
        videoRef,               // ì›¹ìº  ë¹„ë””ì˜¤ ìš”ì†Œ ref
        setupWebcam             // ì›¹ìº  ì„¤ì • í•¨ìˆ˜
    };
};
